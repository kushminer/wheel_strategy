{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "edd518bc",
      "metadata": {},
      "source": [
        "# Wheel Strategy v5: Date Range + Multi-Ticker Scheduler\n",
        "\n",
        "This notebook extends v4 with a scheduler layer that iterates over trading dates and symbols, launching wheel instances for each qualifying entry.\n",
        "\n",
        "> **v5 Scope**: Changes are limited to *wrappers + orchestration + aggregation*; core strategy logic from v4 is unchanged.\n",
        "\n",
        "## Architecture Overview\n",
        "\n",
        "```\n",
        "┌─────────────────────────────────────────────────────────────┐\n",
        "│                    V5 SCHEDULER LAYER                       │\n",
        "│  SCHEDULER_CONFIG → get_trading_days() → Date x Symbol Loop │\n",
        "│                     → get_entry_candidates() → candidates   │\n",
        "└─────────────────────────────────────────────────────────────┘\n",
        "                              ↓\n",
        "┌─────────────────────────────────────────────────────────────┐\n",
        "│                 V4 WHEEL ENGINE (FROZEN)                    │\n",
        "│  CONFIG, CC_CONFIG → run_single_wheel() → CSP/CC Lifecycle  │\n",
        "│                     → State Machine → Exit Records          │\n",
        "└─────────────────────────────────────────────────────────────┘\n",
        "                              ↓\n",
        "┌─────────────────────────────────────────────────────────────┐\n",
        "│                     AGGREGATION                             │\n",
        "│  all_wheel_results → aggregate_v5_results() → Summary Stats │\n",
        "└─────────────────────────────────────────────────────────────┘\n",
        "```\n",
        "\n",
        "## Key Features\n",
        "- **Multi-Date Backtesting**: Run strategy across configurable date ranges\n",
        "- **Multi-Symbol Support**: Test across multiple underlyings simultaneously  \n",
        "- **Deterministic Execution**: Reproducible results via sorted candidates + execution_seed\n",
        "- **Version Tracking**: Each result stamped with `execution_version` for comparison\n",
        "- **Preserved v4 Engine**: State machine, exit logic, and P&L calculation unchanged\n",
        "\n",
        "## Trade States (from v4)\n",
        "```\n",
        "CSP_OPEN → CSP_CLOSED_PROFIT | CSP_CLOSED_STOP | CSP_ASSIGNED | CSP_CLOSED_WORTHLESS\n",
        "CSP_ASSIGNED → CC_OPEN\n",
        "CC_OPEN → CC_CLOSED_PROFIT | CC_ASSIGNED | CC_CLOSED_WORTHLESS\n",
        "All terminal states → WHEEL_COMPLETE\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b9e2470d",
      "metadata": {},
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "875507cc",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parsed keys: odict_keys(['DATABENTO_API_KEY', 'ANTHROPIC_API_KEY'])\n",
            "os.getenv: True\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "from dotenv import dotenv_values, load_dotenv\n",
        "import sys\n",
        "import os\n",
        "import pandas as pd\n",
        "import databento as db\n",
        "import pandas_market_calendars as mcal\n",
        "\n",
        "sys.executable\n",
        "\n",
        "env_path = Path(\"/Users/samuelminer/Projects/nissan_options/wheel_strategy/.env\")\n",
        "\n",
        "print(\"Parsed keys:\", dotenv_values(env_path).keys())\n",
        "\n",
        "load_dotenv()  # loads .env from current working directory\n",
        "\n",
        "assert os.getenv(\"DATABENTO_API_KEY\"), \"DATABENTO_API_KEY still not found\"\n",
        "print(\"os.getenv:\", bool(os.getenv(\"DATABENTO_API_KEY\")))\n",
        "client = db.Historical()\n",
        "\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.width', None)\n",
        "pd.set_option('display.max_colwidth', None)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "config_header",
      "metadata": {},
      "source": [
        "## Configuration\n",
        "\n",
        "All configurable parameters for the backtest. Modify this cell to change settings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "44b3b54b",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "SCHEDULER CONFIGURATION (V5)\n",
            "============================================================\n",
            "Date Range:      2023-06-06 to 2023-09-13\n",
            "Calendar:        NYSE\n",
            "Symbols:         ['TSLA']\n",
            "Multiple Wheels: True\n",
            "Max per Day:     Unlimited\n",
            "Log Level:       INFO\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# SCHEDULER CONFIGURATION (V5 Addition)\n",
        "# =============================================================================\n",
        "# Controls multi-date, multi-symbol orchestration layer.\n",
        "# CONFIG and CC_CONFIG remain frozen - scheduler only wraps them.\n",
        "\n",
        "SCHEDULER_CONFIG = {\n",
        "    # -------------------------------------------------------------------------\n",
        "    # DATE RANGE\n",
        "    # -------------------------------------------------------------------------\n",
        "    'start_date': '2023-06-06',                # First trading day to consider\n",
        "    'end_date': '2023-09-13',                  # Last trading day to consider\n",
        "    'trading_calendar': 'NYSE',                # Market calendar for trading days\n",
        "    \n",
        "    # -------------------------------------------------------------------------\n",
        "    # SYMBOLS\n",
        "    # -------------------------------------------------------------------------\n",
        "    'symbols': ['TSLA'],                       # Underlyings to backtest\n",
        "    \n",
        "    # -------------------------------------------------------------------------\n",
        "    # WHEEL CONSTRAINTS\n",
        "    # -------------------------------------------------------------------------\n",
        "    'allow_multiple_wheels_per_symbol': True,  # If True, launch wheel for every candidate\n",
        "    'max_wheels_per_symbol_per_day': None,     # None = no limit, or integer cap\n",
        "    \n",
        "    # -------------------------------------------------------------------------\n",
        "    # EXECUTION\n",
        "    # -------------------------------------------------------------------------\n",
        "    'scheduler_seed': 123,                     # Reserved for v6 stochastic scheduling\n",
        "    'log_level': 'INFO',                       # 'INFO' = verbose, 'QUIET' = minimal output\n",
        "}\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"SCHEDULER CONFIGURATION (V5)\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Date Range:      {SCHEDULER_CONFIG['start_date']} to {SCHEDULER_CONFIG['end_date']}\")\n",
        "print(f\"Calendar:        {SCHEDULER_CONFIG['trading_calendar']}\")\n",
        "print(f\"Symbols:         {SCHEDULER_CONFIG['symbols']}\")\n",
        "print(f\"Multiple Wheels: {SCHEDULER_CONFIG['allow_multiple_wheels_per_symbol']}\")\n",
        "print(f\"Max per Day:     {SCHEDULER_CONFIG['max_wheels_per_symbol_per_day'] or 'Unlimited'}\")\n",
        "print(f\"Log Level:       {SCHEDULER_CONFIG['log_level']}\")\n",
        "print(\"=\" * 60)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "config_cell",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "BACKTEST CONFIGURATION\n",
            "============================================================\n",
            "Symbol:          ['TSLA']\n",
            "Entry Date:      2023-06-06\n",
            "Entry Time:      15:45\n",
            "Option Type:     Cash-Secured Put\n",
            "DTE Range:       30 - 45 days\n",
            "Delta Range:     0.25 - 0.35\n",
            "Exit Target:     50% of premium\n",
            "Stop Loss:       2.0x premium\n",
            "Fill Mode:       mid\n",
            "Realistic Fills: False\n",
            "Commission:      $0.65/contract\n",
            "============================================================\n",
            "\n",
            "NOTE: Transaction costs and realistic fills are NOT yet applied.\n",
            "      Run both notebooks to compare baseline vs realistic results.\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# UNIFIED CONFIGURATION\n",
        "# =============================================================================\n",
        "\n",
        "CONFIG = {\n",
        "    # -------------------------------------------------------------------------\n",
        "    # SYMBOL & TIMING\n",
        "    # -------------------------------------------------------------------------\n",
        "    'symbol': SCHEDULER_CONFIG['symbols'],                          # Underlying symbol to backtest\n",
        "    'timezone': 'America/New_York',\n",
        "    \n",
        "    # Entry date/time for the single-day backtest\n",
        "    'entry_date': SCHEDULER_CONFIG['start_date'],                # Date to enter positions\n",
        "    'entry_time': '15:45',                     # Time to capture option chain snapshot\n",
        "    \n",
        "    # Historical data lookback for technical indicators (e.g., Bollinger Bands)\n",
        "    'lookback_days': 252 * 2,                  # ~2 years of daily data\n",
        "    \n",
        "    # -------------------------------------------------------------------------\n",
        "    # OPTION SELECTION CRITERIA\n",
        "    # -------------------------------------------------------------------------\n",
        "    'option_type': 'P',                        # 'P' for puts (CSP), 'C' for calls\n",
        "    'dte_min': 30,                             # Minimum days to expiration\n",
        "    'dte_max': 45,                             # Maximum days to expiration\n",
        "    'delta_min': 0.25,                         # Minimum absolute delta\n",
        "    'delta_max': 0.35,                         # Maximum absolute delta\n",
        "    \n",
        "    # -------------------------------------------------------------------------\n",
        "    # LIQUIDITY MODEL (regime-aware, penalty-based)\n",
        "    # -------------------------------------------------------------------------\n",
        "    # Hard rejection thresholds (truly untradeable)\n",
        "    'min_bid_hard': 0.10,                      # Hard floor - reject penny options\n",
        "    'hard_max_spread_pct': 0.20,               # Hard ceiling - reject extreme spreads\n",
        "    \n",
        "    # Base target spread (calm market conditions)\n",
        "    'base_max_spread_pct': 0.08,               # Target max spread in normal conditions\n",
        "    \n",
        "    # IV regime adjustments (allow wider spreads in high-vol)\n",
        "    'ivp_high_threshold': 0.70,                # IV percentile threshold for \"high vol\"\n",
        "    'ivp_high_max_spread_pct': 0.12,           # Allowed spread when IV is high\n",
        "    'ivp_extreme_threshold': 0.90,             # IV percentile threshold for \"extreme vol\"\n",
        "    'ivp_extreme_max_spread_pct': 0.15,        # Allowed spread when IV is extreme\n",
        "    \n",
        "    # DTE adjustments (short-dated options have wider spreads)\n",
        "    'short_dte_threshold': 7,                  # DTE below this gets extra allowance\n",
        "    'short_dte_extra_spread_pct': 0.02,        # Extra spread allowance for short DTE\n",
        "    \n",
        "    # Penalty tiers (execution tax based on spread quality)\n",
        "    # tight:    spread <= 0.6 * allowed → penalty = 1.0 (no extra slippage)\n",
        "    # moderate: spread <= allowed       → penalty = 1.15 (15% wider effective spread)\n",
        "    # wide:     spread <= hard_max      → penalty = 1.35 (35% wider effective spread)\n",
        "    # ugly:     spread > hard_max       → REJECT (no trade)\n",
        "    \n",
        "    # -------------------------------------------------------------------------\n",
        "    # EXIT STRATEGY\n",
        "    # -------------------------------------------------------------------------\n",
        "    'exit_pct': 0.50,                          # 0.50 = buy back at 50%, keep 50% profit\n",
        "    'stop_loss_multiplier': 2.0,               # Exit if option price reaches Nx premium\n",
        "    'max_hold_dte': None,                      # Exit at X DTE if no other trigger (None = disabled)\n",
        "    \n",
        "    # -------------------------------------------------------------------------\n",
        "    # TRANSACTION COSTS (NEW - will be applied later)\n",
        "    # -------------------------------------------------------------------------\n",
        "    'commission_per_contract': 0.65,           # Per contract commission (round trip = 2x)\n",
        "    'sec_fee_per_contract': 0.01,              # SEC/TAF fees per contract\n",
        "    \n",
        "    # -------------------------------------------------------------------------\n",
        "    # EXECUTION / FILL ASSUMPTIONS (NEW - will be applied later)\n",
        "    # -------------------------------------------------------------------------\n",
        "    'fill_mode': 'mid',                        # 'mid' (current), 'bid' (realistic), 'pessimistic'\n",
        "    'use_realistic_fills': False,              # When True: sell at bid, buy back at ask\n",
        "    \n",
        "    # -------------------------------------------------------------------------\n",
        "    # PROBABILISTIC EXIT FILLS\n",
        "    # -------------------------------------------------------------------------\n",
        "    'execution_seed': 42,                      # Random seed for reproducible fills\n",
        "    'use_probabilistic_exit_fills': True,      # Enable probabilistic fill model\n",
        "    \n",
        "    # Fill probability buckets by spread quality\n",
        "    'pfill_tight': 0.90,                       # spread <= 5%\n",
        "    'pfill_normal': 0.70,                      # spread <= 10%\n",
        "    'pfill_wide': 0.40,                        # spread > 10%\n",
        "    \n",
        "    # Spread thresholds for buckets\n",
        "    'tight_spread_pct': 0.05,\n",
        "    'normal_spread_pct': 0.10,\n",
        "    \n",
        "    # Scaling and clamping\n",
        "    'pfill_scale': 0.6,                        # Sensitivity multiplier (0.8, 1.0, 1.2)\n",
        "    'pfill_min': 0.05,\n",
        "    'pfill_max': 0.98,\n",
        "    \n",
        "    # Optional IVP penalty multipliers\n",
        "    'pfill_ivp_high_mult': 0.85,\n",
        "    'pfill_ivp_extreme_mult': 0.70,\n",
        "    \n",
        "    # -------------------------------------------------------------------------\n",
        "    # CACHE\n",
        "    # -------------------------------------------------------------------------\n",
        "    'cache_dir': '../cache/',\n",
        "}\n",
        "\n",
        "# -------------------------------------------------------------------------\n",
        "# DERIVED VALUES (computed from CONFIG)\n",
        "# -------------------------------------------------------------------------\n",
        "SYMBOL = CONFIG['symbol']\n",
        "TZ = CONFIG['timezone']\n",
        "CACHE_DIR = CONFIG['cache_dir']\n",
        "os.makedirs(CACHE_DIR, exist_ok=True)\n",
        "\n",
        "# Entry timestamp\n",
        "ENTRY_DATE = pd.Timestamp(CONFIG['entry_date'], tz=TZ)\n",
        "ENTRY_TIME = pd.Timestamp(f\"{CONFIG['entry_date']} {CONFIG['entry_time']}\", tz=TZ)\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"BACKTEST CONFIGURATION\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Symbol:          {SYMBOL}\")\n",
        "print(f\"Entry Date:      {ENTRY_DATE.date()}\")\n",
        "print(f\"Entry Time:      {CONFIG['entry_time']}\")\n",
        "print(f\"Option Type:     {'Cash-Secured Put' if CONFIG['option_type'] == 'P' else 'Covered Call'}\")\n",
        "print(f\"DTE Range:       {CONFIG['dte_min']} - {CONFIG['dte_max']} days\")\n",
        "print(f\"Delta Range:     {CONFIG['delta_min']} - {CONFIG['delta_max']}\")\n",
        "print(f\"Exit Target:     {CONFIG['exit_pct']*100:.0f}% of premium\")\n",
        "print(f\"Stop Loss:       {CONFIG['stop_loss_multiplier']}x premium\")\n",
        "print(f\"Fill Mode:       {CONFIG['fill_mode']}\")\n",
        "print(f\"Realistic Fills: {CONFIG['use_realistic_fills']}\")\n",
        "print(f\"Commission:      ${CONFIG['commission_per_contract']}/contract\")\n",
        "print(\"=\" * 60)\n",
        "print(\"\\nNOTE: Transaction costs and realistic fills are NOT yet applied.\")\n",
        "print(\"      Run both notebooks to compare baseline vs realistic results.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "0385e192",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "COVERED CALL CONFIGURATION\n",
            "============================================================\n",
            "DTE Range:       14 - 30 days\n",
            "Delta Range:     0.25 - 0.35\n",
            "Entry Time:      15:45\n",
            "Strike >= Basis: True\n",
            "Tie-Breaking:    highest_premium\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# COVERED CALL CONFIGURATION\n",
        "# =============================================================================\n",
        "\n",
        "CC_CONFIG = {\n",
        "    # -------------------------------------------------------------------------\n",
        "    # OPTION SELECTION CRITERIA\n",
        "    # -------------------------------------------------------------------------\n",
        "    'dte_min': 14,                             # Minimum days to expiration\n",
        "    'dte_max': 30,                             # Maximum days to expiration\n",
        "    'delta_min': 0.25,                         # Minimum absolute delta\n",
        "    'delta_max': 0.35,                         # Maximum absolute delta\n",
        "    'strike_min_pct_above_basis': 0.0,         # Allow ATM (0% above cost basis)\n",
        "    'entry_time': '15:45',                     # Same snapshot time as CSP\n",
        "    \n",
        "    # -------------------------------------------------------------------------\n",
        "    # BEHAVIORAL FLAGS (explicit intent documentation)\n",
        "    # -------------------------------------------------------------------------\n",
        "    'sell_call_only_if_price_above_basis': True,  # Require strike >= cost basis per share\n",
        "    \n",
        "    # -------------------------------------------------------------------------\n",
        "    # TIE-BREAKING FOR CALL SELECTION\n",
        "    # -------------------------------------------------------------------------\n",
        "    # When multiple candidates match criteria, how to select:\n",
        "    # Options: 'highest_premium', 'closest_delta', 'highest_strike'\n",
        "    'tie_break_method': 'highest_premium',\n",
        "}\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"COVERED CALL CONFIGURATION\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"DTE Range:       {CC_CONFIG['dte_min']} - {CC_CONFIG['dte_max']} days\")\n",
        "print(f\"Delta Range:     {CC_CONFIG['delta_min']} - {CC_CONFIG['delta_max']}\")\n",
        "print(f\"Entry Time:      {CC_CONFIG['entry_time']}\")\n",
        "print(f\"Strike >= Basis: {CC_CONFIG['sell_call_only_if_price_above_basis']}\")\n",
        "print(f\"Tie-Breaking:    {CC_CONFIG['tie_break_method']}\")\n",
        "print(\"=\" * 60)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "ecc59228",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "STATE MACHINE VALIDATION\n",
            "============================================================\n",
            "  ✓ CSP_OPEN + 'profit_target' → CSP_CLOSED_PROFIT\n",
            "  ✓ CSP_OPEN + 'assigned' → CSP_ASSIGNED\n",
            "  ✓ CSP_ASSIGNED + 'sell_call' → CC_OPEN\n",
            "  ✓ CSP_ASSIGNED + 'complete' → WHEEL_COMPLETE\n",
            "  ✓ CC_OPEN + 'called_away' → CC_ASSIGNED\n",
            "  ✓ CC_ASSIGNED + 'complete' → WHEEL_COMPLETE\n",
            "  ✓ Correctly rejected invalid transition: CSP_OPEN + 'called_away'\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# =============================================================================\n",
        "# WHEEL STATE MACHINE\n",
        "# =============================================================================\n",
        "# Explicit state transitions prevent logic spaghetti and make logs interpretable.\n",
        "# WHEEL_COMPLETE is the single canonical terminal state for all paths.\n",
        "\n",
        "import uuid\n",
        "\n",
        "# Valid state transitions\n",
        "VALID_TRANSITIONS = {\n",
        "    'CSP_OPEN': ['CSP_CLOSED_PROFIT', 'CSP_CLOSED_STOP', 'CSP_ASSIGNED', 'CSP_CLOSED_WORTHLESS'],\n",
        "    'CSP_ASSIGNED': ['CC_OPEN', 'WHEEL_COMPLETE'],  # Can sell CC or mark incomplete\n",
        "    'CC_OPEN': ['CC_CLOSED_PROFIT', 'CC_ASSIGNED', 'CC_CLOSED_WORTHLESS'],\n",
        "    'CC_ASSIGNED': ['WHEEL_COMPLETE'],\n",
        "    'CC_CLOSED_PROFIT': ['WHEEL_COMPLETE'],      # v1: no re-entry after CC profit\n",
        "    'CC_CLOSED_WORTHLESS': ['WHEEL_COMPLETE'],   # v1: no re-entry after CC expires\n",
        "    'CSP_CLOSED_PROFIT': ['WHEEL_COMPLETE'],\n",
        "    'CSP_CLOSED_STOP': ['WHEEL_COMPLETE'],\n",
        "    'CSP_CLOSED_WORTHLESS': ['WHEEL_COMPLETE'],\n",
        "    'WHEEL_COMPLETE': [],  # Terminal state - no further transitions\n",
        "}\n",
        "\n",
        "# Event to state mapping\n",
        "EVENT_TO_STATE = {\n",
        "    # CSP phase events\n",
        "    ('CSP_OPEN', 'profit_target'): 'CSP_CLOSED_PROFIT',\n",
        "    ('CSP_OPEN', 'stop_loss'): 'CSP_CLOSED_STOP',\n",
        "    ('CSP_OPEN', 'assigned'): 'CSP_ASSIGNED',\n",
        "    ('CSP_OPEN', 'expired_worthless'): 'CSP_CLOSED_WORTHLESS',\n",
        "    \n",
        "    # Assignment to CC\n",
        "    ('CSP_ASSIGNED', 'sell_call'): 'CC_OPEN',\n",
        "    \n",
        "    # CC phase events\n",
        "    ('CC_OPEN', 'profit_target'): 'CC_CLOSED_PROFIT',\n",
        "    ('CC_OPEN', 'called_away'): 'CC_ASSIGNED',\n",
        "    ('CC_OPEN', 'expired_worthless'): 'CC_CLOSED_WORTHLESS',\n",
        "    \n",
        "    # Terminal transitions (all paths lead to WHEEL_COMPLETE)\n",
        "    ('CC_ASSIGNED', 'complete'): 'WHEEL_COMPLETE',\n",
        "    ('CC_CLOSED_PROFIT', 'complete'): 'WHEEL_COMPLETE',\n",
        "    ('CC_CLOSED_WORTHLESS', 'complete'): 'WHEEL_COMPLETE',\n",
        "    ('CSP_CLOSED_PROFIT', 'complete'): 'WHEEL_COMPLETE',\n",
        "    ('CSP_CLOSED_STOP', 'complete'): 'WHEEL_COMPLETE',\n",
        "    ('CSP_CLOSED_WORTHLESS', 'complete'): 'WHEEL_COMPLETE',\n",
        "    ('CSP_ASSIGNED', 'complete'): 'WHEEL_COMPLETE',  # For incomplete wheels (no CC processed)\n",
        "}\n",
        "\n",
        "\n",
        "def advance_wheel_state(current_state, event):\n",
        "    \"\"\"\n",
        "    Advance wheel state based on event. Enforces valid transitions.\n",
        "    \n",
        "    Args:\n",
        "        current_state: Current state string (e.g., 'CSP_OPEN', 'CC_OPEN')\n",
        "        event: Event triggering transition (e.g., 'profit_target', 'assigned', 'called_away')\n",
        "    \n",
        "    Returns:\n",
        "        New state string\n",
        "    \n",
        "    Raises:\n",
        "        ValueError if transition is invalid\n",
        "    \n",
        "    Example:\n",
        "        >>> advance_wheel_state('CSP_OPEN', 'assigned')\n",
        "        'CSP_ASSIGNED'\n",
        "        >>> advance_wheel_state('CC_OPEN', 'called_away')\n",
        "        'CC_ASSIGNED'\n",
        "    \"\"\"\n",
        "    key = (current_state, event)\n",
        "    \n",
        "    if key not in EVENT_TO_STATE:\n",
        "        valid_events = [e for (s, e) in EVENT_TO_STATE.keys() if s == current_state]\n",
        "        raise ValueError(\n",
        "            f\"Invalid transition: state='{current_state}' + event='{event}'. \"\n",
        "            f\"Valid events from {current_state}: {valid_events}\"\n",
        "        )\n",
        "    \n",
        "    new_state = EVENT_TO_STATE[key]\n",
        "    \n",
        "    # Double-check against VALID_TRANSITIONS (belt and suspenders)\n",
        "    if new_state not in VALID_TRANSITIONS.get(current_state, []):\n",
        "        raise ValueError(\n",
        "            f\"State '{new_state}' not reachable from '{current_state}'. \"\n",
        "            f\"Valid transitions: {VALID_TRANSITIONS.get(current_state, [])}\"\n",
        "        )\n",
        "    \n",
        "    return new_state\n",
        "\n",
        "\n",
        "def generate_wheel_id():\n",
        "    \"\"\"Generate a unique wheel ID for linking CSP + CC phases.\"\"\"\n",
        "    return str(uuid.uuid4())[:8]\n",
        "\n",
        "\n",
        "def get_phase_from_state(state):\n",
        "    \"\"\"\n",
        "    Extract phase from state string.\n",
        "    \n",
        "    Returns:\n",
        "        'csp': For CSP states (CSP_OPEN, CSP_CLOSED_*, CSP_ASSIGNED)\n",
        "        'cc': For CC states (CC_OPEN, CC_CLOSED_*, CC_ASSIGNED)\n",
        "        'total': For WHEEL_COMPLETE (used in wheel summaries)\n",
        "        'unknown': For unrecognized states\n",
        "    \"\"\"\n",
        "    if state.startswith('CSP'):\n",
        "        return 'csp'\n",
        "    elif state.startswith('CC'):\n",
        "        return 'cc'\n",
        "    elif state == 'WHEEL_COMPLETE':\n",
        "        return 'total'  # Consistent with wheel summary phase\n",
        "    else:\n",
        "        return 'unknown'\n",
        "\n",
        "\n",
        "def is_terminal_state(state):\n",
        "    \"\"\"Check if state is a terminal state (no further transitions possible).\"\"\"\n",
        "    return len(VALID_TRANSITIONS.get(state, [])) == 0 or state == 'WHEEL_COMPLETE'\n",
        "\n",
        "\n",
        "# Test the state machine\n",
        "print(\"=\" * 60)\n",
        "print(\"STATE MACHINE VALIDATION\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Test valid transitions\n",
        "test_cases = [\n",
        "    ('CSP_OPEN', 'profit_target', 'CSP_CLOSED_PROFIT'),\n",
        "    ('CSP_OPEN', 'assigned', 'CSP_ASSIGNED'),\n",
        "    ('CSP_ASSIGNED', 'sell_call', 'CC_OPEN'),\n",
        "    ('CSP_ASSIGNED', 'complete', 'WHEEL_COMPLETE'),  # For incomplete wheels\n",
        "    ('CC_OPEN', 'called_away', 'CC_ASSIGNED'),\n",
        "    ('CC_ASSIGNED', 'complete', 'WHEEL_COMPLETE'),\n",
        "]\n",
        "\n",
        "for current, event, expected in test_cases:\n",
        "    result = advance_wheel_state(current, event)\n",
        "    status = \"✓\" if result == expected else \"✗\"\n",
        "    print(f\"  {status} {current} + '{event}' → {result}\")\n",
        "\n",
        "# Test invalid transition (should raise)\n",
        "try:\n",
        "    advance_wheel_state('CSP_OPEN', 'called_away')  # Invalid: called_away only valid for CC_OPEN\n",
        "    print(\"  ✗ Should have raised ValueError for invalid transition\")\n",
        "except ValueError as e:\n",
        "    print(f\"  ✓ Correctly rejected invalid transition: CSP_OPEN + 'called_away'\")\n",
        "\n",
        "print(\"=\" * 60)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "helper_functions_cell",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "FILL ASSUMPTIONS BY SCENARIO\n",
            "============================================================\n",
            "Scenario     Entry (Sell)              Exit (Buy Back)          \n",
            "------------------------------------------------------------\n",
            "Pessimistic  Mid - 75% of spread       Close + 75% of range     \n",
            "Realistic    Mid - 30% of spread       Close + 30% of range     \n",
            "Optimistic   Mid (no slippage)         Close - 25% of range     \n",
            "============================================================\n",
            "\n",
            "Transaction costs: $0.66/leg\n",
            "\n",
            "Liquidity Model (regime-aware):\n",
            "  Hard reject: bid < $0.1 or spread > 20%\n",
            "  Base target spread: 8%\n",
            "  High IV (70%ile): allow 12%\n",
            "  Extreme IV (90%ile): allow 15%\n",
            "  Short DTE (≤7d): +2% allowed\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# HELPER FUNCTIONS FOR REALISTIC EXECUTION\n",
        "# =============================================================================\n",
        "\n",
        "def get_entry_price(row, fill_mode='realistic', penalty=1.0):\n",
        "    \"\"\"\n",
        "    Calculate entry price when SELLING a put (we receive premium).\n",
        "    Higher price = better for us.\n",
        "    \n",
        "    Slippage is calculated as a percentage of the bid-ask spread from mid.\n",
        "    Penalty multiplier widens the effective spread for illiquid options.\n",
        "    \n",
        "    | Scenario    | Formula                              | Interpretation              |\n",
        "    |-------------|--------------------------------------|-----------------------------|\n",
        "    | pessimistic | mid - 75% of (spread * penalty)      | Forced/stressed execution   |\n",
        "    | realistic   | mid - 30% of (spread * penalty)      | Normal retail execution     |\n",
        "    | optimistic  | mid                                  | Patient, favorable fills    |\n",
        "    \n",
        "    Args:\n",
        "        row: DataFrame row with bid_px_00, ask_px_00\n",
        "        fill_mode: 'optimistic', 'realistic', or 'pessimistic'\n",
        "        penalty: liquidity penalty multiplier (1.0 = no extra slippage)\n",
        "    \"\"\"\n",
        "    bid = row['bid_px_00']\n",
        "    ask = row['ask_px_00']\n",
        "    mid = (bid + ask) / 2\n",
        "    spread = ask - bid\n",
        "    \n",
        "    # Apply liquidity penalty to effective spread\n",
        "    effective_spread = spread * penalty\n",
        "    \n",
        "    if fill_mode == 'optimistic':\n",
        "        return mid                              # Best case - get mid (no penalty applied)\n",
        "    elif fill_mode == 'pessimistic':\n",
        "        fill = mid - (0.75 * effective_spread)  # Worst case - 75% toward bid\n",
        "    else:  # realistic\n",
        "        fill = mid - (0.30 * effective_spread)  # Normal - 30% toward bid\n",
        "    \n",
        "    # Clamp to [bid, ask] to stay realistic\n",
        "    return max(bid, min(ask, fill))\n",
        "\n",
        "\n",
        "def get_exit_price(daily_row, fill_mode=CONFIG['fill_mode'], target_price=None, penalty=1.0): # IS THIS RIGHT TO SET AT PENALTY = 1.0? ##\n",
        "    \"\"\"\n",
        "    Calculate exit price when BUYING BACK a put (we pay to close).\n",
        "    Lower price = better for us.\n",
        "    \n",
        "    For daily OHLCV data, we estimate spread behavior from the day's range.\n",
        "    Penalty multiplier widens the effective range for illiquid options.\n",
        "    \n",
        "    | Scenario    | Formula                              | Interpretation              |\n",
        "    |-------------|--------------------------------------|-----------------------------|\n",
        "    | pessimistic | close + 75% of (range * penalty)     | Forced/stressed execution   |\n",
        "    | realistic   | close + 30% of (range * penalty)     | Normal retail execution     |\n",
        "    | optimistic  | close - 25% of (range * penalty)     | Patient, favorable fills    |\n",
        "    \n",
        "    Args:\n",
        "        daily_row: DataFrame row with close, high, low\n",
        "        fill_mode: 'optimistic', 'realistic', or 'pessimistic'\n",
        "        target_price: Optional target price (not currently used but reserved)\n",
        "        penalty: liquidity penalty multiplier (1.0 = no extra slippage)\n",
        "    \"\"\"\n",
        "    close = daily_row['close']\n",
        "    high = daily_row['high']\n",
        "    low = daily_row['low']\n",
        "    day_range = high - low  # Proxy for intraday spread/volatility\n",
        "    \n",
        "    # Apply liquidity penalty to effective range\n",
        "    effective_range = day_range * penalty\n",
        "    \n",
        "    if fill_mode == 'optimistic':\n",
        "        # Patient buyer - gets below close (toward low)\n",
        "        fill = close - (0.25 * effective_range)\n",
        "        return max(low, fill)\n",
        "    elif fill_mode == 'pessimistic':\n",
        "        # Forced buyer - pays above close (toward high)\n",
        "        fill = close + (0.75 * effective_range)\n",
        "        return min(high, fill)\n",
        "    else:  # realistic\n",
        "        # Normal execution - slight slippage above close\n",
        "        fill = close + (0.30 * effective_range)\n",
        "        return min(high, fill)\n",
        "\n",
        "\n",
        "def get_transaction_costs(config, is_round_trip=True):\n",
        "    \"\"\"\n",
        "    Calculate total transaction costs per contract.\n",
        "    \n",
        "    Args:\n",
        "        config: CONFIG dict with commission and fee rates\n",
        "        is_round_trip: True if both entry and exit, False if entry only (e.g., expired worthless)\n",
        "    \n",
        "    Returns:\n",
        "        Total fees in dollars per contract\n",
        "    \"\"\"\n",
        "    per_leg = config['commission_per_contract'] + config['sec_fee_per_contract']\n",
        "    return per_leg * 2 if is_round_trip else per_leg\n",
        "\n",
        "\n",
        "def compute_allowed_spread(row, config):\n",
        "    \"\"\"\n",
        "    Compute the allowed spread percentage for a single option based on regime.\n",
        "    \n",
        "    Regime factors:\n",
        "    - IV percentile (high vol → allow wider spreads)\n",
        "    - DTE (short-dated → allow wider spreads)\n",
        "    \n",
        "    Returns: allowed_spread_pct for this option\n",
        "    \"\"\"\n",
        "    base = config['base_max_spread_pct']\n",
        "    \n",
        "    # IV regime adjustment\n",
        "    ivp = row.get('ivp', 0.5)  # Default to median if not computed\n",
        "    if ivp >= config['ivp_extreme_threshold']:\n",
        "        base = config['ivp_extreme_max_spread_pct']\n",
        "    elif ivp >= config['ivp_high_threshold']:\n",
        "        base = config['ivp_high_max_spread_pct']\n",
        "    \n",
        "    # DTE adjustment\n",
        "    dte = row.get('dte', 30)\n",
        "    if dte <= config['short_dte_threshold']:\n",
        "        base += config['short_dte_extra_spread_pct']\n",
        "    \n",
        "    return base\n",
        "\n",
        "\n",
        "def compute_liquidity_penalty(spread_pct, allowed_spread_pct, hard_max_spread_pct):\n",
        "    \"\"\"\n",
        "    Compute liquidity penalty multiplier based on spread quality.\n",
        "    \n",
        "    Tiers:\n",
        "    - tight:    spread <= 0.6 * allowed → penalty = 1.0 (no extra slippage)\n",
        "    - moderate: spread <= allowed       → penalty = 1.15\n",
        "    - wide:     spread <= hard_max      → penalty = 1.35\n",
        "    - ugly:     spread > hard_max       → None (reject)\n",
        "    \n",
        "    Returns: (tier_name, penalty_multiplier) or (None, None) if rejected\n",
        "    \"\"\"\n",
        "    if spread_pct > hard_max_spread_pct:\n",
        "        return 'reject', None\n",
        "    \n",
        "    tight_threshold = 0.6 * allowed_spread_pct\n",
        "    \n",
        "    if spread_pct <= tight_threshold:\n",
        "        return 'tight', 1.0\n",
        "    elif spread_pct <= allowed_spread_pct:\n",
        "        return 'moderate', 1.15\n",
        "    else:  # spread_pct <= hard_max_spread_pct\n",
        "        return 'wide', 1.35\n",
        "\n",
        "\n",
        "def apply_liquidity_model(df, config):\n",
        "    \"\"\"\n",
        "    Apply regime-aware liquidity model with penalty tiers.\n",
        "    \n",
        "    Instead of binary reject, this:\n",
        "    1. Computes IV percentile (ivp) for regime detection\n",
        "    2. Computes allowed_spread_pct per option (regime-aware)\n",
        "    3. Assigns liquidity_tier and liquidity_penalty\n",
        "    4. Only hard-rejects truly ugly spreads\n",
        "    \n",
        "    Args:\n",
        "        df: DataFrame with option quotes (needs bid_px_00, ask_px_00, spread_pct, iv, dte)\n",
        "        config: CONFIG dict with liquidity model settings\n",
        "    \n",
        "    Returns:\n",
        "        DataFrame with liquidity columns added, ugly spreads removed\n",
        "    \"\"\"\n",
        "    if len(df) == 0:\n",
        "        return df\n",
        "    \n",
        "    df = df.copy()\n",
        "    original_count = len(df)\n",
        "    \n",
        "    # Ensure required columns exist\n",
        "    if 'spread_pct' not in df.columns:\n",
        "        df['spread'] = df['ask_px_00'] - df['bid_px_00']\n",
        "        df['spread_pct'] = df['spread'] / df['mid']\n",
        "    \n",
        "    # Step 1: Compute IV percentile (cross-sectional within this snapshot)\n",
        "    if 'iv' in df.columns:\n",
        "        df['ivp'] = df['iv'].rank(pct=True)\n",
        "    else:\n",
        "        df['ivp'] = 0.5  # Default to median if IV not available\n",
        "    \n",
        "    # Step 2: Compute allowed spread per option\n",
        "    df['allowed_spread_pct'] = df.apply(\n",
        "        lambda row: compute_allowed_spread(row, config), axis=1\n",
        "    )\n",
        "    \n",
        "    # Step 3: Compute liquidity tier and penalty\n",
        "    def get_tier_and_penalty(row):\n",
        "        return compute_liquidity_penalty(\n",
        "            row['spread_pct'], \n",
        "            row['allowed_spread_pct'],\n",
        "            config['hard_max_spread_pct']\n",
        "        )\n",
        "    \n",
        "    tiers_penalties = df.apply(get_tier_and_penalty, axis=1)\n",
        "    df['liquidity_tier'] = tiers_penalties.apply(lambda x: x[0])\n",
        "    df['liquidity_penalty'] = tiers_penalties.apply(lambda x: x[1])\n",
        "    \n",
        "    # Step 4: Hard reject only truly ugly spreads and penny options\n",
        "    df = df[\n",
        "        (df['liquidity_tier'] != 'reject') &\n",
        "        (df['bid_px_00'] >= config['min_bid_hard'])\n",
        "    ].copy()\n",
        "    \n",
        "    rejected = original_count - len(df)\n",
        "    \n",
        "    # Print diagnostics\n",
        "    print(f\"\\n  Liquidity Model Applied:\")\n",
        "    print(f\"    Original: {original_count} options\")\n",
        "    print(f\"    Hard rejected: {rejected} ({rejected/original_count*100:.1f}%)\")\n",
        "    print(f\"    Remaining: {len(df)} options\")\n",
        "    \n",
        "    if len(df) > 0:\n",
        "        tier_counts = df['liquidity_tier'].value_counts()\n",
        "        print(f\"    Tier breakdown: {dict(tier_counts)}\")\n",
        "        print(f\"    Avg spread: {df['spread_pct'].mean()*100:.1f}%, Avg allowed: {df['allowed_spread_pct'].mean()*100:.1f}%\")\n",
        "        print(f\"    Avg penalty: {df['liquidity_penalty'].mean():.2f}x\")\n",
        "    return df\n",
        "\n",
        "\n",
        "def calculate_pnl(premium_received, exit_price_paid, fees, cost_basis):\n",
        "    \"\"\"\n",
        "    Calculate P&L metrics for a trade.\n",
        "    \n",
        "    Args:\n",
        "        premium_received: Premium collected when selling (contract value)\n",
        "        exit_price_paid: Price paid to close position (contract value), 0 if expired worthless\n",
        "        fees: Total transaction costs\n",
        "        cost_basis: Capital at risk (strike * 100 for CSP)\n",
        "    \n",
        "    Returns:\n",
        "        dict with pnl, pnl_pct, roc\n",
        "    \"\"\"\n",
        "    pnl = premium_received - exit_price_paid - fees\n",
        "    pnl_pct = (pnl / premium_received) * 100 if premium_received > 0 else 0\n",
        "    roc = (pnl / cost_basis) * 100 if cost_basis > 0 else 0\n",
        "    \n",
        "    return {\n",
        "        'pnl': pnl,\n",
        "        'pnl_pct': pnl_pct,\n",
        "        'roc': roc,\n",
        "        'fees': fees\n",
        "    }\n",
        "\n",
        "\n",
        "def compute_p_fill_profit(row, config):\n",
        "    \"\"\"\n",
        "    Compute probability of fill for profit target exit based on entry liquidity.\n",
        "    \n",
        "    Uses entry-time spread and IVP to determine fill probability:\n",
        "    - tight spread (<=5%): high fill probability\n",
        "    - normal spread (<=10%): moderate fill probability\n",
        "    - wide spread (>10%): low fill probability\n",
        "    \n",
        "    Applies IVP penalty multipliers for high-volatility regimes.\n",
        "    \n",
        "    Args:\n",
        "        row: DataFrame row with spread_pct_entry, ivp_entry\n",
        "        config: CONFIG dict with fill probability settings\n",
        "    \n",
        "    Returns:\n",
        "        float: Fill probability in [pfill_min, pfill_max]\n",
        "    \"\"\"\n",
        "    spread_pct = row.get('spread_pct_entry', 0.05)\n",
        "    \n",
        "    # Bucket by spread quality\n",
        "    if spread_pct <= config['tight_spread_pct']:\n",
        "        p_fill = config['pfill_tight']\n",
        "    elif spread_pct <= config['normal_spread_pct']:\n",
        "        p_fill = config['pfill_normal']\n",
        "    else:\n",
        "        p_fill = config['pfill_wide']\n",
        "    \n",
        "    # Apply scale multiplier\n",
        "    p_fill *= config['pfill_scale']\n",
        "    \n",
        "    # Apply IVP penalty (always use ivp_entry, not generic ivp)\n",
        "    ivp = row.get('ivp_entry', 0.5)\n",
        "    if ivp >= config['ivp_extreme_threshold']:\n",
        "        p_fill *= config.get('pfill_ivp_extreme_mult', 1.0)\n",
        "    elif ivp >= config['ivp_high_threshold']:\n",
        "        p_fill *= config.get('pfill_ivp_high_mult', 1.0)\n",
        "    \n",
        "    # Clamp to valid range\n",
        "    return max(config['pfill_min'], min(config['pfill_max'], p_fill))\n",
        "\n",
        "\n",
        "def try_probabilistic_fill(p_fill, rng):\n",
        "    \"\"\"\n",
        "    Simulate probabilistic fill by drawing uniform random number.\n",
        "    \n",
        "    Args:\n",
        "        p_fill: Fill probability (0.0 to 1.0)\n",
        "        rng: numpy random number generator\n",
        "    \n",
        "    Returns:\n",
        "        tuple: (filled: bool, u: float) where u is the random draw\n",
        "    \"\"\"\n",
        "    u = rng.uniform(0, 1)\n",
        "    filled = (u <= p_fill)\n",
        "    return filled, u\n",
        "\n",
        "\n",
        "def fetch_underlying_price_at_expiration(underlying_symbol, expiration_date, client, config):\n",
        "    \"\"\"\n",
        "    Fetch the underlying price at option expiration (for ITM/OTM check).\n",
        "    \n",
        "    Uses cached daily equity data or fetches if not available.\n",
        "    \n",
        "    Args:\n",
        "        underlying_symbol: Underlying ticker (e.g., 'TSLA')\n",
        "        expiration_date: Expiration date (Timestamp)\n",
        "        client: Databento client\n",
        "        config: CONFIG dict\n",
        "    \n",
        "    Returns:\n",
        "        float: Underlying close price on expiration date, or None if unavailable\n",
        "    \"\"\"\n",
        "    cache_dir = config.get('cache_dir', '../cache/')\n",
        "    tz = config.get('timezone', 'America/New_York')\n",
        "    \n",
        "    # Normalize date\n",
        "    exp_date = pd.Timestamp(expiration_date)\n",
        "    if exp_date.tz is not None:\n",
        "        exp_date = exp_date.tz_localize(None)\n",
        "    \n",
        "    date_str = exp_date.strftime('%Y%m%d')\n",
        "    \n",
        "    # Try to find in daily equity cache (check multiple possible formats)\n",
        "    cache_patterns = [\n",
        "        f\"equity_daily_{underlying_symbol}_*.parquet\",\n",
        "    ]\n",
        "    \n",
        "    # First, try to load from any cached daily file\n",
        "    cache_files = [f for f in os.listdir(cache_dir) if f.startswith(f\"equity_daily_{underlying_symbol}_\")]\n",
        "    \n",
        "    for cache_file in cache_files:\n",
        "        try:\n",
        "            df = pd.read_parquet(os.path.join(cache_dir, cache_file))\n",
        "            # Find the expiration date in the index\n",
        "            if hasattr(df.index, 'date'):\n",
        "                matches = df[df.index.date == exp_date.date()]\n",
        "            else:\n",
        "                df.index = pd.to_datetime(df.index)\n",
        "                matches = df[df.index.date == exp_date.date()]\n",
        "            \n",
        "            if len(matches) > 0:\n",
        "                return matches.iloc[-1]['close']\n",
        "        except Exception:\n",
        "            continue\n",
        "    \n",
        "    # Fallback: try to fetch specific day\n",
        "    try:\n",
        "        start = exp_date\n",
        "        end = exp_date + pd.Timedelta(days=1)\n",
        "        \n",
        "        data = client.timeseries.get_range(\n",
        "            dataset='EQUS.MINI',\n",
        "            symbols=underlying_symbol,\n",
        "            schema='ohlcv-1d',\n",
        "            stype_in='raw_symbol',\n",
        "            start=start,\n",
        "            end=end,\n",
        "        )\n",
        "        df = data.to_df(tz=tz)\n",
        "        if len(df) > 0:\n",
        "            return df.iloc[-1]['close']\n",
        "    except Exception as e:\n",
        "        pass\n",
        "    \n",
        "    return None\n",
        "\n",
        "\n",
        "# Print summary of fill assumptions\n",
        "print(\"=\" * 60)\n",
        "print(\"FILL ASSUMPTIONS BY SCENARIO\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"{'Scenario':<12} {'Entry (Sell)':<25} {'Exit (Buy Back)':<25}\")\n",
        "print(\"-\" * 60)\n",
        "print(f\"{'Pessimistic':<12} {'Mid - 75% of spread':<25} {'Close + 75% of range':<25}\")\n",
        "print(f\"{'Realistic':<12} {'Mid - 30% of spread':<25} {'Close + 30% of range':<25}\")\n",
        "print(f\"{'Optimistic':<12} {'Mid (no slippage)':<25} {'Close - 25% of range':<25}\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"\\nTransaction costs: ${CONFIG['commission_per_contract'] + CONFIG['sec_fee_per_contract']:.2f}/leg\")\n",
        "print(f\"\\nLiquidity Model (regime-aware):\")\n",
        "print(f\"  Hard reject: bid < ${CONFIG['min_bid_hard']} or spread > {CONFIG['hard_max_spread_pct']*100:.0f}%\")\n",
        "print(f\"  Base target spread: {CONFIG['base_max_spread_pct']*100:.0f}%\")\n",
        "print(f\"  High IV ({CONFIG['ivp_high_threshold']*100:.0f}%ile): allow {CONFIG['ivp_high_max_spread_pct']*100:.0f}%\")\n",
        "print(f\"  Extreme IV ({CONFIG['ivp_extreme_threshold']*100:.0f}%ile): allow {CONFIG['ivp_extreme_max_spread_pct']*100:.0f}%\")\n",
        "print(f\"  Short DTE (≤{CONFIG['short_dte_threshold']}d): +{CONFIG['short_dte_extra_spread_pct']*100:.0f}% allowed\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1970a90f",
      "metadata": {},
      "source": [
        "## V5 Scheduler Layer\n",
        "\n",
        "The following cells add orchestration on top of the v4 wheel engine:\n",
        "1. **Trading Calendar Utility**: Generate valid trading days\n",
        "2. **Entry Candidate Wrapper**: Encapsulate option chain fetch + filter logic\n",
        "3. **Single Wheel Wrapper**: Run one wheel cycle for a given candidate\n",
        "4. **Scheduler Loop**: Iterate over dates × symbols, launching wheels\n",
        "5. **Aggregation**: Combine results across all wheels\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "bb4d1101",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "TRADING CALENDAR UTILITY\n",
            "============================================================\n",
            "Trading days Jan 1-15, 2023: 9 days\n",
            "First: 2023-01-03, Last: 2023-01-13\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# TRADING CALENDAR UTILITY (V5)\n",
        "# =============================================================================\n",
        "\n",
        "def get_trading_days(start_date, end_date, calendar='NYSE'):\n",
        "    \"\"\"\n",
        "    Get valid trading days for a date range using market calendar.\n",
        "    \n",
        "    Args:\n",
        "        start_date: Start date string or Timestamp\n",
        "        end_date: End date string or Timestamp  \n",
        "        calendar: Market calendar name (default 'NYSE')\n",
        "    \n",
        "    Returns:\n",
        "        DatetimeIndex of valid trading days (timezone-naive, treated as NY dates)\n",
        "    \"\"\"\n",
        "    cal = mcal.get_calendar(calendar)\n",
        "    schedule = cal.schedule(start_date=start_date, end_date=end_date)\n",
        "    # schedule.index is timezone-naive; we treat it as trading day in NY\n",
        "    return schedule.index\n",
        "\n",
        "\n",
        "# Test the function\n",
        "test_days = get_trading_days('2023-01-01', '2023-01-15')\n",
        "print(\"=\" * 60)\n",
        "print(\"TRADING CALENDAR UTILITY\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Trading days Jan 1-15, 2023: {len(test_days)} days\")\n",
        "print(f\"First: {test_days[0].date()}, Last: {test_days[-1].date()}\")\n",
        "print(\"=\" * 60)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "5549a541",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "ENTRY CANDIDATE WRAPPER LOADED\n",
            "============================================================\n",
            "  get_entry_candidates(symbol, trade_date, config, client)\n",
            "  Returns DataFrame of qualifying CSP candidates\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# ENTRY CANDIDATE WRAPPER (V5)\n",
        "# =============================================================================\n",
        "\n",
        "def get_entry_candidates(symbol, trade_date, config, client):\n",
        "    \"\"\"\n",
        "    Get qualifying CSP entry candidates for a given symbol and date.\n",
        "    \n",
        "    Encapsulates:\n",
        "    1. Fetch option chain snapshot at entry_time\n",
        "    2. Parse option symbols and calculate DTE\n",
        "    3. Compute IV and delta\n",
        "    4. Apply delta/DTE filters\n",
        "    5. Apply liquidity model\n",
        "    6. Sort deterministically for reproducibility\n",
        "    \n",
        "    Args:\n",
        "        symbol: Underlying symbol (e.g., 'TSLA')\n",
        "        trade_date: Trading date (Timestamp or date-like)\n",
        "        config: CONFIG dict with entry parameters\n",
        "        client: Databento client\n",
        "    \n",
        "    Returns:\n",
        "        DataFrame of qualifying candidates, or empty DataFrame if none found\n",
        "    \"\"\"\n",
        "    import numpy as np\n",
        "    from py_vollib.black_scholes.implied_volatility import implied_volatility\n",
        "    from py_vollib.black_scholes.greeks.analytical import delta as calc_delta\n",
        "    \n",
        "    tz = config.get('timezone', 'America/New_York')\n",
        "    cache_dir = config.get('cache_dir', '../cache/')\n",
        "    entry_time = config.get('entry_time', '15:45')\n",
        "    r = 0.04  # Risk-free rate\n",
        "    \n",
        "    # Build entry timestamp\n",
        "    trade_date_str = pd.Timestamp(trade_date).strftime('%Y-%m-%d')\n",
        "    entry_ts = pd.Timestamp(f\"{trade_date_str} {entry_time}\", tz=tz)\n",
        "    \n",
        "    # Cache filename for options\n",
        "    date_str = entry_ts.strftime('%Y%m%d')\n",
        "    time_str = entry_ts.strftime('%H%M')\n",
        "    cache_file = os.path.join(cache_dir, f\"options_{symbol}_{date_str}_{time_str}.parquet\")\n",
        "    \n",
        "    # Fetch or load options data\n",
        "    if os.path.exists(cache_file):\n",
        "        df_opts = pd.read_parquet(cache_file)\n",
        "    else:\n",
        "        try:\n",
        "            start = entry_ts\n",
        "            end = start + pd.Timedelta(minutes=1)\n",
        "            data = client.timeseries.get_range(\n",
        "                dataset='OPRA.PILLAR',\n",
        "                schema='cmbp-1',\n",
        "                symbols=f\"{symbol}.OPT\",\n",
        "                stype_in='parent',\n",
        "                start=start,\n",
        "                end=end,\n",
        "            )\n",
        "            df_opts = data.to_df(tz=tz).sort_values(\"ts_event\")\n",
        "            df_opts.to_parquet(cache_file)\n",
        "        except Exception as e:\n",
        "            # Return empty DataFrame on error\n",
        "            return pd.DataFrame()\n",
        "    \n",
        "    if len(df_opts) == 0:\n",
        "        return pd.DataFrame()\n",
        "    \n",
        "    # Parse option symbols\n",
        "    sym = df_opts[\"symbol\"]\n",
        "    root_and_code = sym.str.split(expand=True)\n",
        "    df_opts[\"root\"] = root_and_code[0]\n",
        "    code = root_and_code[1]\n",
        "    df_opts[\"expiration\"] = pd.to_datetime(code.str[:6], format=\"%y%m%d\")\n",
        "    df_opts[\"call_put\"] = code.str[6]\n",
        "    strike_int = code.str[7:].astype(\"int32\")\n",
        "    df_opts[\"strike\"] = strike_int / 1000.0\n",
        "    expiration_tz = df_opts[\"expiration\"].dt.tz_localize(df_opts[\"ts_event\"].dt.tz)\n",
        "    df_opts[\"dte\"] = (expiration_tz - df_opts[\"ts_event\"].dt.normalize()).dt.days\n",
        "    \n",
        "    # Filter by DTE and option type\n",
        "    df_opts = df_opts[\n",
        "        (df_opts['dte'] >= config['dte_min']) & \n",
        "        (df_opts['dte'] <= config['dte_max']) & \n",
        "        (df_opts['call_put'] == config['option_type'])\n",
        "    ]\n",
        "    \n",
        "    if len(df_opts) == 0:\n",
        "        return pd.DataFrame()\n",
        "    \n",
        "    # Get underlying price\n",
        "    equity_cache = os.path.join(cache_dir, f\"equity_minute_{symbol}_{date_str}_{time_str}.parquet\")\n",
        "    if os.path.exists(equity_cache):\n",
        "        equity_df = pd.read_parquet(equity_cache)\n",
        "        underlying_price = equity_df['close'].iloc[-1] if len(equity_df) > 0 else None\n",
        "    else:\n",
        "        # Fetch underlying price\n",
        "        try:\n",
        "            start_time = entry_ts\n",
        "            end_time = start_time + pd.Timedelta(minutes=1)\n",
        "            equity_data = client.timeseries.get_range(\n",
        "                dataset='XNAS.ITCH',\n",
        "                symbols=[symbol],\n",
        "                schema='ohlcv-1m',\n",
        "                start=start_time,\n",
        "                end=end_time,\n",
        "                stype_in='raw_symbol'\n",
        "            )\n",
        "            equity_df = equity_data.to_df()\n",
        "            equity_df.to_parquet(equity_cache)\n",
        "            underlying_price = equity_df['close'].iloc[-1] if len(equity_df) > 0 else None\n",
        "        except:\n",
        "            underlying_price = None\n",
        "    \n",
        "    if underlying_price is None:\n",
        "        return pd.DataFrame()\n",
        "    \n",
        "    # Keep only rows with valid quotes\n",
        "    quotes = df_opts[df_opts[\"bid_px_00\"].notna() & df_opts[\"ask_px_00\"].notna()].copy()\n",
        "    if len(quotes) == 0:\n",
        "        return pd.DataFrame()\n",
        "    \n",
        "    quotes[\"mid\"] = (quotes[\"bid_px_00\"] + quotes[\"ask_px_00\"]) / 2\n",
        "    quotes[\"spread\"] = quotes[\"ask_px_00\"] - quotes[\"bid_px_00\"]\n",
        "    quotes[\"spread_pct\"] = quotes[\"spread\"] / quotes[\"mid\"]\n",
        "    \n",
        "    # Collapse to one row per contract (latest quote)\n",
        "    chain_snapshot = (\n",
        "        quotes\n",
        "        .sort_values(\"ts_event\")\n",
        "        .groupby([\"symbol\", \"expiration\", \"strike\", \"call_put\"])\n",
        "        .tail(1)\n",
        "        .copy()\n",
        "    )\n",
        "    chain_snapshot[\"underlying_last\"] = underlying_price\n",
        "    \n",
        "    # Compute IV and delta\n",
        "    def compute_iv_delta(row):\n",
        "        price = row[\"mid\"]\n",
        "        S = row[\"underlying_last\"]\n",
        "        K = row[\"strike\"]\n",
        "        t = row[\"dte\"] / 365.0\n",
        "        flag = \"p\" if row[\"call_put\"] == \"P\" else \"c\"\n",
        "        \n",
        "        if not (np.isfinite(price) and np.isfinite(S) and np.isfinite(K) and t > 0):\n",
        "            return np.nan, np.nan\n",
        "        if price <= 0 or S <= 0 or K <= 0:\n",
        "            return np.nan, np.nan\n",
        "        \n",
        "        try:\n",
        "            iv = implied_volatility(price, S, K, t, r, flag)\n",
        "            d = abs(calc_delta(flag, S, K, t, r, iv))\n",
        "            return iv, d\n",
        "        except:\n",
        "            return np.nan, np.nan\n",
        "    \n",
        "    iv_delta = chain_snapshot.apply(compute_iv_delta, axis=1, result_type='expand')\n",
        "    chain_snapshot['iv'] = iv_delta[0]\n",
        "    chain_snapshot['delta'] = iv_delta[1]\n",
        "    chain_snapshot['date'] = chain_snapshot['ts_event'].dt.date\n",
        "    \n",
        "    # Filter by delta range\n",
        "    candidates = chain_snapshot[\n",
        "        chain_snapshot[\"delta\"].abs().between(config['delta_min'], config['delta_max'])\n",
        "    ].copy()\n",
        "    \n",
        "    if len(candidates) == 0:\n",
        "        return pd.DataFrame()\n",
        "    \n",
        "    # Apply liquidity model (use the existing function - it prints output, so we suppress later)\n",
        "    candidates = apply_liquidity_model(candidates, config)\n",
        "    \n",
        "    if len(candidates) == 0:\n",
        "        return pd.DataFrame()\n",
        "    \n",
        "    # Calculate entry price with liquidity penalty\n",
        "    candidates['entry_price'] = candidates.apply(\n",
        "        lambda row: get_entry_price(row, config['fill_mode'], row.get('liquidity_penalty', 1.0)), \n",
        "        axis=1\n",
        "    )\n",
        "    candidates['per_share_premium'] = candidates['entry_price']\n",
        "    candidates['premium'] = candidates['per_share_premium'] * 100\n",
        "    candidates['cost_basis'] = candidates['strike'] * 100\n",
        "    candidates['exit_pct'] = config['exit_pct']\n",
        "    candidates['exit_price_per_share'] = candidates['per_share_premium'] * candidates['exit_pct']\n",
        "    candidates['spread_pct_entry'] = candidates['spread_pct']\n",
        "    candidates['ivp_entry'] = candidates['ivp']\n",
        "    \n",
        "    # DETERMINISTIC SORT for reproducibility\n",
        "    candidates = candidates.sort_values(\n",
        "        ['expiration', 'strike', 'symbol']\n",
        "    ).reset_index(drop=True)\n",
        "    \n",
        "    return candidates\n",
        "\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"ENTRY CANDIDATE WRAPPER LOADED\")\n",
        "print(\"=\" * 60)\n",
        "print(\"  get_entry_candidates(symbol, trade_date, config, client)\")\n",
        "print(\"  Returns DataFrame of qualifying CSP candidates\")\n",
        "print(\"=\" * 60)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "34b3e449",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "SINGLE WHEEL WRAPPER LOADED\n",
            "============================================================\n",
            "  run_single_wheel(candidate, config, cc_config, wheel_id, client)\n",
            "  Returns List[dict] of exit records for one wheel cycle\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# SINGLE WHEEL WRAPPER (V5)\n",
        "# =============================================================================\n",
        "\n",
        "def run_single_wheel(candidate, config, cc_config, wheel_id, client, log_info=True):\n",
        "    \"\"\"\n",
        "    Run a complete wheel cycle for a single candidate.\n",
        "    \n",
        "    Orchestrates:\n",
        "    1. CSP entry and exit (using existing backtest_exit_strategy logic)\n",
        "    2. If assigned: handle assignment and sell covered call\n",
        "    3. CC exit (if applicable)\n",
        "    4. Calculate wheel P&L\n",
        "    \n",
        "    Args:\n",
        "        candidate: Series with candidate option data\n",
        "        config: CONFIG dict\n",
        "        cc_config: CC_CONFIG dict  \n",
        "        wheel_id: Unique identifier for this wheel\n",
        "        client: Databento client\n",
        "        log_info: If True, print progress info\n",
        "    \n",
        "    Returns:\n",
        "        List[dict]: Exit records for this wheel (CSP, CC if applicable, total)\n",
        "    \"\"\"\n",
        "    import numpy as np\n",
        "    \n",
        "    # Initialize RNG with wheel-specific seed for reproducibility\n",
        "    base_seed = config.get('execution_seed', 42)\n",
        "    rng = np.random.RandomState(base_seed + hash(wheel_id) % 10000)\n",
        "    \n",
        "    wheel_results = []\n",
        "    \n",
        "    # Extract candidate info\n",
        "    symbol = candidate['symbol']\n",
        "    entry_date = pd.Timestamp(candidate['date']).tz_localize(None)\n",
        "    expiration_date = pd.Timestamp(candidate['expiration']).tz_localize(None)\n",
        "    strike = candidate['strike']\n",
        "    premium_per_share = candidate['entry_price']\n",
        "    premium = premium_per_share * 100\n",
        "    cost_basis = candidate['cost_basis']\n",
        "    exit_pct = candidate['exit_pct']\n",
        "    exit_price_per_share = premium_per_share * exit_pct\n",
        "    stop_loss_per_share = premium_per_share * config.get('stop_loss_multiplier', 2.0)\n",
        "    liquidity_penalty = candidate.get('liquidity_penalty', 1.0)\n",
        "    spread_pct_entry = candidate.get('spread_pct_entry', 0.05)\n",
        "    ivp_entry = candidate.get('ivp_entry', 0.5)\n",
        "    \n",
        "    # Initialize CSP state\n",
        "    current_state = 'CSP_OPEN'\n",
        "    \n",
        "    if log_info:\n",
        "        print(f\"\\n  Wheel {wheel_id}: {symbol}\")\n",
        "        print(f\"    Entry: {entry_date.date()}, Strike: ${strike:.2f}, Premium: ${premium:.2f}\")\n",
        "    \n",
        "    # Initialize tracking variables BEFORE try block to avoid UnboundLocalError\n",
        "    touch_count = 0\n",
        "    touch_profit_target = False\n",
        "    filled_profit_target = False\n",
        "    p_fill_profit = None\n",
        "    u_fill_profit = None\n",
        "    exit_date = None\n",
        "    exit_daily_row = None\n",
        "    exit_reason = None\n",
        "    exit_price = None\n",
        "    underlying_at_exp = None\n",
        "    \n",
        "    # ----- CSP LIFECYCLE -----\n",
        "    try:\n",
        "        # Fetch daily prices for the option\n",
        "        df_daily = fetch_daily_prices_for_option(symbol, entry_date, expiration_date, client, config)\n",
        "        \n",
        "        # Compute fill probability\n",
        "        if config.get('use_probabilistic_exit_fills', True):\n",
        "            p_fill_profit = compute_p_fill_profit(candidate, config)\n",
        "        \n",
        "        # Loop through trading days\n",
        "        for check_date, daily_row in df_daily.iterrows():\n",
        "            check_date_normalized = check_date.tz_localize(None) if hasattr(check_date, 'tz_localize') and check_date.tz else check_date\n",
        "            \n",
        "            if check_date_normalized.date() <= entry_date.date():\n",
        "                continue\n",
        "            \n",
        "            daily_low = daily_row['low']\n",
        "            daily_high = daily_row['high']\n",
        "            \n",
        "            # Check stop-loss first\n",
        "            if daily_high >= stop_loss_per_share:\n",
        "                exit_date = check_date_normalized\n",
        "                exit_daily_row = daily_row\n",
        "                exit_reason = 'stop_loss'\n",
        "                current_state = advance_wheel_state(current_state, 'stop_loss')\n",
        "                actual_exit_per_share = get_exit_price(daily_row, config.get('fill_mode', 'realistic'), penalty=liquidity_penalty)\n",
        "                exit_price = actual_exit_per_share * 100\n",
        "                break\n",
        "            \n",
        "            # Check profit target touch\n",
        "            if daily_low <= exit_price_per_share:\n",
        "                touch_profit_target = True\n",
        "                touch_count += 1\n",
        "                \n",
        "                if config.get('use_probabilistic_exit_fills', True) and p_fill_profit is not None:\n",
        "                    u = rng.uniform(0, 1)\n",
        "                    u_fill_profit = u\n",
        "                    \n",
        "                    if u <= p_fill_profit:\n",
        "                        exit_date = check_date_normalized\n",
        "                        exit_daily_row = daily_row\n",
        "                        exit_reason = 'profit_target'\n",
        "                        current_state = advance_wheel_state(current_state, 'profit_target')\n",
        "                        filled_profit_target = True\n",
        "                        actual_exit_per_share = get_exit_price(daily_row, config.get('fill_mode', 'realistic'), penalty=liquidity_penalty)\n",
        "                        exit_price = actual_exit_per_share * 100\n",
        "                        break\n",
        "                else:\n",
        "                    exit_date = check_date_normalized\n",
        "                    exit_daily_row = daily_row\n",
        "                    exit_reason = 'profit_target'\n",
        "                    current_state = advance_wheel_state(current_state, 'profit_target')\n",
        "                    filled_profit_target = True\n",
        "                    actual_exit_per_share = get_exit_price(daily_row, config.get('fill_mode', 'realistic'), penalty=liquidity_penalty)\n",
        "                    exit_price = actual_exit_per_share * 100\n",
        "                    break\n",
        "        \n",
        "        # Handle expiration if no exit\n",
        "        if exit_date is None:\n",
        "            exit_date = expiration_date\n",
        "            exit_daily_row = None\n",
        "            \n",
        "            # Check if assigned (ITM at expiration)\n",
        "            underlying_at_exp = fetch_underlying_price_at_expiration(\n",
        "                symbol.split()[0], expiration_date, client, config\n",
        "            )\n",
        "            \n",
        "            if underlying_at_exp is not None and underlying_at_exp < strike:\n",
        "                # Put is ITM → assigned\n",
        "                exit_reason = 'assigned'\n",
        "                current_state = advance_wheel_state(current_state, 'assigned')\n",
        "                exit_price = 0.0  # Option not bought back, shares assigned\n",
        "            else:\n",
        "                # OTM → expired worthless\n",
        "                exit_reason = 'expired_worthless'\n",
        "                current_state = advance_wheel_state(current_state, 'expired_worthless')\n",
        "                exit_price = 0.0\n",
        "        \n",
        "    except Exception as e:\n",
        "        if log_info:\n",
        "            print(f\"    ✗ CSP Error: {e}\")\n",
        "        exit_date = expiration_date\n",
        "        exit_reason = 'error'\n",
        "        exit_price = 0.0\n",
        "        current_state = 'CSP_CLOSED_WORTHLESS'\n",
        "    \n",
        "    # Calculate CSP fees\n",
        "    csp_fees = get_transaction_costs(config, is_round_trip=(exit_reason not in ['expired_worthless', 'assigned']))\n",
        "    csp_pnl = premium - exit_price - csp_fees\n",
        "    csp_roc = (csp_pnl / cost_basis) * 100\n",
        "    \n",
        "    # Create CSP exit record\n",
        "    csp_exit = {\n",
        "        'wheel_id': wheel_id,\n",
        "        'phase': 'csp',\n",
        "        'state': current_state,\n",
        "        'symbol': symbol,\n",
        "        'strike': strike,\n",
        "        'entry_date': entry_date,\n",
        "        'exit_date': exit_date,\n",
        "        'expiration': expiration_date,\n",
        "        'cost_basis': cost_basis,\n",
        "        'initial_capital': cost_basis,\n",
        "        'premium': premium,\n",
        "        'exit_pct': exit_pct,\n",
        "        'exit_price': exit_price,\n",
        "        'exit_reason': exit_reason,\n",
        "        'days_held': (exit_date - entry_date).days if exit_date else None,\n",
        "        'pnl': csp_pnl,\n",
        "        'roc': csp_roc,\n",
        "        'fees': csp_fees,\n",
        "        'touch_profit_target': touch_profit_target,\n",
        "        'p_fill_profit_target': p_fill_profit,\n",
        "        'u_fill_profit_target': u_fill_profit,\n",
        "        'filled_profit_target': filled_profit_target,\n",
        "        'touch_count': touch_count,\n",
        "        'spread_pct_entry': spread_pct_entry,\n",
        "        'ivp_entry': ivp_entry,\n",
        "        'underlying_at_expiration': underlying_at_exp,\n",
        "        'execution_version': 'v5_scheduler',\n",
        "    }\n",
        "    wheel_results.append(csp_exit)\n",
        "    \n",
        "    if log_info:\n",
        "        print(f\"    CSP: {exit_reason} → {current_state}, P&L: ${csp_pnl:.2f}\")\n",
        "    \n",
        "    # ----- COVERED CALL LIFECYCLE (if assigned) -----\n",
        "    cc_exit = None\n",
        "    if exit_reason == 'assigned':\n",
        "        if log_info:\n",
        "            print(f\"    → Processing CC after assignment...\")\n",
        "        \n",
        "        # Create assignment record\n",
        "        assignment_record = {\n",
        "            'wheel_id': wheel_id,\n",
        "            'symbol': symbol.split()[0],  # Underlying\n",
        "            'assignment_date': expiration_date,\n",
        "            'strike': strike,\n",
        "            'shares': 100,\n",
        "            'assigned_price': strike,\n",
        "            'cash_used': strike * 100,\n",
        "            'premium_kept': premium,\n",
        "            'net_stock_cost': (strike * 100) - premium,\n",
        "            'stock_cost_per_share': ((strike * 100) - premium) / 100,\n",
        "            'underlying_at_assignment': underlying_at_exp,\n",
        "            'initial_capital': cost_basis,\n",
        "        }\n",
        "        \n",
        "        # Fetch call chain\n",
        "        underlying_symbol = assignment_record['symbol']\n",
        "        cc_entry_date = pd.Timestamp(expiration_date) + pd.Timedelta(days=1)\n",
        "        \n",
        "        call_chain = fetch_option_chain_for_cc(\n",
        "            underlying_symbol, cc_entry_date, client, config, cc_config\n",
        "        )\n",
        "        \n",
        "        if len(call_chain) > 0:\n",
        "            cc_selection = select_covered_call(assignment_record, call_chain, cc_config, config)\n",
        "            \n",
        "            if cc_selection is not None:\n",
        "                cc_exit_dict, final_cc_state = backtest_covered_call(\n",
        "                    assignment_record, cc_selection, client, config, cc_config\n",
        "                )\n",
        "                cc_exit_dict['execution_version'] = 'v5_scheduler'\n",
        "                wheel_results.append(cc_exit_dict)\n",
        "                cc_exit = cc_exit_dict\n",
        "                current_state = final_cc_state\n",
        "    \n",
        "    # ----- WHEEL TOTAL -----\n",
        "    # Calculate total P&L\n",
        "    total_pnl = csp_pnl\n",
        "    total_days = csp_exit.get('days_held', 0) or 0\n",
        "    cc_pnl = 0.0\n",
        "    stock_pnl = 0.0\n",
        "    \n",
        "    if cc_exit is not None:\n",
        "        cc_premium = cc_exit.get('premium', 0)\n",
        "        cc_exit_price = cc_exit.get('exit_price', 0)\n",
        "        cc_fees = get_transaction_costs(config, is_round_trip=(cc_exit.get('exit_reason') not in ['expired_worthless', 'called_away']))\n",
        "        cc_pnl = cc_premium - cc_exit_price - cc_fees\n",
        "        total_pnl += cc_pnl\n",
        "        total_days += cc_exit.get('days_held', 0) or 0\n",
        "        \n",
        "        # Stock P&L if called away\n",
        "        if cc_exit.get('exit_reason') == 'called_away':\n",
        "            net_stock_cost = (strike * 100) - premium\n",
        "            call_strike = cc_exit.get('strike', strike)\n",
        "            stock_pnl = (call_strike * 100) - net_stock_cost\n",
        "            total_pnl += stock_pnl\n",
        "        \n",
        "        # Advance to complete\n",
        "        if current_state != 'WHEEL_COMPLETE':\n",
        "            current_state = advance_wheel_state(current_state, 'complete')\n",
        "    else:\n",
        "        # No CC - advance CSP to complete\n",
        "        if current_state != 'WHEEL_COMPLETE':\n",
        "            current_state = advance_wheel_state(current_state, 'complete')\n",
        "    \n",
        "    wheel_roc = (total_pnl / cost_basis) * 100\n",
        "    \n",
        "    # Create total record\n",
        "    total_record = {\n",
        "        'wheel_id': wheel_id,\n",
        "        'phase': 'total',\n",
        "        'state': current_state,\n",
        "        'symbol': symbol.split()[0],\n",
        "        'entry_date': entry_date,\n",
        "        'exit_date': cc_exit['exit_date'] if cc_exit else exit_date,\n",
        "        'initial_capital': cost_basis,\n",
        "        'csp_pnl': csp_pnl,\n",
        "        'cc_pnl': cc_pnl,\n",
        "        'stock_pnl': stock_pnl,\n",
        "        'pnl': total_pnl,\n",
        "        'wheel_roc': wheel_roc,\n",
        "        'total_days': total_days,\n",
        "        'csp_exit_reason': csp_exit['exit_reason'],\n",
        "        'cc_exit_reason': cc_exit.get('exit_reason') if cc_exit else None,\n",
        "        'execution_version': 'v5_scheduler',\n",
        "    }\n",
        "    wheel_results.append(total_record)\n",
        "    \n",
        "    if log_info:\n",
        "        print(f\"    TOTAL: ${total_pnl:.2f} ({wheel_roc:.2f}% ROC), {total_days} days\")\n",
        "    \n",
        "    return wheel_results\n",
        "\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"SINGLE WHEEL WRAPPER LOADED\")\n",
        "print(\"=\" * 60)\n",
        "print(\"  run_single_wheel(candidate, config, cc_config, wheel_id, client)\")\n",
        "print(\"  Returns List[dict] of exit records for one wheel cycle\")\n",
        "print(\"=\" * 60)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "a5d5d569",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "V5 SCHEDULER LOADED\n",
            "============================================================\n",
            "  run_v5_scheduler(config, cc_config, scheduler_config, client)\n",
            "  Iterates over trading days × symbols, returns combined results\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# V5 SCHEDULER - MAIN ORCHESTRATION LOOP\n",
        "# =============================================================================\n",
        "\n",
        "def run_v5_scheduler(config, cc_config, scheduler_config, client):\n",
        "    \"\"\"\n",
        "    Main V5 scheduler: iterate over trading days and symbols, launching wheels.\n",
        "    \n",
        "    For each trading day in the date range:\n",
        "        For each symbol in the symbol list:\n",
        "            1. Get entry candidates meeting all criteria\n",
        "            2. Launch a wheel for each qualifying candidate\n",
        "            3. Collect results\n",
        "    \n",
        "    Args:\n",
        "        config: CONFIG dict (frozen - not mutated)\n",
        "        cc_config: CC_CONFIG dict (frozen - not mutated)\n",
        "        scheduler_config: SCHEDULER_CONFIG dict with date range and symbols\n",
        "        client: Databento client\n",
        "    \n",
        "    Returns:\n",
        "        DataFrame with all wheel exit records\n",
        "    \"\"\"\n",
        "    from copy import deepcopy\n",
        "    \n",
        "    all_wheel_results = []\n",
        "    wheel_counter = 0\n",
        "    log_info = scheduler_config.get('log_level', 'INFO') == 'INFO'\n",
        "    \n",
        "    # Get trading days\n",
        "    trading_days = get_trading_days(\n",
        "        scheduler_config['start_date'],\n",
        "        scheduler_config['end_date'],\n",
        "        scheduler_config['trading_calendar'],\n",
        "    )\n",
        "    \n",
        "    if log_info:\n",
        "        print(\"=\" * 60)\n",
        "        print(\"V5 SCHEDULER STARTING\")\n",
        "        print(\"=\" * 60)\n",
        "        print(f\"Date range: {scheduler_config['start_date']} to {scheduler_config['end_date']}\")\n",
        "        print(f\"Trading days: {len(trading_days)}\")\n",
        "        print(f\"Symbols: {scheduler_config['symbols']}\")\n",
        "        print(\"=\" * 60)\n",
        "    \n",
        "    # Main loop: dates × symbols\n",
        "    for trade_date in trading_days:\n",
        "        for symbol in scheduler_config['symbols']:\n",
        "            # Deep copy config to avoid mutation\n",
        "            config_day = deepcopy(config)\n",
        "            config_day['symbol'] = symbol\n",
        "            config_day['entry_date'] = trade_date.strftime('%Y-%m-%d')\n",
        "            \n",
        "            # Get entry candidates\n",
        "            entry_candidates = get_entry_candidates(symbol, trade_date, config_day, client)\n",
        "            \n",
        "            if len(entry_candidates) == 0:\n",
        "                continue\n",
        "            \n",
        "            if log_info:\n",
        "                print(f\"\\n[{trade_date.date()}] {symbol}: {len(entry_candidates)} candidates\")\n",
        "            \n",
        "            # Apply max wheels per day limit if configured\n",
        "            max_wheels = scheduler_config.get('max_wheels_per_symbol_per_day')\n",
        "            if max_wheels is not None:\n",
        "                entry_candidates = entry_candidates.head(max_wheels)\n",
        "            \n",
        "            # Launch wheel for each candidate\n",
        "            for idx, candidate in entry_candidates.iterrows():\n",
        "                wheel_id = f\"{symbol}_{trade_date.date()}_{wheel_counter}\"\n",
        "                wheel_counter += 1\n",
        "                \n",
        "                wheel_results = run_single_wheel(\n",
        "                    candidate=candidate,\n",
        "                    config=config_day,\n",
        "                    cc_config=cc_config,\n",
        "                    wheel_id=wheel_id,\n",
        "                    client=client,\n",
        "                    log_info=log_info,\n",
        "                )\n",
        "                all_wheel_results.extend(wheel_results)\n",
        "    \n",
        "    if log_info:\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"SCHEDULER COMPLETE: {wheel_counter} wheels launched\")\n",
        "        print(f\"{'='*60}\")\n",
        "    \n",
        "    # Handle empty results case\n",
        "    if len(all_wheel_results) == 0:\n",
        "        return pd.DataFrame()\n",
        "    \n",
        "    # Combine all results into DataFrame\n",
        "    results_df = pd.DataFrame(all_wheel_results)\n",
        "    \n",
        "    return results_df\n",
        "\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"V5 SCHEDULER LOADED\")\n",
        "print(\"=\" * 60)\n",
        "print(\"  run_v5_scheduler(config, cc_config, scheduler_config, client)\")\n",
        "print(\"  Iterates over trading days × symbols, returns combined results\")\n",
        "print(\"=\" * 60)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "5c683a00",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "V5 AGGREGATION FUNCTIONS LOADED\n",
            "============================================================\n",
            "  aggregate_v5_results(df) - Returns summary statistics dict\n",
            "  display_v5_summary(df) - Prints formatted summary\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# V5 AGGREGATION FUNCTIONS\n",
        "# =============================================================================\n",
        "\n",
        "def aggregate_v5_results(df):\n",
        "    \"\"\"\n",
        "    Aggregate V5 scheduler results into summary statistics.\n",
        "    \n",
        "    Focuses on 'total' phase records which contain wheel-level P&L.\n",
        "    \n",
        "    Args:\n",
        "        df: DataFrame from run_v5_scheduler()\n",
        "    \n",
        "    Returns:\n",
        "        dict with aggregate statistics\n",
        "    \"\"\"\n",
        "    if len(df) == 0:\n",
        "        return {\n",
        "            'total_wheels': 0,\n",
        "            'total_pnl': 0.0,\n",
        "            'avg_wheel_roc': 0.0,\n",
        "            'median_wheel_roc': 0.0,\n",
        "            'max_drawdown_proxy': 0.0,\n",
        "            'win_rate': 0.0,\n",
        "        }\n",
        "    \n",
        "    # Filter to wheel totals only\n",
        "    totals = df[df['phase'] == 'total'].copy()\n",
        "    \n",
        "    if len(totals) == 0:\n",
        "        return {\n",
        "            'total_wheels': 0,\n",
        "            'total_pnl': 0.0,\n",
        "            'avg_wheel_roc': 0.0,\n",
        "            'median_wheel_roc': 0.0,\n",
        "            'max_drawdown_proxy': 0.0,\n",
        "            'win_rate': 0.0,\n",
        "        }\n",
        "    \n",
        "    return {\n",
        "        'total_wheels': totals['wheel_id'].nunique(),\n",
        "        'total_pnl': totals['pnl'].sum(),\n",
        "        'avg_wheel_roc': totals['wheel_roc'].mean(),\n",
        "        'median_wheel_roc': totals['wheel_roc'].median(),\n",
        "        'std_wheel_roc': totals['wheel_roc'].std(),\n",
        "        'max_wheel_roc': totals['wheel_roc'].max(),\n",
        "        'min_wheel_roc': totals['wheel_roc'].min(),\n",
        "        'max_drawdown_proxy': totals['pnl'].min(),\n",
        "        'win_rate': (totals['pnl'] > 0).mean() * 100,\n",
        "        'avg_days_held': totals['total_days'].mean(),\n",
        "        'total_capital_deployed': totals['initial_capital'].sum(),\n",
        "    }\n",
        "\n",
        "\n",
        "def display_v5_summary(df):\n",
        "    \"\"\"\n",
        "    Display formatted summary of V5 backtest results.\n",
        "    \n",
        "    Args:\n",
        "        df: DataFrame from run_v5_scheduler()\n",
        "    \"\"\"\n",
        "    stats = aggregate_v5_results(df)\n",
        "    \n",
        "    print(\"=\" * 60)\n",
        "    print(\"V5 SCHEDULER BACKTEST SUMMARY\")\n",
        "    print(\"=\" * 60)\n",
        "    print(f\"Total Wheels:      {stats['total_wheels']}\")\n",
        "    print(f\"Total P&L:         ${stats['total_pnl']:,.2f}\")\n",
        "    print(f\"Win Rate:          {stats['win_rate']:.1f}%\")\n",
        "    print(\"-\" * 40)\n",
        "    print(f\"Avg Wheel ROC:     {stats['avg_wheel_roc']:.2f}%\")\n",
        "    print(f\"Median Wheel ROC:  {stats['median_wheel_roc']:.2f}%\")\n",
        "    print(f\"Std Wheel ROC:     {stats.get('std_wheel_roc', 0):.2f}%\")\n",
        "    print(f\"Best Wheel ROC:    {stats.get('max_wheel_roc', 0):.2f}%\")\n",
        "    print(f\"Worst Wheel ROC:   {stats.get('min_wheel_roc', 0):.2f}%\")\n",
        "    print(\"-\" * 40)\n",
        "    print(f\"Avg Days Held:     {stats.get('avg_days_held', 0):.1f}\")\n",
        "    print(f\"Total Capital:     ${stats.get('total_capital_deployed', 0):,.2f}\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    # Phase breakdown\n",
        "    if len(df) > 0:\n",
        "        print(\"\\nPhase Breakdown:\")\n",
        "        print(df['phase'].value_counts())\n",
        "        \n",
        "        print(\"\\nExit Reason Breakdown (CSP phase):\")\n",
        "        csp_df = df[df['phase'] == 'csp']\n",
        "        if len(csp_df) > 0:\n",
        "            print(csp_df['exit_reason'].value_counts())\n",
        "    \n",
        "    return stats\n",
        "\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"V5 AGGREGATION FUNCTIONS LOADED\")\n",
        "print(\"=\" * 60)\n",
        "print(\"  aggregate_v5_results(df) - Returns summary statistics dict\")\n",
        "print(\"  display_v5_summary(df) - Prints formatted summary\")\n",
        "print(\"=\" * 60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a12c3971",
      "metadata": {},
      "source": [
        "## Run V5 Scheduler\n",
        "\n",
        "Execute the scheduler across the configured date range and symbols.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "bcc809fc",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "V5 SCHEDULER STARTING\n",
            "============================================================\n",
            "Date range: 2023-06-06 to 2023-09-13\n",
            "Trading days: 69\n",
            "Symbols: ['TSLA']\n",
            "============================================================\n",
            "\n",
            "  Liquidity Model Applied:\n",
            "    Original: 7 options\n",
            "    Hard rejected: 0 (0.0%)\n",
            "    Remaining: 7 options\n",
            "    Tier breakdown: {'tight': np.int64(7)}\n",
            "    Avg spread: 2.7%, Avg allowed: 10.1%\n",
            "    Avg penalty: 1.00x\n",
            "\n",
            "[2023-06-06] TSLA: 7 candidates\n",
            "\n",
            "  Wheel TSLA_2023-06-06_0: TSLA  230707P00205000\n",
            "    Entry: 2023-06-06, Strike: $205.00, Premium: $634.00\n",
            "    ✗ CSP Error: name 'fetch_daily_prices_for_option' is not defined\n"
          ]
        },
        {
          "ename": "UnboundLocalError",
          "evalue": "cannot access local variable 'touch_profit_target' where it is not associated with a value",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mUnboundLocalError\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# =============================================================================\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# RUN V5 SCHEDULER\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# =============================================================================\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Execute the multi-date, multi-symbol backtest\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m v5_results = \u001b[43mrun_v5_scheduler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mCONFIG\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcc_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mCC_CONFIG\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mscheduler_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mSCHEDULER_CONFIG\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclient\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# Display summary\u001b[39;00m\n\u001b[32m     14\u001b[39m v5_stats = display_v5_summary(v5_results)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 73\u001b[39m, in \u001b[36mrun_v5_scheduler\u001b[39m\u001b[34m(config, cc_config, scheduler_config, client)\u001b[39m\n\u001b[32m     70\u001b[39m             wheel_id = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msymbol\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrade_date.date()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwheel_counter\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     71\u001b[39m             wheel_counter += \u001b[32m1\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m             wheel_results = \u001b[43mrun_single_wheel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m                \u001b[49m\u001b[43mcandidate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcandidate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[43m                \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig_day\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     76\u001b[39m \u001b[43m                \u001b[49m\u001b[43mcc_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcc_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[43m                \u001b[49m\u001b[43mwheel_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwheel_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     78\u001b[39m \u001b[43m                \u001b[49m\u001b[43mclient\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     79\u001b[39m \u001b[43m                \u001b[49m\u001b[43mlog_info\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlog_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     80\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     81\u001b[39m             all_wheel_results.extend(wheel_results)\n\u001b[32m     83\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m log_info:\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 179\u001b[39m, in \u001b[36mrun_single_wheel\u001b[39m\u001b[34m(candidate, config, cc_config, wheel_id, client, log_info)\u001b[39m\n\u001b[32m    157\u001b[39m csp_roc = (csp_pnl / cost_basis) * \u001b[32m100\u001b[39m\n\u001b[32m    159\u001b[39m \u001b[38;5;66;03m# Create CSP exit record\u001b[39;00m\n\u001b[32m    160\u001b[39m csp_exit = {\n\u001b[32m    161\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mwheel_id\u001b[39m\u001b[33m'\u001b[39m: wheel_id,\n\u001b[32m    162\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mphase\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mcsp\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    163\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mstate\u001b[39m\u001b[33m'\u001b[39m: current_state,\n\u001b[32m    164\u001b[39m     \u001b[33m'\u001b[39m\u001b[33msymbol\u001b[39m\u001b[33m'\u001b[39m: symbol,\n\u001b[32m    165\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mstrike\u001b[39m\u001b[33m'\u001b[39m: strike,\n\u001b[32m    166\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mentry_date\u001b[39m\u001b[33m'\u001b[39m: entry_date,\n\u001b[32m    167\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mexit_date\u001b[39m\u001b[33m'\u001b[39m: exit_date,\n\u001b[32m    168\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mexpiration\u001b[39m\u001b[33m'\u001b[39m: expiration_date,\n\u001b[32m    169\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mcost_basis\u001b[39m\u001b[33m'\u001b[39m: cost_basis,\n\u001b[32m    170\u001b[39m     \u001b[33m'\u001b[39m\u001b[33minitial_capital\u001b[39m\u001b[33m'\u001b[39m: cost_basis,\n\u001b[32m    171\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mpremium\u001b[39m\u001b[33m'\u001b[39m: premium,\n\u001b[32m    172\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mexit_pct\u001b[39m\u001b[33m'\u001b[39m: exit_pct,\n\u001b[32m    173\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mexit_price\u001b[39m\u001b[33m'\u001b[39m: exit_price,\n\u001b[32m    174\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mexit_reason\u001b[39m\u001b[33m'\u001b[39m: exit_reason,\n\u001b[32m    175\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mdays_held\u001b[39m\u001b[33m'\u001b[39m: (exit_date - entry_date).days \u001b[38;5;28;01mif\u001b[39;00m exit_date \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    176\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mpnl\u001b[39m\u001b[33m'\u001b[39m: csp_pnl,\n\u001b[32m    177\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mroc\u001b[39m\u001b[33m'\u001b[39m: csp_roc,\n\u001b[32m    178\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mfees\u001b[39m\u001b[33m'\u001b[39m: csp_fees,\n\u001b[32m--> \u001b[39m\u001b[32m179\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mtouch_profit_target\u001b[39m\u001b[33m'\u001b[39m: \u001b[43mtouch_profit_target\u001b[49m,\n\u001b[32m    180\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mp_fill_profit_target\u001b[39m\u001b[33m'\u001b[39m: p_fill_profit,\n\u001b[32m    181\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mu_fill_profit_target\u001b[39m\u001b[33m'\u001b[39m: u_fill_profit,\n\u001b[32m    182\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mfilled_profit_target\u001b[39m\u001b[33m'\u001b[39m: filled_profit_target,\n\u001b[32m    183\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mtouch_count\u001b[39m\u001b[33m'\u001b[39m: touch_count,\n\u001b[32m    184\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mspread_pct_entry\u001b[39m\u001b[33m'\u001b[39m: spread_pct_entry,\n\u001b[32m    185\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mivp_entry\u001b[39m\u001b[33m'\u001b[39m: ivp_entry,\n\u001b[32m    186\u001b[39m     \u001b[33m'\u001b[39m\u001b[33munderlying_at_expiration\u001b[39m\u001b[33m'\u001b[39m: underlying_at_exp,\n\u001b[32m    187\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mexecution_version\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mv5_scheduler\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    188\u001b[39m }\n\u001b[32m    189\u001b[39m wheel_results.append(csp_exit)\n\u001b[32m    191\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m log_info:\n",
            "\u001b[31mUnboundLocalError\u001b[39m: cannot access local variable 'touch_profit_target' where it is not associated with a value"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# RUN V5 SCHEDULER\n",
        "# =============================================================================\n",
        "# Execute the multi-date, multi-symbol backtest\n",
        "\n",
        "v5_results = run_v5_scheduler(\n",
        "    config=CONFIG,\n",
        "    cc_config=CC_CONFIG,\n",
        "    scheduler_config=SCHEDULER_CONFIG,\n",
        "    client=client,\n",
        ")\n",
        "\n",
        "# Display summary\n",
        "v5_stats = display_v5_summary(v5_results)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89e69ec8",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "DATA MODEL VALIDATION\n",
            "============================================================\n",
            "✓ Every wheel_id has at least one phase\n",
            "✓ All required fields present: ['wheel_id', 'phase', 'state', 'entry_date', 'exit_reason', 'pnl', 'execution_version']\n",
            "✓ Execution version is consistent (v5_scheduler)\n",
            "✓ Exactly one 'total' row per wheel_id\n",
            "✓ All wheels have required phases (csp, total)\n",
            "============================================================\n",
            "ALL VALIDATIONS PASSED\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# DATA MODEL VALIDATION (V5)\n",
        "# =============================================================================\n",
        "# Assert data integrity after scheduler run\n",
        "\n",
        "def validate_v5_results(df):\n",
        "    \"\"\"\n",
        "    Validate V5 results DataFrame for data integrity.\n",
        "    \n",
        "    Assertions:\n",
        "    1. Every wheel_id has at least one phase\n",
        "    2. Required fields present\n",
        "    3. Execution version is consistent\n",
        "    4. Exactly one 'total' row per wheel_id\n",
        "    \n",
        "    Args:\n",
        "        df: DataFrame from run_v5_scheduler()\n",
        "    \n",
        "    Raises:\n",
        "        AssertionError if validation fails\n",
        "    \"\"\"\n",
        "    if len(df) == 0:\n",
        "        print(\"⚠ No results to validate (empty DataFrame)\")\n",
        "        return\n",
        "    \n",
        "    print(\"=\" * 60)\n",
        "    print(\"DATA MODEL VALIDATION\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    # 1. Every wheel_id must have at least one phase\n",
        "    phase_counts = df.groupby('wheel_id')['phase'].nunique()\n",
        "    assert phase_counts.ge(1).all(), \"Some wheel_ids have no phases\"\n",
        "    print(\"✓ Every wheel_id has at least one phase\")\n",
        "    \n",
        "    # 2. Required fields present\n",
        "    required_fields = [\n",
        "        'wheel_id', 'phase', 'state', 'entry_date', 'exit_reason', \n",
        "        'pnl', 'execution_version'\n",
        "    ]\n",
        "    missing = [col for col in required_fields if col not in df.columns]\n",
        "    assert len(missing) == 0, f\"Missing required fields: {missing}\"\n",
        "    print(f\"✓ All required fields present: {required_fields}\")\n",
        "    \n",
        "    # 3. Verify execution version is consistent\n",
        "    assert (df['execution_version'] == 'v5_scheduler').all(), \\\n",
        "        \"Inconsistent execution_version values\"\n",
        "    print(\"✓ Execution version is consistent (v5_scheduler)\")\n",
        "    \n",
        "    # 4. Ensure exactly one 'total' row per wheel_id\n",
        "    totals = df[df['phase'] == 'total']\n",
        "    assert totals['wheel_id'].is_unique, \\\n",
        "        \"Duplicate 'total' rows detected for same wheel_id\"\n",
        "    print(\"✓ Exactly one 'total' row per wheel_id\")\n",
        "    \n",
        "    # 5. Phase consistency check\n",
        "    wheel_ids = df['wheel_id'].unique()\n",
        "    for wid in wheel_ids:\n",
        "        wheel_df = df[df['wheel_id'] == wid]\n",
        "        phases = set(wheel_df['phase'].unique())\n",
        "        \n",
        "        # Every wheel must have 'csp' and 'total'\n",
        "        assert 'csp' in phases, f\"Wheel {wid} missing CSP phase\"\n",
        "        assert 'total' in phases, f\"Wheel {wid} missing total phase\"\n",
        "    print(\"✓ All wheels have required phases (csp, total)\")\n",
        "    \n",
        "    print(\"=\" * 60)\n",
        "    print(\"ALL VALIDATIONS PASSED\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "\n",
        "# Run validation\n",
        "validate_v5_results(v5_results)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "id": "9f88c0c3",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "V5 ALL EXIT RECORDS\n",
            "============================================================\n",
            "Total records: 754\n",
            "\n",
            "Phase breakdown:\n",
            "phase\n",
            "csp      377\n",
            "total    377\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Sample records:\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# V5 RESULTS EXPLORATION\n",
        "# =============================================================================\n",
        "\n",
        "# Configure pandas display\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.width', None)\n",
        "pd.set_option('display.max_colwidth', 50)\n",
        "\n",
        "# Display all results\n",
        "print(\"=\" * 60)\n",
        "print(\"V5 ALL EXIT RECORDS\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Total records: {len(v5_results)}\")\n",
        "\n",
        "if len(v5_results) > 0:\n",
        "    # Show phase breakdown\n",
        "    print(f\"\\nPhase breakdown:\")\n",
        "    print(v5_results['phase'].value_counts())\n",
        "    \n",
        "    # Show key columns for all records\n",
        "    display_cols = ['wheel_id', 'phase', 'state', 'symbol', 'entry_date', 'exit_date', \n",
        "                    'pnl', 'exit_reason', 'execution_version']\n",
        "    available_cols = [c for c in display_cols if c in v5_results.columns]\n",
        "    \n",
        "    print(\"\\nSample records:\")\n",
        "    v5_results[available_cols].head(15)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "id": "e8619c96",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "WHEEL TOTALS (one row per wheel)\n",
            "============================================================\n",
            "Total wheels: 377\n",
            "\n",
            "P&L Statistics:\n",
            "count     377.000000\n",
            "mean      -69.187546\n",
            "std       687.523007\n",
            "min     -1716.320000\n",
            "25%      -795.320000\n",
            "50%       348.680000\n",
            "75%       486.680000\n",
            "max       935.380000\n",
            "Name: pnl, dtype: float64\n",
            "\n",
            "ROC Statistics:\n",
            "count    377.000000\n",
            "mean      -0.220194\n",
            "std        2.817519\n",
            "min       -6.241164\n",
            "25%       -3.267429\n",
            "50%        1.515512\n",
            "75%        2.051070\n",
            "max        3.890333\n",
            "Name: wheel_roc, dtype: float64\n",
            "\n",
            "Exit Reason Breakdown:\n",
            "csp_exit_reason\n",
            "profit_target    223\n",
            "stop_loss        154\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Top 5 Performers:\n",
            "               wheel_id symbol entry_date     pnl  wheel_roc csp_exit_reason\n",
            "95   TSLA_2023-06-15_47   TSLA 2023-06-15  933.68   3.890333   profit_target\n",
            "63   TSLA_2023-06-13_31   TSLA 2023-06-13  935.38   3.817878   profit_target\n",
            "83   TSLA_2023-06-14_41   TSLA 2023-06-14  906.78   3.778250   profit_target\n",
            "107  TSLA_2023-06-16_53   TSLA 2023-06-16  878.18   3.584408   profit_target\n",
            "93   TSLA_2023-06-15_46   TSLA 2023-06-15  830.98   3.536085   profit_target\n",
            "\n",
            "Bottom 5 Performers:\n",
            "                wheel_id symbol entry_date      pnl  wheel_roc csp_exit_reason\n",
            "317  TSLA_2023-07-17_158   TSLA 2023-07-17 -1716.32  -6.241164       stop_loss\n",
            "349  TSLA_2023-07-19_174   TSLA 2023-07-19 -1520.32  -5.630815       stop_loss\n",
            "315  TSLA_2023-07-17_157   TSLA 2023-07-17 -1408.32  -5.216000       stop_loss\n",
            "359  TSLA_2023-07-20_179   TSLA 2023-07-20 -1302.32  -5.209280       stop_loss\n",
            "351  TSLA_2023-07-19_175   TSLA 2023-07-19 -1390.32  -5.055709       stop_loss\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# V5 WHEEL TOTALS ANALYSIS\n",
        "# =============================================================================\n",
        "\n",
        "if len(v5_results) > 0:\n",
        "    # Filter to totals only for wheel-level analysis\n",
        "    totals = v5_results[v5_results['phase'] == 'total'].copy()\n",
        "    \n",
        "    print(\"=\" * 60)\n",
        "    print(\"WHEEL TOTALS (one row per wheel)\")\n",
        "    print(\"=\" * 60)\n",
        "    print(f\"Total wheels: {len(totals)}\")\n",
        "    \n",
        "    # Summary statistics\n",
        "    print(f\"\\nP&L Statistics:\")\n",
        "    print(totals['pnl'].describe())\n",
        "    \n",
        "    print(f\"\\nROC Statistics:\")\n",
        "    print(totals['wheel_roc'].describe())\n",
        "    \n",
        "    print(f\"\\nExit Reason Breakdown:\")\n",
        "    print(totals['csp_exit_reason'].value_counts())\n",
        "    \n",
        "    # Show top and bottom performers\n",
        "    print(f\"\\nTop 5 Performers:\")\n",
        "    print(totals.nlargest(5, 'wheel_roc')[['wheel_id', 'symbol', 'entry_date', 'pnl', 'wheel_roc', 'csp_exit_reason']])\n",
        "    \n",
        "    print(f\"\\nBottom 5 Performers:\")\n",
        "    print(totals.nsmallest(5, 'wheel_roc')[['wheel_id', 'symbol', 'entry_date', 'pnl', 'wheel_roc', 'csp_exit_reason']])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "id": "357cbc0b",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "exit_reason\n",
              "profit_target    223\n",
              "stop_loss        154\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 103,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# We need to save backtest results with metadata as our strategy evolves\n",
        "# exists_df should contain option data such as delta at entry, peak delta, maybe other information that would be helpful for analysis\n",
        "\n",
        "# \n",
        "v5_results['daily_adjusted_roc'] = v5_results['csp_pnl']/v5_results['cost_basis']\n",
        "v5_results['daily_adjusted_roc'].describe()\n",
        "v5_results['days_held'].describe()\n",
        "v5_results['exit_reason'].value_counts()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "318c9393",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.14.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
