{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "edd518bc",
   "metadata": {},
   "source": [
    "# Wheel Strategy v4: CSP Assignment → Covered Call Module\n",
    "\n",
    "This notebook extends the CSP backtest to handle the full wheel cycle:\n",
    "1. Sell Cash-Secured Put (CSP)\n",
    "2. If assigned (expires ITM): take stock delivery\n",
    "3. Sell Covered Call (CC) against assigned shares\n",
    "4. If called away (CC expires ITM): wheel complete\n",
    "\n",
    "## Key Features\n",
    "- **State Machine Architecture**: Explicit trade lifecycle states prevent logic spaghetti\n",
    "- **Unified P&L Accounting**: CSP + CC + Stock P&L properly aggregated\n",
    "- **v1 Scope**: One CC cycle per assignment (no rolling, no early assignment)\n",
    "\n",
    "## Trade States\n",
    "```\n",
    "CSP_OPEN → CSP_CLOSED_PROFIT | CSP_CLOSED_STOP | CSP_ASSIGNED | CSP_CLOSED_WORTHLESS\n",
    "CSP_ASSIGNED → CC_OPEN\n",
    "CC_OPEN → CC_CLOSED_PROFIT | CC_ASSIGNED | CC_CLOSED_WORTHLESS\n",
    "All terminal states → WHEEL_COMPLETE\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e2470d",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "875507cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed keys: odict_keys(['DATABENTO_API_KEY', 'ANTHROPIC_API_KEY'])\n",
      "os.getenv: True\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from dotenv import dotenv_values, load_dotenv\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import databento as db\n",
    "import pandas_market_calendars as mcal\n",
    "\n",
    "sys.executable\n",
    "\n",
    "env_path = Path(\"/Users/samuelminer/Projects/nissan_options/wheel_strategy/.env\")\n",
    "\n",
    "print(\"Parsed keys:\", dotenv_values(env_path).keys())\n",
    "\n",
    "load_dotenv()  # loads .env from current working directory\n",
    "\n",
    "assert os.getenv(\"DATABENTO_API_KEY\"), \"DATABENTO_API_KEY still not found\"\n",
    "print(\"os.getenv:\", bool(os.getenv(\"DATABENTO_API_KEY\")))\n",
    "client = db.Historical()\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "config_header",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "All configurable parameters for the backtest. Modify this cell to change settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "config_cell",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "BACKTEST CONFIGURATION\n",
      "============================================================\n",
      "Symbol:          TSLA\n",
      "Entry Date:      2023-06-06\n",
      "Entry Time:      15:45\n",
      "Option Type:     Cash-Secured Put\n",
      "DTE Range:       30 - 45 days\n",
      "Delta Range:     0.25 - 0.35\n",
      "Exit Target:     50% of premium\n",
      "Stop Loss:       20.0x premium\n",
      "Fill Mode:       mid\n",
      "Realistic Fills: False\n",
      "Commission:      $0.65/contract\n",
      "============================================================\n",
      "\n",
      "NOTE: Transaction costs and realistic fills are NOT yet applied.\n",
      "      Run both notebooks to compare baseline vs realistic results.\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# UNIFIED CONFIGURATION\n",
    "# =============================================================================\n",
    "\n",
    "CONFIG = {\n",
    "    # -------------------------------------------------------------------------\n",
    "    # SYMBOL & TIMING\n",
    "    # -------------------------------------------------------------------------\n",
    "    'symbol': 'TSLA',                          # Underlying symbol to backtest\n",
    "    'timezone': 'America/New_York',\n",
    "    \n",
    "    # Entry date/time for the single-day backtest\n",
    "    'entry_date': '2023-06-06',                # Date to enter positions\n",
    "    'entry_time': '15:45',                     # Time to capture option chain snapshot\n",
    "    \n",
    "    # Historical data lookback for technical indicators (e.g., Bollinger Bands)\n",
    "    'lookback_days': 252 * 2,                  # ~2 years of daily data\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # OPTION SELECTION CRITERIA\n",
    "    # -------------------------------------------------------------------------\n",
    "    'option_type': 'P',                        # 'P' for puts (CSP), 'C' for calls\n",
    "    'dte_min': 30,                             # Minimum days to expiration\n",
    "    'dte_max': 45,                             # Maximum days to expiration\n",
    "    'delta_min': 0.25,                         # Minimum absolute delta\n",
    "    'delta_max': 0.35,                         # Maximum absolute delta\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # LIQUIDITY MODEL (regime-aware, penalty-based)\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Hard rejection thresholds (truly untradeable)\n",
    "    'min_bid_hard': 0.10,                      # Hard floor - reject penny options\n",
    "    'hard_max_spread_pct': 0.20,               # Hard ceiling - reject extreme spreads\n",
    "    \n",
    "    # Base target spread (calm market conditions)\n",
    "    'base_max_spread_pct': 0.08,               # Target max spread in normal conditions\n",
    "    \n",
    "    # IV regime adjustments (allow wider spreads in high-vol)\n",
    "    'ivp_high_threshold': 0.70,                # IV percentile threshold for \"high vol\"\n",
    "    'ivp_high_max_spread_pct': 0.12,           # Allowed spread when IV is high\n",
    "    'ivp_extreme_threshold': 0.90,             # IV percentile threshold for \"extreme vol\"\n",
    "    'ivp_extreme_max_spread_pct': 0.15,        # Allowed spread when IV is extreme\n",
    "    \n",
    "    # DTE adjustments (short-dated options have wider spreads)\n",
    "    'short_dte_threshold': 7,                  # DTE below this gets extra allowance\n",
    "    'short_dte_extra_spread_pct': 0.02,        # Extra spread allowance for short DTE\n",
    "    \n",
    "    # Penalty tiers (execution tax based on spread quality)\n",
    "    # tight:    spread <= 0.6 * allowed → penalty = 1.0 (no extra slippage)\n",
    "    # moderate: spread <= allowed       → penalty = 1.15 (15% wider effective spread)\n",
    "    # wide:     spread <= hard_max      → penalty = 1.35 (35% wider effective spread)\n",
    "    # ugly:     spread > hard_max       → REJECT (no trade)\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # EXIT STRATEGY\n",
    "    # -------------------------------------------------------------------------\n",
    "    'exit_pct': 0.50,                          # 0.50 = buy back at 50%, keep 50% profit\n",
    "    'stop_loss_multiplier': 20.0,               # Exit if option price reaches Nx premium\n",
    "    'max_hold_dte': None,                      # Exit at X DTE if no other trigger (None = disabled)\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # TRANSACTION COSTS (NEW - will be applied later)\n",
    "    # -------------------------------------------------------------------------\n",
    "    'commission_per_contract': 0.65,           # Per contract commission (round trip = 2x)\n",
    "    'sec_fee_per_contract': 0.01,              # SEC/TAF fees per contract\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # EXECUTION / FILL ASSUMPTIONS (NEW - will be applied later)\n",
    "    # -------------------------------------------------------------------------\n",
    "    'fill_mode': 'mid',                        # 'mid' (current), 'bid' (realistic), 'pessimistic'\n",
    "    'use_realistic_fills': False,              # When True: sell at bid, buy back at ask\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # PROBABILISTIC EXIT FILLS\n",
    "    # -------------------------------------------------------------------------\n",
    "    'execution_seed': 42,                      # Random seed for reproducible fills\n",
    "    'use_probabilistic_exit_fills': True,      # Enable probabilistic fill model\n",
    "    \n",
    "    # Fill probability buckets by spread quality\n",
    "    'pfill_tight': 0.90,                       # spread <= 5%\n",
    "    'pfill_normal': 0.70,                      # spread <= 10%\n",
    "    'pfill_wide': 0.40,                        # spread > 10%\n",
    "    \n",
    "    # Spread thresholds for buckets\n",
    "    'tight_spread_pct': 0.05,\n",
    "    'normal_spread_pct': 0.10,\n",
    "    \n",
    "    # Scaling and clamping\n",
    "    'pfill_scale': 0.6,                        # Sensitivity multiplier (0.8, 1.0, 1.2)\n",
    "    'pfill_min': 0.05,\n",
    "    'pfill_max': 0.98,\n",
    "    \n",
    "    # Optional IVP penalty multipliers\n",
    "    'pfill_ivp_high_mult': 0.85,\n",
    "    'pfill_ivp_extreme_mult': 0.70,\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # CACHE\n",
    "    # -------------------------------------------------------------------------\n",
    "    'cache_dir': '../cache/',\n",
    "}\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# DERIVED VALUES (computed from CONFIG)\n",
    "# -------------------------------------------------------------------------\n",
    "SYMBOL = CONFIG['symbol']\n",
    "TZ = CONFIG['timezone']\n",
    "CACHE_DIR = CONFIG['cache_dir']\n",
    "os.makedirs(CACHE_DIR, exist_ok=True)\n",
    "\n",
    "# Entry timestamp\n",
    "ENTRY_DATE = pd.Timestamp(CONFIG['entry_date'], tz=TZ)\n",
    "ENTRY_TIME = pd.Timestamp(f\"{CONFIG['entry_date']} {CONFIG['entry_time']}\", tz=TZ)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"BACKTEST CONFIGURATION\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Symbol:          {SYMBOL}\")\n",
    "print(f\"Entry Date:      {ENTRY_DATE.date()}\")\n",
    "print(f\"Entry Time:      {CONFIG['entry_time']}\")\n",
    "print(f\"Option Type:     {'Cash-Secured Put' if CONFIG['option_type'] == 'P' else 'Covered Call'}\")\n",
    "print(f\"DTE Range:       {CONFIG['dte_min']} - {CONFIG['dte_max']} days\")\n",
    "print(f\"Delta Range:     {CONFIG['delta_min']} - {CONFIG['delta_max']}\")\n",
    "print(f\"Exit Target:     {CONFIG['exit_pct']*100:.0f}% of premium\")\n",
    "print(f\"Stop Loss:       {CONFIG['stop_loss_multiplier']}x premium\")\n",
    "print(f\"Fill Mode:       {CONFIG['fill_mode']}\")\n",
    "print(f\"Realistic Fills: {CONFIG['use_realistic_fills']}\")\n",
    "print(f\"Commission:      ${CONFIG['commission_per_contract']}/contract\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nNOTE: Transaction costs and realistic fills are NOT yet applied.\")\n",
    "print(\"      Run both notebooks to compare baseline vs realistic results.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0385e192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "COVERED CALL CONFIGURATION\n",
      "============================================================\n",
      "DTE Range:       14 - 30 days\n",
      "Delta Range:     0.25 - 0.35\n",
      "Entry Time:      15:45\n",
      "Strike >= Basis: True\n",
      "Tie-Breaking:    highest_premium\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# COVERED CALL CONFIGURATION\n",
    "# =============================================================================\n",
    "\n",
    "CC_CONFIG = {\n",
    "    # -------------------------------------------------------------------------\n",
    "    # OPTION SELECTION CRITERIA\n",
    "    # -------------------------------------------------------------------------\n",
    "    'dte_min': 14,                             # Minimum days to expiration\n",
    "    'dte_max': 30,                             # Maximum days to expiration\n",
    "    'delta_min': 0.25,                         # Minimum absolute delta\n",
    "    'delta_max': 0.35,                         # Maximum absolute delta\n",
    "    'strike_min_pct_above_basis': 0.0,         # Allow ATM (0% above cost basis)\n",
    "    'entry_time': '15:45',                     # Same snapshot time as CSP\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # BEHAVIORAL FLAGS (explicit intent documentation)\n",
    "    # -------------------------------------------------------------------------\n",
    "    'sell_call_only_if_price_above_basis': True,  # Require strike >= cost basis per share\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # TIE-BREAKING FOR CALL SELECTION\n",
    "    # -------------------------------------------------------------------------\n",
    "    # When multiple candidates match criteria, how to select:\n",
    "    # Options: 'highest_premium', 'closest_delta', 'highest_strike'\n",
    "    'tie_break_method': 'highest_premium',\n",
    "}\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"COVERED CALL CONFIGURATION\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"DTE Range:       {CC_CONFIG['dte_min']} - {CC_CONFIG['dte_max']} days\")\n",
    "print(f\"Delta Range:     {CC_CONFIG['delta_min']} - {CC_CONFIG['delta_max']}\")\n",
    "print(f\"Entry Time:      {CC_CONFIG['entry_time']}\")\n",
    "print(f\"Strike >= Basis: {CC_CONFIG['sell_call_only_if_price_above_basis']}\")\n",
    "print(f\"Tie-Breaking:    {CC_CONFIG['tie_break_method']}\")\n",
    "print(\"=\" * 60)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2535c0d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "V5 SCHEDULER CONFIGURATION\n",
      "============================================================\n",
      "Date Range:      2023-06-06 to 2023-09-13\n",
      "Calendar:        NYSE\n",
      "Symbols:         ['TSLA']\n",
      "Multi-Wheel:     True\n",
      "Log Level:       INFO\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# V5 SCHEDULER CONFIGURATION\n",
    "# =============================================================================\n",
    "\n",
    "SCHEDULER_CONFIG = {\n",
    "    # -------------------------------------------------------------------------\n",
    "    # DATE RANGE\n",
    "    # -------------------------------------------------------------------------\n",
    "    'start_date': '2023-06-06',                # Start date for backtest\n",
    "    'end_date': '2023-09-13',                  # End date for backtest\n",
    "    'trading_calendar': 'NYSE',                # Market calendar to use\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # SYMBOLS\n",
    "    # -------------------------------------------------------------------------\n",
    "    'symbols': ['TSLA'],                       # List of symbols to backtest\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # WHEEL INSTANCE CONTROL\n",
    "    # -------------------------------------------------------------------------\n",
    "    'allow_multiple_wheels_per_symbol': True,  # Allow overlapping wheels\n",
    "    'max_wheels_per_symbol_per_day': None,     # None = no limit\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # REPRODUCIBILITY\n",
    "    # -------------------------------------------------------------------------\n",
    "    'scheduler_seed': 123,                     # Reserved for v6 ranking/capital allocation\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # LOGGING\n",
    "    # -------------------------------------------------------------------------\n",
    "    'log_level': 'INFO',                       # 'INFO' or 'QUIET'\n",
    "}\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"V5 SCHEDULER CONFIGURATION\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Date Range:      {SCHEDULER_CONFIG['start_date']} to {SCHEDULER_CONFIG['end_date']}\")\n",
    "print(f\"Calendar:        {SCHEDULER_CONFIG['trading_calendar']}\")\n",
    "print(f\"Symbols:         {SCHEDULER_CONFIG['symbols']}\")\n",
    "print(f\"Multi-Wheel:     {SCHEDULER_CONFIG['allow_multiple_wheels_per_symbol']}\")\n",
    "print(f\"Log Level:       {SCHEDULER_CONFIG['log_level']}\")\n",
    "print(\"=\" * 60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ecc59228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "STATE MACHINE VALIDATION\n",
      "============================================================\n",
      "  ✓ CSP_OPEN + 'profit_target' → CSP_CLOSED_PROFIT\n",
      "  ✓ CSP_OPEN + 'assigned' → CSP_ASSIGNED\n",
      "  ✓ CSP_ASSIGNED + 'sell_call' → CC_OPEN\n",
      "  ✓ CSP_ASSIGNED + 'complete' → WHEEL_COMPLETE\n",
      "  ✓ CC_OPEN + 'called_away' → CC_ASSIGNED\n",
      "  ✓ CC_ASSIGNED + 'complete' → WHEEL_COMPLETE\n",
      "  ✓ Correctly rejected invalid transition: CSP_OPEN + 'called_away'\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# WHEEL STATE MACHINE\n",
    "# =============================================================================\n",
    "# Explicit state transitions prevent logic spaghetti and make logs interpretable.\n",
    "# WHEEL_COMPLETE is the single canonical terminal state for all paths.\n",
    "\n",
    "import uuid\n",
    "\n",
    "# Valid state transitions\n",
    "VALID_TRANSITIONS = {\n",
    "    'CSP_OPEN': ['CSP_CLOSED_PROFIT', 'CSP_CLOSED_STOP', 'CSP_ASSIGNED', 'CSP_CLOSED_WORTHLESS'],\n",
    "    'CSP_ASSIGNED': ['CC_OPEN', 'WHEEL_COMPLETE'],  # Can sell CC or mark incomplete\n",
    "    'CC_OPEN': ['CC_CLOSED_PROFIT', 'CC_ASSIGNED', 'CC_CLOSED_WORTHLESS'],\n",
    "    'CC_ASSIGNED': ['WHEEL_COMPLETE'],\n",
    "    'CC_CLOSED_PROFIT': ['WHEEL_COMPLETE'],      # v1: no re-entry after CC profit\n",
    "    'CC_CLOSED_WORTHLESS': ['WHEEL_COMPLETE'],   # v1: no re-entry after CC expires\n",
    "    'CSP_CLOSED_PROFIT': ['WHEEL_COMPLETE'],\n",
    "    'CSP_CLOSED_STOP': ['WHEEL_COMPLETE'],\n",
    "    'CSP_CLOSED_WORTHLESS': ['WHEEL_COMPLETE'],\n",
    "    'WHEEL_COMPLETE': [],  # Terminal state - no further transitions\n",
    "}\n",
    "\n",
    "# Event to state mapping\n",
    "EVENT_TO_STATE = {\n",
    "    # CSP phase events\n",
    "    ('CSP_OPEN', 'profit_target'): 'CSP_CLOSED_PROFIT',\n",
    "    ('CSP_OPEN', 'stop_loss'): 'CSP_CLOSED_STOP',\n",
    "    ('CSP_OPEN', 'assigned'): 'CSP_ASSIGNED',\n",
    "    ('CSP_OPEN', 'expired_worthless'): 'CSP_CLOSED_WORTHLESS',\n",
    "    \n",
    "    # Assignment to CC\n",
    "    ('CSP_ASSIGNED', 'sell_call'): 'CC_OPEN',\n",
    "    \n",
    "    # CC phase events\n",
    "    ('CC_OPEN', 'profit_target'): 'CC_CLOSED_PROFIT',\n",
    "    ('CC_OPEN', 'called_away'): 'CC_ASSIGNED',\n",
    "    ('CC_OPEN', 'expired_worthless'): 'CC_CLOSED_WORTHLESS',\n",
    "    \n",
    "    # Terminal transitions (all paths lead to WHEEL_COMPLETE)\n",
    "    ('CC_ASSIGNED', 'complete'): 'WHEEL_COMPLETE',\n",
    "    ('CC_CLOSED_PROFIT', 'complete'): 'WHEEL_COMPLETE',\n",
    "    ('CC_CLOSED_WORTHLESS', 'complete'): 'WHEEL_COMPLETE',\n",
    "    ('CSP_CLOSED_PROFIT', 'complete'): 'WHEEL_COMPLETE',\n",
    "    ('CSP_CLOSED_STOP', 'complete'): 'WHEEL_COMPLETE',\n",
    "    ('CSP_CLOSED_WORTHLESS', 'complete'): 'WHEEL_COMPLETE',\n",
    "    ('CSP_ASSIGNED', 'complete'): 'WHEEL_COMPLETE',  # For incomplete wheels (no CC processed)\n",
    "}\n",
    "\n",
    "\n",
    "def advance_wheel_state(current_state, event):\n",
    "    \"\"\"\n",
    "    Advance wheel state based on event. Enforces valid transitions.\n",
    "    \n",
    "    Args:\n",
    "        current_state: Current state string (e.g., 'CSP_OPEN', 'CC_OPEN')\n",
    "        event: Event triggering transition (e.g., 'profit_target', 'assigned', 'called_away')\n",
    "    \n",
    "    Returns:\n",
    "        New state string\n",
    "    \n",
    "    Raises:\n",
    "        ValueError if transition is invalid\n",
    "    \n",
    "    Example:\n",
    "        >>> advance_wheel_state('CSP_OPEN', 'assigned')\n",
    "        'CSP_ASSIGNED'\n",
    "        >>> advance_wheel_state('CC_OPEN', 'called_away')\n",
    "        'CC_ASSIGNED'\n",
    "    \"\"\"\n",
    "    key = (current_state, event)\n",
    "    \n",
    "    if key not in EVENT_TO_STATE:\n",
    "        valid_events = [e for (s, e) in EVENT_TO_STATE.keys() if s == current_state]\n",
    "        raise ValueError(\n",
    "            f\"Invalid transition: state='{current_state}' + event='{event}'. \"\n",
    "            f\"Valid events from {current_state}: {valid_events}\"\n",
    "        )\n",
    "    \n",
    "    new_state = EVENT_TO_STATE[key]\n",
    "    \n",
    "    # Double-check against VALID_TRANSITIONS (belt and suspenders)\n",
    "    if new_state not in VALID_TRANSITIONS.get(current_state, []):\n",
    "        raise ValueError(\n",
    "            f\"State '{new_state}' not reachable from '{current_state}'. \"\n",
    "            f\"Valid transitions: {VALID_TRANSITIONS.get(current_state, [])}\"\n",
    "        )\n",
    "    \n",
    "    return new_state\n",
    "\n",
    "\n",
    "def generate_wheel_id():\n",
    "    \"\"\"Generate a unique wheel ID for linking CSP + CC phases.\"\"\"\n",
    "    return str(uuid.uuid4())[:8]\n",
    "\n",
    "\n",
    "def get_phase_from_state(state):\n",
    "    \"\"\"\n",
    "    Extract phase from state string.\n",
    "    \n",
    "    Returns:\n",
    "        'csp': For CSP states (CSP_OPEN, CSP_CLOSED_*, CSP_ASSIGNED)\n",
    "        'cc': For CC states (CC_OPEN, CC_CLOSED_*, CC_ASSIGNED)\n",
    "        'total': For WHEEL_COMPLETE (used in wheel summaries)\n",
    "        'unknown': For unrecognized states\n",
    "    \"\"\"\n",
    "    if state.startswith('CSP'):\n",
    "        return 'csp'\n",
    "    elif state.startswith('CC'):\n",
    "        return 'cc'\n",
    "    elif state == 'WHEEL_COMPLETE':\n",
    "        return 'total'  # Consistent with wheel summary phase\n",
    "    else:\n",
    "        return 'unknown'\n",
    "\n",
    "\n",
    "def is_terminal_state(state):\n",
    "    \"\"\"Check if state is a terminal state (no further transitions possible).\"\"\"\n",
    "    return len(VALID_TRANSITIONS.get(state, [])) == 0 or state == 'WHEEL_COMPLETE'\n",
    "\n",
    "\n",
    "# Test the state machine\n",
    "print(\"=\" * 60)\n",
    "print(\"STATE MACHINE VALIDATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Test valid transitions\n",
    "test_cases = [\n",
    "    ('CSP_OPEN', 'profit_target', 'CSP_CLOSED_PROFIT'),\n",
    "    ('CSP_OPEN', 'assigned', 'CSP_ASSIGNED'),\n",
    "    ('CSP_ASSIGNED', 'sell_call', 'CC_OPEN'),\n",
    "    ('CSP_ASSIGNED', 'complete', 'WHEEL_COMPLETE'),  # For incomplete wheels\n",
    "    ('CC_OPEN', 'called_away', 'CC_ASSIGNED'),\n",
    "    ('CC_ASSIGNED', 'complete', 'WHEEL_COMPLETE'),\n",
    "]\n",
    "\n",
    "for current, event, expected in test_cases:\n",
    "    result = advance_wheel_state(current, event)\n",
    "    status = \"✓\" if result == expected else \"✗\"\n",
    "    print(f\"  {status} {current} + '{event}' → {result}\")\n",
    "\n",
    "# Test invalid transition (should raise)\n",
    "try:\n",
    "    advance_wheel_state('CSP_OPEN', 'called_away')  # Invalid: called_away only valid for CC_OPEN\n",
    "    print(\"  ✗ Should have raised ValueError for invalid transition\")\n",
    "except ValueError as e:\n",
    "    print(f\"  ✓ Correctly rejected invalid transition: CSP_OPEN + 'called_away'\")\n",
    "\n",
    "print(\"=\" * 60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "helper_functions_cell",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "FILL ASSUMPTIONS BY SCENARIO\n",
      "============================================================\n",
      "Scenario     Entry (Sell)              Exit (Buy Back)          \n",
      "------------------------------------------------------------\n",
      "Pessimistic  Mid - 75% of spread       Close + 75% of range     \n",
      "Realistic    Mid - 30% of spread       Close + 30% of range     \n",
      "Optimistic   Mid (no slippage)         Close - 25% of range     \n",
      "============================================================\n",
      "\n",
      "Transaction costs: $0.66/leg\n",
      "\n",
      "Liquidity Model (regime-aware):\n",
      "  Hard reject: bid < $0.1 or spread > 20%\n",
      "  Base target spread: 8%\n",
      "  High IV (70%ile): allow 12%\n",
      "  Extreme IV (90%ile): allow 15%\n",
      "  Short DTE (≤7d): +2% allowed\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# HELPER FUNCTIONS FOR REALISTIC EXECUTION\n",
    "# =============================================================================\n",
    "\n",
    "def get_entry_price(row, fill_mode='realistic', penalty=1.0):\n",
    "    \"\"\"\n",
    "    Calculate entry price when SELLING a put (we receive premium).\n",
    "    Higher price = better for us.\n",
    "    \n",
    "    Slippage is calculated as a percentage of the bid-ask spread from mid.\n",
    "    Penalty multiplier widens the effective spread for illiquid options.\n",
    "    \n",
    "    | Scenario    | Formula                              | Interpretation              |\n",
    "    |-------------|--------------------------------------|-----------------------------|\n",
    "    | pessimistic | mid - 75% of (spread * penalty)      | Forced/stressed execution   |\n",
    "    | realistic   | mid - 30% of (spread * penalty)      | Normal retail execution     |\n",
    "    | optimistic  | mid                                  | Patient, favorable fills    |\n",
    "    \n",
    "    Args:\n",
    "        row: DataFrame row with bid_px_00, ask_px_00\n",
    "        fill_mode: 'optimistic', 'realistic', or 'pessimistic'\n",
    "        penalty: liquidity penalty multiplier (1.0 = no extra slippage)\n",
    "    \"\"\"\n",
    "    bid = row['bid_px_00']\n",
    "    ask = row['ask_px_00']\n",
    "    mid = (bid + ask) / 2\n",
    "    spread = ask - bid\n",
    "    \n",
    "    # Apply liquidity penalty to effective spread\n",
    "    effective_spread = spread * penalty\n",
    "    \n",
    "    if fill_mode == 'optimistic':\n",
    "        return mid                              # Best case - get mid (no penalty applied)\n",
    "    elif fill_mode == 'pessimistic':\n",
    "        fill = mid - (0.75 * effective_spread)  # Worst case - 75% toward bid\n",
    "    else:  # realistic\n",
    "        fill = mid - (0.30 * effective_spread)  # Normal - 30% toward bid\n",
    "    \n",
    "    # Clamp to [bid, ask] to stay realistic\n",
    "    return max(bid, min(ask, fill))\n",
    "\n",
    "\n",
    "def get_exit_price(daily_row, fill_mode=CONFIG['fill_mode'], target_price=None, penalty=1.0): # IS THIS RIGHT TO SET AT PENALTY = 1.0? ##\n",
    "    \"\"\"\n",
    "    Calculate exit price when BUYING BACK a put (we pay to close).\n",
    "    Lower price = better for us.\n",
    "    \n",
    "    For daily OHLCV data, we estimate spread behavior from the day's range.\n",
    "    Penalty multiplier widens the effective range for illiquid options.\n",
    "    \n",
    "    | Scenario    | Formula                              | Interpretation              |\n",
    "    |-------------|--------------------------------------|-----------------------------|\n",
    "    | pessimistic | close + 75% of (range * penalty)     | Forced/stressed execution   |\n",
    "    | realistic   | close + 30% of (range * penalty)     | Normal retail execution     |\n",
    "    | optimistic  | close - 25% of (range * penalty)     | Patient, favorable fills    |\n",
    "    \n",
    "    Args:\n",
    "        daily_row: DataFrame row with close, high, low\n",
    "        fill_mode: 'optimistic', 'realistic', or 'pessimistic'\n",
    "        target_price: Optional target price (not currently used but reserved)\n",
    "        penalty: liquidity penalty multiplier (1.0 = no extra slippage)\n",
    "    \"\"\"\n",
    "    close = daily_row['close']\n",
    "    high = daily_row['high']\n",
    "    low = daily_row['low']\n",
    "    day_range = high - low  # Proxy for intraday spread/volatility\n",
    "    \n",
    "    # Apply liquidity penalty to effective range\n",
    "    effective_range = day_range * penalty\n",
    "    \n",
    "    if fill_mode == 'optimistic':\n",
    "        # Patient buyer - gets below close (toward low)\n",
    "        fill = close - (0.25 * effective_range)\n",
    "        return max(low, fill)\n",
    "    elif fill_mode == 'pessimistic':\n",
    "        # Forced buyer - pays above close (toward high)\n",
    "        fill = close + (0.75 * effective_range)\n",
    "        return min(high, fill)\n",
    "    else:  # realistic\n",
    "        # Normal execution - slight slippage above close\n",
    "        fill = close + (0.30 * effective_range)\n",
    "        return min(high, fill)\n",
    "\n",
    "\n",
    "def get_transaction_costs(config, is_round_trip=True):\n",
    "    \"\"\"\n",
    "    Calculate total transaction costs per contract.\n",
    "    \n",
    "    Args:\n",
    "        config: CONFIG dict with commission and fee rates\n",
    "        is_round_trip: True if both entry and exit, False if entry only (e.g., expired worthless)\n",
    "    \n",
    "    Returns:\n",
    "        Total fees in dollars per contract\n",
    "    \"\"\"\n",
    "    per_leg = config['commission_per_contract'] + config['sec_fee_per_contract']\n",
    "    return per_leg * 2 if is_round_trip else per_leg\n",
    "\n",
    "\n",
    "def compute_allowed_spread(row, config):\n",
    "    \"\"\"\n",
    "    Compute the allowed spread percentage for a single option based on regime.\n",
    "    \n",
    "    Regime factors:\n",
    "    - IV percentile (high vol → allow wider spreads)\n",
    "    - DTE (short-dated → allow wider spreads)\n",
    "    \n",
    "    Returns: allowed_spread_pct for this option\n",
    "    \"\"\"\n",
    "    base = config['base_max_spread_pct']\n",
    "    \n",
    "    # IV regime adjustment\n",
    "    ivp = row.get('ivp', 0.5)  # Default to median if not computed\n",
    "    if ivp >= config['ivp_extreme_threshold']:\n",
    "        base = config['ivp_extreme_max_spread_pct']\n",
    "    elif ivp >= config['ivp_high_threshold']:\n",
    "        base = config['ivp_high_max_spread_pct']\n",
    "    \n",
    "    # DTE adjustment\n",
    "    dte = row.get('dte', 30)\n",
    "    if dte <= config['short_dte_threshold']:\n",
    "        base += config['short_dte_extra_spread_pct']\n",
    "    \n",
    "    return base\n",
    "\n",
    "\n",
    "def compute_liquidity_penalty(spread_pct, allowed_spread_pct, hard_max_spread_pct):\n",
    "    \"\"\"\n",
    "    Compute liquidity penalty multiplier based on spread quality.\n",
    "    \n",
    "    Tiers:\n",
    "    - tight:    spread <= 0.6 * allowed → penalty = 1.0 (no extra slippage)\n",
    "    - moderate: spread <= allowed       → penalty = 1.15\n",
    "    - wide:     spread <= hard_max      → penalty = 1.35\n",
    "    - ugly:     spread > hard_max       → None (reject)\n",
    "    \n",
    "    Returns: (tier_name, penalty_multiplier) or (None, None) if rejected\n",
    "    \"\"\"\n",
    "    if spread_pct > hard_max_spread_pct:\n",
    "        return 'reject', None\n",
    "    \n",
    "    tight_threshold = 0.6 * allowed_spread_pct\n",
    "    \n",
    "    if spread_pct <= tight_threshold:\n",
    "        return 'tight', 1.0\n",
    "    elif spread_pct <= allowed_spread_pct:\n",
    "        return 'moderate', 1.15\n",
    "    else:  # spread_pct <= hard_max_spread_pct\n",
    "        return 'wide', 1.35\n",
    "\n",
    "\n",
    "def apply_liquidity_model(df, config):\n",
    "    \"\"\"\n",
    "    Apply regime-aware liquidity model with penalty tiers.\n",
    "    \n",
    "    Instead of binary reject, this:\n",
    "    1. Computes IV percentile (ivp) for regime detection\n",
    "    2. Computes allowed_spread_pct per option (regime-aware)\n",
    "    3. Assigns liquidity_tier and liquidity_penalty\n",
    "    4. Only hard-rejects truly ugly spreads\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame with option quotes (needs bid_px_00, ask_px_00, spread_pct, iv, dte)\n",
    "        config: CONFIG dict with liquidity model settings\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with liquidity columns added, ugly spreads removed\n",
    "    \"\"\"\n",
    "    if len(df) == 0:\n",
    "        return df\n",
    "    \n",
    "    df = df.copy()\n",
    "    original_count = len(df)\n",
    "    \n",
    "    # Ensure required columns exist\n",
    "    if 'spread_pct' not in df.columns:\n",
    "        df['spread'] = df['ask_px_00'] - df['bid_px_00']\n",
    "        df['spread_pct'] = df['spread'] / df['mid']\n",
    "    \n",
    "    # Step 1: Compute IV percentile (cross-sectional within this snapshot)\n",
    "    if 'iv' in df.columns:\n",
    "        df['ivp'] = df['iv'].rank(pct=True)\n",
    "    else:\n",
    "        df['ivp'] = 0.5  # Default to median if IV not available\n",
    "    \n",
    "    # Step 2: Compute allowed spread per option\n",
    "    df['allowed_spread_pct'] = df.apply(\n",
    "        lambda row: compute_allowed_spread(row, config), axis=1\n",
    "    )\n",
    "    \n",
    "    # Step 3: Compute liquidity tier and penalty\n",
    "    def get_tier_and_penalty(row):\n",
    "        return compute_liquidity_penalty(\n",
    "            row['spread_pct'], \n",
    "            row['allowed_spread_pct'],\n",
    "            config['hard_max_spread_pct']\n",
    "        )\n",
    "    \n",
    "    tiers_penalties = df.apply(get_tier_and_penalty, axis=1)\n",
    "    df['liquidity_tier'] = tiers_penalties.apply(lambda x: x[0])\n",
    "    df['liquidity_penalty'] = tiers_penalties.apply(lambda x: x[1])\n",
    "    \n",
    "    # Step 4: Hard reject only truly ugly spreads and penny options\n",
    "    df = df[\n",
    "        (df['liquidity_tier'] != 'reject') &\n",
    "        (df['bid_px_00'] >= config['min_bid_hard'])\n",
    "    ].copy()\n",
    "    \n",
    "    rejected = original_count - len(df)\n",
    "    \n",
    "    # Print diagnostics\n",
    "    print(f\"\\n  Liquidity Model Applied:\")\n",
    "    print(f\"    Original: {original_count} options\")\n",
    "    print(f\"    Hard rejected: {rejected} ({rejected/original_count*100:.1f}%)\")\n",
    "    print(f\"    Remaining: {len(df)} options\")\n",
    "    \n",
    "    if len(df) > 0:\n",
    "        tier_counts = df['liquidity_tier'].value_counts()\n",
    "        print(f\"    Tier breakdown: {dict(tier_counts)}\")\n",
    "        print(f\"    Avg spread: {df['spread_pct'].mean()*100:.1f}%, Avg allowed: {df['allowed_spread_pct'].mean()*100:.1f}%\")\n",
    "        print(f\"    Avg penalty: {df['liquidity_penalty'].mean():.2f}x\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def calculate_pnl(premium_received, exit_price_paid, fees, cost_basis):\n",
    "    \"\"\"\n",
    "    Calculate P&L metrics for a trade.\n",
    "    \n",
    "    Args:\n",
    "        premium_received: Premium collected when selling (contract value)\n",
    "        exit_price_paid: Price paid to close position (contract value), 0 if expired worthless\n",
    "        fees: Total transaction costs\n",
    "        cost_basis: Capital at risk (strike * 100 for CSP)\n",
    "    \n",
    "    Returns:\n",
    "        dict with pnl, pnl_pct, roc\n",
    "    \"\"\"\n",
    "    pnl = premium_received - exit_price_paid - fees\n",
    "    pnl_pct = (pnl / premium_received) * 100 if premium_received > 0 else 0\n",
    "    roc = (pnl / cost_basis) * 100 if cost_basis > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        'pnl': pnl,\n",
    "        'pnl_pct': pnl_pct,\n",
    "        'roc': roc,\n",
    "        'fees': fees\n",
    "    }\n",
    "\n",
    "\n",
    "def compute_p_fill_profit(row, config):\n",
    "    \"\"\"\n",
    "    Compute probability of fill for profit target exit based on entry liquidity.\n",
    "    \n",
    "    Uses entry-time spread and IVP to determine fill probability:\n",
    "    - tight spread (<=5%): high fill probability\n",
    "    - normal spread (<=10%): moderate fill probability\n",
    "    - wide spread (>10%): low fill probability\n",
    "    \n",
    "    Applies IVP penalty multipliers for high-volatility regimes.\n",
    "    \n",
    "    Args:\n",
    "        row: DataFrame row with spread_pct_entry, ivp_entry\n",
    "        config: CONFIG dict with fill probability settings\n",
    "    \n",
    "    Returns:\n",
    "        float: Fill probability in [pfill_min, pfill_max]\n",
    "    \"\"\"\n",
    "    spread_pct = row.get('spread_pct_entry', 0.05)\n",
    "    \n",
    "    # Bucket by spread quality\n",
    "    if spread_pct <= config['tight_spread_pct']:\n",
    "        p_fill = config['pfill_tight']\n",
    "    elif spread_pct <= config['normal_spread_pct']:\n",
    "        p_fill = config['pfill_normal']\n",
    "    else:\n",
    "        p_fill = config['pfill_wide']\n",
    "    \n",
    "    # Apply scale multiplier\n",
    "    p_fill *= config['pfill_scale']\n",
    "    \n",
    "    # Apply IVP penalty (always use ivp_entry, not generic ivp)\n",
    "    ivp = row.get('ivp_entry', 0.5)\n",
    "    if ivp >= config['ivp_extreme_threshold']:\n",
    "        p_fill *= config.get('pfill_ivp_extreme_mult', 1.0)\n",
    "    elif ivp >= config['ivp_high_threshold']:\n",
    "        p_fill *= config.get('pfill_ivp_high_mult', 1.0)\n",
    "    \n",
    "    # Clamp to valid range\n",
    "    return max(config['pfill_min'], min(config['pfill_max'], p_fill))\n",
    "\n",
    "\n",
    "def try_probabilistic_fill(p_fill, rng):\n",
    "    \"\"\"\n",
    "    Simulate probabilistic fill by drawing uniform random number.\n",
    "    \n",
    "    Args:\n",
    "        p_fill: Fill probability (0.0 to 1.0)\n",
    "        rng: numpy random number generator\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (filled: bool, u: float) where u is the random draw\n",
    "    \"\"\"\n",
    "    u = rng.uniform(0, 1)\n",
    "    filled = (u <= p_fill)\n",
    "    return filled, u\n",
    "\n",
    "\n",
    "# Print summary of fill assumptions\n",
    "print(\"=\" * 60)\n",
    "print(\"FILL ASSUMPTIONS BY SCENARIO\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"{'Scenario':<12} {'Entry (Sell)':<25} {'Exit (Buy Back)':<25}\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'Pessimistic':<12} {'Mid - 75% of spread':<25} {'Close + 75% of range':<25}\")\n",
    "print(f\"{'Realistic':<12} {'Mid - 30% of spread':<25} {'Close + 30% of range':<25}\")\n",
    "print(f\"{'Optimistic':<12} {'Mid (no slippage)':<25} {'Close - 25% of range':<25}\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nTransaction costs: ${CONFIG['commission_per_contract'] + CONFIG['sec_fee_per_contract']:.2f}/leg\")\n",
    "print(f\"\\nLiquidity Model (regime-aware):\")\n",
    "print(f\"  Hard reject: bid < ${CONFIG['min_bid_hard']} or spread > {CONFIG['hard_max_spread_pct']*100:.0f}%\")\n",
    "print(f\"  Base target spread: {CONFIG['base_max_spread_pct']*100:.0f}%\")\n",
    "print(f\"  High IV ({CONFIG['ivp_high_threshold']*100:.0f}%ile): allow {CONFIG['ivp_high_max_spread_pct']*100:.0f}%\")\n",
    "print(f\"  Extreme IV ({CONFIG['ivp_extreme_threshold']*100:.0f}%ile): allow {CONFIG['ivp_extreme_max_spread_pct']*100:.0f}%\")\n",
    "print(f\"  Short DTE (≤{CONFIG['short_dte_threshold']}d): +{CONFIG['short_dte_extra_spread_pct']*100:.0f}% allowed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "aa05df59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TRADING CALENDAR UTILITIES LOADED\n",
      "============================================================\n",
      "Sample trading days (Jan 1-10, 2023):\n",
      "  2023-01-03 (Tuesday)\n",
      "  2023-01-04 (Wednesday)\n",
      "  2023-01-05 (Thursday)\n",
      "  2023-01-06 (Friday)\n",
      "  2023-01-09 (Monday)\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# V5 TRADING CALENDAR UTILITIES\n",
    "# =============================================================================\n",
    "\n",
    "def get_trading_days(start_date, end_date, calendar='NYSE'):\n",
    "    \"\"\"\n",
    "    Get list of trading days between start and end dates.\n",
    "    \n",
    "    Args:\n",
    "        start_date: Start date (string or Timestamp)\n",
    "        end_date: End date (string or Timestamp)\n",
    "        calendar: Market calendar name (default 'NYSE')\n",
    "    \n",
    "    Returns:\n",
    "        DatetimeIndex of trading days\n",
    "    \n",
    "    Note:\n",
    "        schedule.index is timezone-naive; we treat it as a date (NY trading day).\n",
    "        The entry_time timezone logic is applied separately when building \n",
    "        config_day['entry_date'].\n",
    "    \"\"\"\n",
    "    cal = mcal.get_calendar(calendar)\n",
    "    schedule = cal.schedule(start_date=start_date, end_date=end_date)\n",
    "    return schedule.index\n",
    "\n",
    "# Test the utility\n",
    "test_days = get_trading_days('2023-01-01', '2023-01-10')\n",
    "print(\"=\" * 60)\n",
    "print(\"TRADING CALENDAR UTILITIES LOADED\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Sample trading days (Jan 1-10, 2023):\")\n",
    "for day in test_days[:5]:\n",
    "    print(f\"  {day.date()} ({day.day_name()})\")\n",
    "print(\"=\" * 60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fe231b4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "V5 ENTRY CANDIDATE WRAPPER LOADED\n",
      "============================================================\n",
      "  - get_entry_candidates(symbol, trade_date, config, client)\n",
      "  - apply_liquidity_model_silent(df, config)\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# V5 ENTRY CANDIDATE WRAPPER\n",
    "# =============================================================================\n",
    "# Encapsulates option chain fetching and filtering for a single symbol/date\n",
    "\n",
    "import numpy as np\n",
    "from py_vollib.black_scholes.implied_volatility import implied_volatility\n",
    "from py_vollib.black_scholes.greeks.analytical import delta as calc_delta\n",
    "\n",
    "def get_entry_candidates(symbol, trade_date, config, client):\n",
    "    \"\"\"\n",
    "    Get qualifying CSP entry candidates for a symbol on a given date.\n",
    "    \n",
    "    This function encapsulates:\n",
    "    1. Fetch option chain snapshot at entry_time\n",
    "    2. Parse option symbols and calculate DTE\n",
    "    3. Compute mid price, spread, IV, and delta\n",
    "    4. Apply delta/DTE/liquidity filters\n",
    "    5. Sort candidates deterministically for reproducibility\n",
    "    \n",
    "    Args:\n",
    "        symbol: Underlying symbol (e.g., 'TSLA')\n",
    "        trade_date: Trading date (pandas Timestamp)\n",
    "        config: CONFIG dict with entry parameters\n",
    "        client: Databento client\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame of qualifying CSP candidates (empty if none qualify)\n",
    "    \"\"\"\n",
    "    cache_dir = config.get('cache_dir', '../cache/')\n",
    "    tz = config.get('timezone', 'America/New_York')\n",
    "    entry_time = config.get('entry_time', '15:45')\n",
    "    \n",
    "    # Build entry timestamp\n",
    "    date_str = trade_date.strftime('%Y-%m-%d')\n",
    "    entry_ts = pd.Timestamp(f\"{date_str} {entry_time}\", tz=tz)\n",
    "    \n",
    "    # Generate cache filename for options data\n",
    "    date_cache_str = trade_date.strftime('%Y%m%d')\n",
    "    time_cache_str = entry_ts.strftime('%H%M')\n",
    "    cache_file = os.path.join(cache_dir, f\"options_{symbol}_{date_cache_str}_{time_cache_str}.parquet\")\n",
    "    \n",
    "    # Check cache first\n",
    "    if os.path.exists(cache_file):\n",
    "        df_opts = pd.read_parquet(cache_file)\n",
    "    else:\n",
    "        # Fetch from API\n",
    "        try:\n",
    "            start = entry_ts\n",
    "            end = start + pd.Timedelta(minutes=1)\n",
    "            \n",
    "            data = client.timeseries.get_range(\n",
    "                dataset='OPRA.PILLAR',\n",
    "                schema='cmbp-1',\n",
    "                symbols=f\"{symbol}.OPT\",\n",
    "                stype_in='parent',\n",
    "                start=start,\n",
    "                end=end,\n",
    "            )\n",
    "            \n",
    "            df_opts = data.to_df(tz=tz).sort_values(\"ts_event\")\n",
    "            df_opts.to_parquet(cache_file)\n",
    "        except Exception as e:\n",
    "            return pd.DataFrame()\n",
    "    \n",
    "    if len(df_opts) == 0:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # Parse option symbols\n",
    "    sym = df_opts[\"symbol\"]\n",
    "    root_and_code = sym.str.split(expand=True)\n",
    "    df_opts[\"root\"] = root_and_code[0]\n",
    "    code = root_and_code[1]\n",
    "    df_opts[\"expiration\"] = pd.to_datetime(code.str[:6], format=\"%y%m%d\")\n",
    "    df_opts[\"call_put\"] = code.str[6]\n",
    "    strike_int = code.str[7:].astype(\"int32\")\n",
    "    df_opts[\"strike\"] = strike_int / 1000.0\n",
    "    expiration_tz = df_opts[\"expiration\"].dt.tz_localize(df_opts[\"ts_event\"].dt.tz)\n",
    "    df_opts[\"dte\"] = (expiration_tz - df_opts[\"ts_event\"].dt.normalize()).dt.days\n",
    "    \n",
    "    # Filter by DTE and option type\n",
    "    df_opts = df_opts[\n",
    "        (df_opts['dte'] >= config['dte_min']) & \n",
    "        (df_opts['dte'] <= config['dte_max']) & \n",
    "        (df_opts['call_put'] == config['option_type'])\n",
    "    ].copy()\n",
    "    \n",
    "    if len(df_opts) == 0:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # Get underlying price at entry time\n",
    "    equity_cache = os.path.join(cache_dir, f\"equity_minute_{symbol}_{date_cache_str}_{time_cache_str}.parquet\")\n",
    "    if os.path.exists(equity_cache):\n",
    "        equity_df = pd.read_parquet(equity_cache)\n",
    "        underlying_price = equity_df['close'].iloc[-1] if len(equity_df) > 0 else None\n",
    "    else:\n",
    "        # Fetch from API\n",
    "        try:\n",
    "            equity_data = client.timeseries.get_range(\n",
    "                dataset='XNAS.ITCH',\n",
    "                symbols=[symbol],\n",
    "                schema='ohlcv-1m',\n",
    "                start=entry_ts,\n",
    "                end=entry_ts + pd.Timedelta(minutes=1),\n",
    "                stype_in='raw_symbol'\n",
    "            )\n",
    "            equity_df = equity_data.to_df()\n",
    "            if len(equity_df) > 0:\n",
    "                equity_df.to_parquet(equity_cache)\n",
    "                underlying_price = equity_df['close'].iloc[-1]\n",
    "            else:\n",
    "                underlying_price = None\n",
    "        except:\n",
    "            underlying_price = None\n",
    "    \n",
    "    if underlying_price is None:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # Filter to valid quotes only\n",
    "    quotes = df_opts[df_opts[\"bid_px_00\"].notna() & df_opts[\"ask_px_00\"].notna()].copy()\n",
    "    if len(quotes) == 0:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # Compute mid price\n",
    "    quotes[\"mid\"] = (quotes[\"bid_px_00\"] + quotes[\"ask_px_00\"]) / 2\n",
    "    quotes[\"spread\"] = quotes[\"ask_px_00\"] - quotes[\"bid_px_00\"]\n",
    "    quotes[\"spread_pct\"] = quotes[\"spread\"] / quotes[\"mid\"]\n",
    "    \n",
    "    # Get last quote per contract\n",
    "    chain_snapshot = (\n",
    "        quotes\n",
    "        .sort_values(\"ts_event\")\n",
    "        .groupby([\"symbol\", \"expiration\", \"strike\", \"call_put\"])\n",
    "        .tail(1)\n",
    "        .copy()\n",
    "    )\n",
    "    chain_snapshot[\"underlying_last\"] = underlying_price\n",
    "    \n",
    "    # Compute IV and delta\n",
    "    r = 0.04\n",
    "    \n",
    "    def compute_iv(row):\n",
    "        price = row[\"mid\"]\n",
    "        S = row[\"underlying_last\"]\n",
    "        K = row[\"strike\"]\n",
    "        t = row[\"dte\"] / 365.0\n",
    "        flag = \"p\" if row[\"call_put\"] == \"P\" else \"c\"\n",
    "        \n",
    "        if not (np.isfinite(price) and np.isfinite(S) and np.isfinite(K) and t > 0):\n",
    "            return np.nan\n",
    "        if price <= 0 or S <= 0 or K <= 0:\n",
    "            return np.nan\n",
    "        \n",
    "        try:\n",
    "            return implied_volatility(price, S, K, t, r, flag)\n",
    "        except Exception:\n",
    "            return np.nan\n",
    "    \n",
    "    def compute_delta(row):\n",
    "        sigma = row[\"iv\"]\n",
    "        if not np.isfinite(sigma):\n",
    "            return np.nan\n",
    "        \n",
    "        S = row[\"underlying_last\"]\n",
    "        K = row[\"strike\"]\n",
    "        t = row[\"dte\"] / 365.0\n",
    "        flag = \"p\" if row[\"call_put\"] == \"P\" else \"c\"\n",
    "        \n",
    "        return abs(calc_delta(flag, S, K, t, r, sigma))\n",
    "    \n",
    "    chain_snapshot[\"iv\"] = chain_snapshot.apply(compute_iv, axis=1)\n",
    "    chain_snapshot[\"delta\"] = chain_snapshot.apply(compute_delta, axis=1)\n",
    "    chain_snapshot['date'] = chain_snapshot['ts_event'].dt.date\n",
    "    \n",
    "    # Filter by delta\n",
    "    candidates = chain_snapshot[\n",
    "        (chain_snapshot[\"call_put\"] == config['option_type'])\n",
    "        & chain_snapshot[\"dte\"].between(config['dte_min'], config['dte_max'])\n",
    "        & chain_snapshot[\"delta\"].abs().between(config['delta_min'], config['delta_max'])\n",
    "    ].copy()\n",
    "    \n",
    "    if len(candidates) == 0:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # Apply liquidity model (silently)\n",
    "    candidates = apply_liquidity_model_silent(candidates, config)\n",
    "    \n",
    "    if len(candidates) == 0:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # Calculate entry price with liquidity penalty\n",
    "    candidates['entry_price'] = candidates.apply(\n",
    "        lambda row: get_entry_price(row, config['fill_mode'], row.get('liquidity_penalty', 1.0)), \n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    # Set up backtest fields\n",
    "    candidates['per_share_premium'] = candidates['entry_price']\n",
    "    candidates['premium'] = candidates['per_share_premium'] * 100\n",
    "    candidates['cost_basis'] = candidates['strike'] * 100\n",
    "    candidates['exit_pct'] = config['exit_pct']\n",
    "    candidates['exit_price_per_share'] = candidates['per_share_premium'] * candidates['exit_pct']\n",
    "    candidates['spread_pct_entry'] = candidates['spread_pct']\n",
    "    candidates['ivp_entry'] = candidates['ivp']\n",
    "    \n",
    "    # Deterministic ordering for reproducibility\n",
    "    candidates = candidates.sort_values(\n",
    "        ['expiration', 'strike', 'symbol']\n",
    "    ).reset_index(drop=True)\n",
    "    \n",
    "    return candidates\n",
    "\n",
    "\n",
    "def apply_liquidity_model_silent(df, config):\n",
    "    \"\"\"\n",
    "    Apply liquidity model without printing diagnostics.\n",
    "    Same logic as apply_liquidity_model but silent.\n",
    "    \"\"\"\n",
    "    if len(df) == 0:\n",
    "        return df\n",
    "    \n",
    "    df = df.copy()\n",
    "    \n",
    "    if 'spread_pct' not in df.columns:\n",
    "        df['spread'] = df['ask_px_00'] - df['bid_px_00']\n",
    "        df['spread_pct'] = df['spread'] / df['mid']\n",
    "    \n",
    "    if 'iv' in df.columns:\n",
    "        df['ivp'] = df['iv'].rank(pct=True)\n",
    "    else:\n",
    "        df['ivp'] = 0.5\n",
    "    \n",
    "    df['allowed_spread_pct'] = df.apply(\n",
    "        lambda row: compute_allowed_spread(row, config), axis=1\n",
    "    )\n",
    "    \n",
    "    def get_tier_and_penalty(row):\n",
    "        return compute_liquidity_penalty(\n",
    "            row['spread_pct'], \n",
    "            row['allowed_spread_pct'],\n",
    "            config['hard_max_spread_pct']\n",
    "        )\n",
    "    \n",
    "    tiers_penalties = df.apply(get_tier_and_penalty, axis=1)\n",
    "    df['liquidity_tier'] = tiers_penalties.apply(lambda x: x[0])\n",
    "    df['liquidity_penalty'] = tiers_penalties.apply(lambda x: x[1])\n",
    "    \n",
    "    df = df[\n",
    "        (df['liquidity_tier'] != 'reject') &\n",
    "        (df['bid_px_00'] >= config['min_bid_hard'])\n",
    "    ].copy()\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"V5 ENTRY CANDIDATE WRAPPER LOADED\")\n",
    "print(\"=\" * 60)\n",
    "print(\"  - get_entry_candidates(symbol, trade_date, config, client)\")\n",
    "print(\"  - apply_liquidity_model_silent(df, config)\")\n",
    "print(\"=\" * 60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10cb2001",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'backtest_candidates' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 416\u001b[39m\n\u001b[32m    412\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m exits_df\n\u001b[32m    414\u001b[39m \u001b[38;5;66;03m# Run backtest (uses CONFIG from top of notebook)\u001b[39;00m\n\u001b[32m    415\u001b[39m exits_df = backtest_exit_strategy(\n\u001b[32m--> \u001b[39m\u001b[32m416\u001b[39m     backtest_candidates=\u001b[43mbacktest_candidates\u001b[49m,\n\u001b[32m    417\u001b[39m     client=client,\n\u001b[32m    418\u001b[39m     config=CONFIG\n\u001b[32m    419\u001b[39m )\n\u001b[32m    421\u001b[39m \u001b[38;5;66;03m# Display results\u001b[39;00m\n\u001b[32m    422\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m + \u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m60\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'backtest_candidates' is not defined"
     ]
    }
   ],
   "source": [
    "def fetch_underlying_price_at_expiration(underlying_symbol, expiration_date, client, config):\n",
    "    \"\"\"\n",
    "    Fetch underlying stock price at expiration date.\n",
    "    \n",
    "    Used to determine if a covered call is ITM (called away) or OTM (expires worthless).\n",
    "    \n",
    "    Args:\n",
    "        underlying_symbol: Underlying symbol (e.g., 'TSLA')\n",
    "        expiration_date: Expiration date (pandas Timestamp)\n",
    "        client: Databento client\n",
    "        config: Configuration dict with cache_dir and timezone\n",
    "    \n",
    "    Returns:\n",
    "        float: Close price at expiration, or None if unavailable\n",
    "    \"\"\"\n",
    "    cache_dir = config.get('cache_dir', '../cache/')\n",
    "    tz = config.get('timezone', 'America/New_York')\n",
    "    \n",
    "    # Normalize expiration date\n",
    "    if hasattr(expiration_date, 'tz') and expiration_date.tz:\n",
    "        expiration_date = expiration_date.tz_localize(None)\n",
    "    expiration_date = pd.Timestamp(expiration_date).normalize()\n",
    "    \n",
    "    # Try to fetch daily equity data for expiration date\n",
    "    try:\n",
    "        # Generate cache filename\n",
    "        date_str = expiration_date.strftime('%Y%m%d')\n",
    "        cache_file = os.path.join(cache_dir, f\"equity_daily_{underlying_symbol}_{date_str}.parquet\")\n",
    "        \n",
    "        # Check cache first\n",
    "        if os.path.exists(cache_file):\n",
    "            equity_df = pd.read_parquet(cache_file)\n",
    "            if len(equity_df) > 0:\n",
    "                # Return the close price\n",
    "                return float(equity_df['close'].iloc[-1])\n",
    "        \n",
    "        # Cache miss - fetch from API\n",
    "        start = pd.Timestamp(expiration_date, tz=tz)\n",
    "        end = start + pd.Timedelta(days=1)\n",
    "        \n",
    "        equity_data = client.timeseries.get_range(\n",
    "            dataset='EQUS.MINI',  # Consolidated US equities\n",
    "            symbols=[underlying_symbol],\n",
    "            schema='ohlcv-1d',\n",
    "            start=start,\n",
    "            end=end,\n",
    "            stype_in='raw_symbol'\n",
    "        )\n",
    "        \n",
    "        equity_df = equity_data.to_df(tz=tz)\n",
    "        \n",
    "        if len(equity_df) > 0:\n",
    "            # Save to cache\n",
    "            equity_df.to_parquet(cache_file)\n",
    "            return float(equity_df['close'].iloc[-1])\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"    Warning: Could not fetch underlying price at expiration: {e}\")\n",
    "        return None\n",
    "    \n",
    "    return None\n",
    "    \n",
    "def fetch_daily_prices_for_option(symbol, entry_date, expiration_date, client, config):\n",
    "    \"\"\"\n",
    "    Fetch daily OHLC prices for an option from entry date to expiration.\n",
    "\n",
    "    Args:\n",
    "        symbol: Option symbol\n",
    "        entry_date: Entry date (normalized)\n",
    "        expiration_date: Expiration date (normalized)\n",
    "        client: Databento client\n",
    "        config: Configuration dict\n",
    "\n",
    "    Returns:\n",
    "        DataFrame with daily OHLC data\n",
    "    \"\"\"\n",
    "    # Generate cache filename for daily option prices\n",
    "    entry_str = entry_date.strftime('%Y%m%d')\n",
    "    exp_str = expiration_date.strftime('%Y%m%d')\n",
    "    cache_file = os.path.join(CACHE_DIR, f\"option_daily_{symbol}_{entry_str}_{exp_str}.parquet\")\n",
    "\n",
    "    # Check cache first\n",
    "    if os.path.exists(cache_file):\n",
    "        print(f\"    [CACHE HIT] Loading daily prices for {symbol}\")\n",
    "        return pd.read_parquet(cache_file)\n",
    "\n",
    "    # Cache miss - fetch from API\n",
    "    print(f\"    [API] Fetching daily prices for {symbol} from {entry_date.date()} to {expiration_date.date()}\")\n",
    "\n",
    "    start_daily = entry_date + pd.Timedelta(days=1)  # Day after entry\n",
    "    end_daily = expiration_date + pd.Timedelta(days=1)  # Include expiration day\n",
    "\n",
    "    daily_data = client.timeseries.get_range(\n",
    "        dataset='OPRA.PILLAR',\n",
    "        schema='ohlcv-1d',\n",
    "        symbols=symbol,\n",
    "        stype_in='raw_symbol',\n",
    "        start=start_daily,\n",
    "        end=end_daily,\n",
    "    )\n",
    "\n",
    "    df_daily = daily_data.to_df(tz=config['timezone'])\n",
    "\n",
    "    # Save to cache\n",
    "    df_daily.to_parquet(cache_file)\n",
    "    print(f\"    [CACHE SAVE] Saved {len(df_daily)} days to cache\")\n",
    "\n",
    "    return df_daily\n",
    "\n",
    "\n",
    "def check_profit_target_hit(df_daily, exit_price_per_share, entry_date):\n",
    "    \"\"\"\n",
    "    Check if the exit price target was hit in the daily price data.\n",
    "\n",
    "    Args:\n",
    "        df_daily: DataFrame with daily OHLC data (prices are per-share)\n",
    "        exit_price_per_share: Target price per share to exit at\n",
    "        entry_date: Entry date to skip (we can't exit same day we entered)\n",
    "\n",
    "    Returns:\n",
    "        tuple: (hit_date, daily_row) if hit, (None, None) if not hit\n",
    "    \"\"\"\n",
    "    for check_date, daily_row in df_daily.iterrows():\n",
    "        # Skip the entry date - we can't exit on the same day we entered\n",
    "        check_date_normalized = check_date.tz_localize(None) if hasattr(check_date, 'tz_localize') and check_date.tz else check_date\n",
    "        if check_date_normalized.date() <= entry_date.date():\n",
    "            continue\n",
    "            \n",
    "        daily_low = daily_row['low']\n",
    "        daily_high = daily_row['high']\n",
    "\n",
    "        # Check if our exit target (per-share) is within the daily range\n",
    "        if daily_low <= exit_price_per_share <= daily_high:\n",
    "            return check_date, daily_row\n",
    "\n",
    "    return None, None\n",
    "\n",
    "\n",
    "def create_exit_record(symbol, entry_date, expiration_date, premium, exit_pct,\n",
    "                       exit_price, exit_reason, check_date, daily_row, cost_basis,\n",
    "                       wheel_id=None, initial_capital=None,  \n",
    "                       touch_profit_target=None, p_fill_profit_target=None, u_fill_profit_target=None,\n",
    "                       filled_profit_target=None, spread_pct_entry=None, ivp_entry=None,\n",
    "                       touch_count=None):\n",
    "    \"\"\"\n",
    "    Create an exit record dictionary.\n",
    "\n",
    "    Args:\n",
    "        symbol: Option symbol\n",
    "        entry_date: Entry date\n",
    "        expiration_date: Expiration date\n",
    "        premium: Premium received\n",
    "        exit_pct: Exit percentage (e.g., 0.25 = exit when decays 25%)\n",
    "        exit_price: Actual exit price\n",
    "        exit_reason: Reason for exit\n",
    "        check_date: Date of exit\n",
    "        daily_row: Daily price data row\n",
    "        cost_basis: Cost basis (strike * 100)\n",
    "        wheel_id: Unique identifier for this wheel instance  # ADD THIS\n",
    "        initial_capital: Initial capital at risk (strike * 100 for CSP)  # ADD THIS\n",
    "        touch_profit_target: Did price ever touch limit? (bool)\n",
    "        p_fill_profit_target: Computed fill probability (float)\n",
    "        u_fill_profit_target: Random draw value (float)\n",
    "        filled_profit_target: Actually filled? (bool)\n",
    "        spread_pct_entry: Entry-time spread % (float)\n",
    "        ivp_entry: Entry-time IV percentile (float)\n",
    "        touch_count: Number of distinct days with low <= L before fill (int)\n",
    "\n",
    "    Returns:\n",
    "        dict: Exit record\n",
    "    \"\"\"\n",
    "\n",
    "        # Map exit_reason to state\n",
    "    exit_reason_to_state = {\n",
    "        'profit_target': 'CSP_CLOSED_PROFIT',\n",
    "        'stop_loss': 'CSP_CLOSED_STOP',\n",
    "        'expired_worthless': 'CSP_CLOSED_WORTHLESS',\n",
    "        'assigned': 'CSP_ASSIGNED',\n",
    "    }\n",
    "    state = exit_reason_to_state.get(exit_reason, 'CSP_OPEN')\n",
    "\n",
    "    return {\n",
    "        'wheel_id': wheel_id,  # ADD THIS LINE\n",
    "        'initial_capital': initial_capital,  # ADD THIS LINE\n",
    "        'state': state,  # ADD THIS LINE - map exit_reason to state\n",
    "        'symbol': symbol,\n",
    "        'entry_date': entry_date,\n",
    "        'exit_date': check_date.tz_localize(None) if hasattr(check_date, 'tz_localize') and check_date.tz else check_date,\n",
    "        'expiration': expiration_date,\n",
    "        'cost_basis': cost_basis,\n",
    "        'premium': premium,\n",
    "        'exit_pct': exit_pct,\n",
    "        'exit_price': exit_price,\n",
    "        'exit_reason': exit_reason,\n",
    "        'days_held': (check_date.tz_localize(None) - entry_date).days if check_date else None,\n",
    "        'daily_low': daily_row['low'] if daily_row is not None else None,\n",
    "        'daily_high': daily_row['high'] if daily_row is not None else None,\n",
    "        'touch_profit_target': touch_profit_target,\n",
    "        'p_fill_profit_target': p_fill_profit_target,\n",
    "        'u_fill_profit_target': u_fill_profit_target,\n",
    "        'filled_profit_target': filled_profit_target,\n",
    "        'spread_pct_entry': spread_pct_entry,\n",
    "        'ivp_entry': ivp_entry,\n",
    "        'touch_count': touch_count,\n",
    "        'fill_model': 'ohlc_touch_prob_v1',\n",
    "    }\n",
    "\n",
    "\n",
    "def calculate_pnl_metrics(exits_df, config):\n",
    "    \"\"\"\n",
    "    Calculate P&L metrics for exit results.\n",
    "\n",
    "    Args:\n",
    "        exits_df: DataFrame with exit records\n",
    "        config: Configuration dict with fee settings\n",
    "\n",
    "    Returns:\n",
    "        DataFrame with P&L metrics added\n",
    "    \"\"\"\n",
    "    if len(exits_df) > 0:\n",
    "        exits_df = exits_df.copy()\n",
    "        \n",
    "        # Calculate transaction costs based on exit reason\n",
    "        # Expired worthless = entry fee only (no buyback needed)\n",
    "        # All other exits = round-trip fees\n",
    "        exits_df['fees'] = exits_df['exit_reason'].apply(\n",
    "            lambda reason: get_transaction_costs(config, is_round_trip=(reason != 'expired_worthless'))\n",
    "        )\n",
    "        \n",
    "        # P&L after fees\n",
    "        exits_df['exit_pnl'] = exits_df['premium'] - exits_df['exit_price'] - exits_df['fees']\n",
    "        exits_df['exit_pnl_pct'] = (exits_df['exit_pnl'] / exits_df['premium']) * 100\n",
    "        exits_df['roc'] = (exits_df['exit_pnl'] / exits_df['cost_basis']) * 100\n",
    "        \n",
    "        # Summary stats\n",
    "        total_fees = exits_df['fees'].sum()\n",
    "        print(f\"\\n  Transaction costs: ${total_fees:.2f} total ({len(exits_df)} trades)\")\n",
    "\n",
    "    return exits_df\n",
    "\n",
    "\n",
    "def backtest_exit_strategy(backtest_candidates, client, config):\n",
    "    \"\"\"\n",
    "    Backtest exit strategy for wheel options with probabilistic fills.\n",
    "\n",
    "    Exit conditions:\n",
    "    1. Profit target: Exit when option price <= premium * exit_pct\n",
    "       - Uses probabilistic fill model: touch does not guarantee fill\n",
    "       - Loops through days until filled or expired\n",
    "    2. Stop-loss: Exit immediately when high >= stop threshold (p_fill=1.0)\n",
    "    3. Expiration: If no exit by expiration, option expires worthless\n",
    "\n",
    "    Args:\n",
    "        backtest_candidates: DataFrame with options to backtest\n",
    "        client: Databento client\n",
    "        config: Configuration dict\n",
    "\n",
    "    Returns:\n",
    "        DataFrame with exit results\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    \n",
    "    # Initialize RNG for reproducible fills\n",
    "    rng = np.random.RandomState(config.get('execution_seed', 42))\n",
    "    exits = []\n",
    "\n",
    "    for idx, row in backtest_candidates.iterrows():\n",
    "        symbol = row['symbol']\n",
    "\n",
    "                # Generate wheel_id for this candidate\n",
    "        wheel_id = generate_wheel_id()  # ADD THIS\n",
    "        initial_capital = row['cost_basis']  # ADD THIS (cost_basis = strike * 100)\n",
    "\n",
    "        # Normalize dates\n",
    "        entry_date = pd.Timestamp(row['date']).tz_localize(None)\n",
    "        expiration_date = pd.Timestamp(row['expiration']).tz_localize(None)\n",
    "\n",
    "        # Entry details - work with per-share prices for comparison, contract prices for P&L\n",
    "        premium_per_share = row['entry_price']  # Use entry_price (with slippage) not mid\n",
    "        premium = premium_per_share * 100  # Contract premium (100 shares per contract)\n",
    "        exit_pct = row['exit_pct']\n",
    "        exit_price_per_share = premium_per_share * exit_pct  # Per-share exit price (buy back at this price)\n",
    "        stop_loss_per_share = premium_per_share * config.get('stop_loss_multiplier', 2.0)\n",
    "        cost_basis = row['strike'] * 100  # Contract cost basis\n",
    "        liquidity_penalty = row.get('liquidity_penalty', 1.0)\n",
    "        \n",
    "        # Entry-time liquidity data for fill probability\n",
    "        spread_pct_entry = row.get('spread_pct_entry', 0.05)\n",
    "        ivp_entry = row.get('ivp_entry', 0.5)\n",
    "\n",
    "        print(f\"\\nProcessing {symbol}...\")\n",
    "        print(f\"  Entry: {entry_date.date()}, Premium: ${premium:.2f} (${premium_per_share:.2f}/share)\")\n",
    "        print(f\"  Exit target: ${exit_price_per_share*100:.2f} (${exit_price_per_share:.2f}/share, exit at {exit_pct*100:.0f}% of premium)\")\n",
    "        print(f\"  Stop loss: ${stop_loss_per_share*100:.2f} (${stop_loss_per_share:.2f}/share)\")\n",
    "\n",
    "        try:\n",
    "            # Fetch daily prices\n",
    "            df_daily = fetch_daily_prices_for_option(symbol, entry_date, expiration_date, client, config)\n",
    "\n",
    "            # Initialize tracking variables\n",
    "            touch_count = 0\n",
    "            touch_profit_target = False\n",
    "            filled_profit_target = False\n",
    "            p_fill_profit = None\n",
    "            u_fill_profit = None\n",
    "            exit_date = None\n",
    "            exit_daily_row = None\n",
    "            exit_reason = None\n",
    "            exit_price = None\n",
    "\n",
    "            # Compute fill probability once (based on entry-time liquidity)\n",
    "            if config.get('use_probabilistic_exit_fills', True):\n",
    "                p_fill_profit = compute_p_fill_profit(row, config)\n",
    "\n",
    "            # Loop through trading days until expiration\n",
    "            for check_date, daily_row in df_daily.iterrows():\n",
    "                # Normalize check_date\n",
    "                check_date_normalized = check_date.tz_localize(None) if hasattr(check_date, 'tz_localize') and check_date.tz else check_date\n",
    "                \n",
    "                # Skip entry date\n",
    "                if check_date_normalized.date() <= entry_date.date():\n",
    "                    continue\n",
    "\n",
    "                daily_low = daily_row['low']\n",
    "                daily_high = daily_row['high']\n",
    "\n",
    "                # Check stop-loss first (always fills with p_fill=1.0)\n",
    "                if daily_high >= stop_loss_per_share:\n",
    "                    exit_date = check_date_normalized\n",
    "                    exit_daily_row = daily_row\n",
    "                    exit_reason = 'stop_loss'\n",
    "                    # Stop-loss: calculate exit price with slippage\n",
    "                    actual_exit_per_share = get_exit_price(daily_row, config.get('fill_mode', 'realistic'), penalty=liquidity_penalty)\n",
    "                    exit_price = actual_exit_per_share * 100\n",
    "                    filled_profit_target = False  # Stop-loss is not a profit target fill\n",
    "                    print(f\"  ⚠ Stop-loss triggered on {exit_date.date()}\")\n",
    "                    print(f\"    Threshold: ${stop_loss_per_share:.2f}/share, Actual fill: ${actual_exit_per_share:.2f}/share\")\n",
    "                    break\n",
    "\n",
    "                # Check profit target touch\n",
    "                if daily_low <= exit_price_per_share:\n",
    "                    touch_profit_target = True\n",
    "                    touch_count += 1\n",
    "\n",
    "                    if config.get('use_probabilistic_exit_fills', True) and p_fill_profit is not None:\n",
    "                        # Probabilistic fill: draw random number\n",
    "                        filled, u = try_probabilistic_fill(p_fill_profit, rng)\n",
    "                        u_fill_profit = u\n",
    "\n",
    "                        if filled:\n",
    "                            # Fill successful - exit trade\n",
    "                            exit_date = check_date_normalized\n",
    "                            exit_daily_row = daily_row\n",
    "                            exit_reason = 'profit_target'\n",
    "                            filled_profit_target = True\n",
    "                            # Calculate exit price with slippage\n",
    "                            actual_exit_per_share = get_exit_price(daily_row, config.get('fill_mode', 'realistic'), penalty=liquidity_penalty)\n",
    "                            exit_price = actual_exit_per_share * 100\n",
    "                            print(f\"  ✓ Profit target hit on {exit_date.date()} (touch #{touch_count}, filled)\")\n",
    "                            print(f\"    Target: ${exit_price_per_share:.2f}/share, Actual fill: ${actual_exit_per_share:.2f}/share\")\n",
    "                            print(f\"    p_fill={p_fill_profit:.2f}, u={u:.3f}\")\n",
    "                            break\n",
    "                        else:\n",
    "                            # Touch but no fill - continue holding\n",
    "                            print(f\"    Touch #{touch_count} on {check_date_normalized.date()}: NO FILL (p_fill={p_fill_profit:.2f}, u={u:.3f})\")\n",
    "                    else:\n",
    "                        # Deterministic fill (legacy behavior)\n",
    "                        exit_date = check_date_normalized\n",
    "                        exit_daily_row = daily_row\n",
    "                        exit_reason = 'profit_target'\n",
    "                        filled_profit_target = True\n",
    "                        touch_count = 1\n",
    "                        actual_exit_per_share = get_exit_price(daily_row, config.get('fill_mode', 'realistic'), penalty=liquidity_penalty)\n",
    "                        exit_price = actual_exit_per_share * 100\n",
    "                        print(f\"  ✓ Profit target hit on {exit_date.date()} (deterministic)\")\n",
    "                        break\n",
    "\n",
    "            # Handle expiration if no exit occurred\n",
    "            if exit_date is None:\n",
    "                exit_date = expiration_date\n",
    "                exit_daily_row = None\n",
    "                exit_reason = 'expired_worthless'\n",
    "                exit_price = 0.0\n",
    "                print(f\"  🎉 Option expired worthless on {expiration_date.date()} - KEEP 100% PREMIUM!\")\n",
    "\n",
    "            # Create exit record with all tracking fields\n",
    "            exit_record = create_exit_record(\n",
    "                symbol, entry_date, expiration_date, premium, exit_pct,\n",
    "                exit_price, exit_reason, exit_date, exit_daily_row, cost_basis,\n",
    "                wheel_id=wheel_id, \n",
    "                initial_capital=initial_capital,\n",
    "                touch_profit_target=touch_profit_target,\n",
    "                p_fill_profit_target=p_fill_profit,\n",
    "                u_fill_profit_target=u_fill_profit,\n",
    "                filled_profit_target=filled_profit_target,\n",
    "                spread_pct_entry=spread_pct_entry,\n",
    "                ivp_entry=ivp_entry,\n",
    "                touch_count=touch_count if touch_profit_target else 0\n",
    "            )\n",
    "            exits.append(exit_record)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"  ✗ Error: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            continue\n",
    "\n",
    "    # Create results DataFrame and calculate P&L\n",
    "    exits_df = pd.DataFrame(exits)\n",
    "    exits_df = calculate_pnl_metrics(exits_df, config)\n",
    "\n",
    "    return exits_df\n",
    "\n",
    "# Run backtest (uses CONFIG from top of notebook)\n",
    "exits_df = backtest_exit_strategy(\n",
    "    backtest_candidates=backtest_candidates,\n",
    "    client=client,\n",
    "    config=CONFIG\n",
    ")\n",
    "\n",
    "# Display results\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"BACKTEST RESULTS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nTotal exits: {len(exits_df)}\")\n",
    "\n",
    "if len(exits_df) > 0:\n",
    "    print(f\"\\nExit reasons:\")\n",
    "    print(exits_df['exit_reason'].value_counts())\n",
    "    print(f\"\\nP&L Summary:\")\n",
    "    print(exits_df[['exit_pnl', 'exit_pnl_pct', 'roc']].describe())\n",
    "    \n",
    "    # Show sample\n",
    "    print(\"\\nSample exits:\")\n",
    "    print(exits_df[['symbol', 'entry_date', 'exit_date', 'premium', 'exit_price', \n",
    "                   'exit_pnl', 'roc', 'exit_reason']].head(10))\n",
    "else:\n",
    "    print(\"\\n⚠ No exits recorded - check for errors above\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ca4d8ee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "WHEEL MODULE: Assignment and Covered Call Functions Loaded\n",
      "============================================================\n",
      "  - handle_assignment(): Create assignment record from CSP exit\n",
      "  - fetch_option_chain_for_cc(): Fetch call chain for CC selection\n",
      "  - select_covered_call(): Select optimal call to sell\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# WHEEL MODULE: ASSIGNMENT HANDLER AND COVERED CALL SELECTION\n",
    "# =============================================================================\n",
    "\n",
    "def handle_assignment(csp_exit_record):\n",
    "    \"\"\"\n",
    "    Create assignment record when CSP expires ITM.\n",
    "    \n",
    "    This captures the state when a put is assigned and shares are received.\n",
    "    \n",
    "    NOTE: premium_kept is recorded for audit trail but is already \n",
    "    included in CSP P&L. Do not double-count in wheel totals.\n",
    "    \n",
    "    Args:\n",
    "        csp_exit_record: Dict from create_exit_record with exit_reason='assigned'\n",
    "    \n",
    "    Returns:\n",
    "        dict: Assignment record with stock position details\n",
    "    \"\"\"\n",
    "    strike = csp_exit_record['strike']\n",
    "    premium = csp_exit_record['premium']\n",
    "    net_stock_cost = strike * 100 - premium\n",
    "    \n",
    "    return {\n",
    "        'wheel_id': csp_exit_record['wheel_id'],\n",
    "        'symbol': csp_exit_record['symbol'].split()[0],  # Underlying (e.g., \"TSLA\")\n",
    "        'assignment_date': csp_exit_record['expiration'],\n",
    "        'strike': strike,\n",
    "        'shares': 100,\n",
    "        'assigned_price': strike,\n",
    "        'cash_used': strike * 100,\n",
    "        'premium_kept': premium,  # Audit only - already in CSP P&L\n",
    "        'net_stock_cost': net_stock_cost,\n",
    "        'stock_cost_per_share': net_stock_cost / 100,  # Derived field for CC strike constraint\n",
    "        'underlying_at_assignment': csp_exit_record.get('underlying_at_expiration'),\n",
    "        'initial_capital': csp_exit_record.get('initial_capital'),\n",
    "    }\n",
    "\n",
    "\n",
    "def fetch_option_chain_for_cc(underlying_symbol, entry_date, client, config, cc_config):\n",
    "    \"\"\"\n",
    "    Fetch call option chain for covered call selection.\n",
    "    \n",
    "    Args:\n",
    "        underlying_symbol: Underlying symbol (e.g., 'TSLA')\n",
    "        entry_date: Date to enter CC position\n",
    "        client: Databento client\n",
    "        config: Main CONFIG dict\n",
    "        cc_config: CC_CONFIG dict\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with call options meeting criteria, or empty DataFrame\n",
    "    \"\"\"\n",
    "    from py_vollib.black_scholes.implied_volatility import implied_volatility\n",
    "    from py_vollib.black_scholes.greeks.analytical import delta as calc_delta\n",
    "    import numpy as np\n",
    "    \n",
    "    cache_dir = config.get('cache_dir', '../cache/')\n",
    "    tz = config.get('timezone', 'America/New_York')\n",
    "    entry_time = cc_config.get('entry_time', '15:45')\n",
    "    \n",
    "    # Build entry timestamp\n",
    "    entry_ts = pd.Timestamp(f\"{entry_date.date()} {entry_time}\", tz=tz)\n",
    "    \n",
    "    # Cache filename\n",
    "    date_str = entry_ts.strftime('%Y%m%d')\n",
    "    time_str = entry_ts.strftime('%H%M')\n",
    "    cache_file = os.path.join(cache_dir, f\"options_{underlying_symbol}_{date_str}_{time_str}.parquet\")\n",
    "    \n",
    "    # Check cache first\n",
    "    if os.path.exists(cache_file):\n",
    "        print(f\"    [CACHE HIT] Loading options for CC selection on {entry_date.date()}\")\n",
    "        df_opts = pd.read_parquet(cache_file)\n",
    "    else:\n",
    "        print(f\"    [API] Fetching options for CC selection on {entry_date.date()}...\")\n",
    "        start = entry_ts\n",
    "        end = start + pd.Timedelta(minutes=1)\n",
    "        \n",
    "        try:\n",
    "            data = client.timeseries.get_range(\n",
    "                dataset='OPRA.PILLAR',\n",
    "                schema='cmbp-1',\n",
    "                symbols=f\"{underlying_symbol}.OPT\",\n",
    "                stype_in='parent',\n",
    "                start=start,\n",
    "                end=end,\n",
    "            )\n",
    "            df_opts = data.to_df(tz=tz).sort_values(\"ts_event\")\n",
    "            df_opts.to_parquet(cache_file)\n",
    "        except Exception as e:\n",
    "            print(f\"    Error fetching options: {e}\")\n",
    "            return pd.DataFrame()\n",
    "    \n",
    "    if len(df_opts) == 0:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # Parse option symbols\n",
    "    sym = df_opts[\"symbol\"]\n",
    "    root_and_code = sym.str.split(expand=True)\n",
    "    df_opts[\"root\"] = root_and_code[0]\n",
    "    code = root_and_code[1]\n",
    "    df_opts[\"expiration\"] = pd.to_datetime(code.str[:6], format=\"%y%m%d\")\n",
    "    df_opts[\"call_put\"] = code.str[6]\n",
    "    strike_int = code.str[7:].astype(\"int32\")\n",
    "    df_opts[\"strike\"] = strike_int / 1000.0\n",
    "    expiration_tz = df_opts[\"expiration\"].dt.tz_localize(df_opts[\"ts_event\"].dt.tz)\n",
    "    df_opts[\"dte\"] = (expiration_tz - df_opts[\"ts_event\"].dt.normalize()).dt.days\n",
    "    \n",
    "    # Filter to calls only with valid quotes\n",
    "    calls = df_opts[\n",
    "        (df_opts['call_put'] == 'C') &\n",
    "        (df_opts['bid_px_00'].notna()) &\n",
    "        (df_opts['ask_px_00'].notna()) &\n",
    "        (df_opts['dte'] >= cc_config['dte_min']) &\n",
    "        (df_opts['dte'] <= cc_config['dte_max'])\n",
    "    ].copy()\n",
    "    \n",
    "    if len(calls) == 0:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # Compute mid price\n",
    "    calls['mid'] = (calls['bid_px_00'] + calls['ask_px_00']) / 2\n",
    "    calls['spread'] = calls['ask_px_00'] - calls['bid_px_00']\n",
    "    calls['spread_pct'] = calls['spread'] / calls['mid']\n",
    "    \n",
    "    # Get last quote per contract\n",
    "    calls = calls.sort_values(\"ts_event\").groupby(\n",
    "        [\"symbol\", \"expiration\", \"strike\", \"call_put\"]\n",
    "    ).tail(1).copy()\n",
    "    \n",
    "    # Get underlying price\n",
    "    equity_cache = os.path.join(cache_dir, f\"equity_minute_{underlying_symbol}_{date_str}_{time_str}.parquet\")\n",
    "    if os.path.exists(equity_cache):\n",
    "        equity_df = pd.read_parquet(equity_cache)\n",
    "        underlying_price = equity_df['close'].iloc[-1] if len(equity_df) > 0 else None\n",
    "    else:\n",
    "        underlying_price = None\n",
    "    \n",
    "    if underlying_price is None:\n",
    "        print(f\"    Warning: Could not get underlying price for delta calc\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    calls['underlying_last'] = underlying_price\n",
    "    \n",
    "    # Compute IV and delta\n",
    "    r = 0.04  # Risk-free rate\n",
    "    \n",
    "    def compute_iv_delta(row):\n",
    "        price = row['mid']\n",
    "        S = row['underlying_last']\n",
    "        K = row['strike']\n",
    "        t = row['dte'] / 365.0\n",
    "        \n",
    "        if not (np.isfinite(price) and np.isfinite(S) and np.isfinite(K) and t > 0):\n",
    "            return np.nan, np.nan\n",
    "        if price <= 0 or S <= 0 or K <= 0:\n",
    "            return np.nan, np.nan\n",
    "        \n",
    "        try:\n",
    "            iv = implied_volatility(price, S, K, t, r, 'c')\n",
    "            d = abs(calc_delta('c', S, K, t, r, iv))\n",
    "            return iv, d\n",
    "        except Exception:\n",
    "            return np.nan, np.nan\n",
    "    \n",
    "    iv_delta = calls.apply(compute_iv_delta, axis=1, result_type='expand')\n",
    "    calls['iv'] = iv_delta[0]\n",
    "    calls['delta'] = iv_delta[1]\n",
    "    \n",
    "    # Filter by delta\n",
    "    calls = calls[\n",
    "        calls['delta'].between(cc_config['delta_min'], cc_config['delta_max'])\n",
    "    ].copy()\n",
    "    \n",
    "    return calls\n",
    "\n",
    "\n",
    "def select_covered_call(assignment_record, option_chain, cc_config, config):\n",
    "    \"\"\"\n",
    "    Select covered call to sell after assignment.\n",
    "    \n",
    "    Args:\n",
    "        assignment_record: Dict from handle_assignment()\n",
    "        option_chain: DataFrame with call options (from fetch_option_chain_for_cc)\n",
    "        cc_config: CC_CONFIG dict\n",
    "        config: Main CONFIG dict\n",
    "    \n",
    "    Returns:\n",
    "        Series with selected call, or None if no suitable call found\n",
    "    \"\"\"\n",
    "    if len(option_chain) == 0:\n",
    "        return None\n",
    "    \n",
    "    stock_cost_per_share = assignment_record['stock_cost_per_share']\n",
    "    \n",
    "    # Filter by strike constraint if enabled\n",
    "    if cc_config.get('sell_call_only_if_price_above_basis', True):\n",
    "        candidates = option_chain[\n",
    "            option_chain['strike'] >= stock_cost_per_share\n",
    "        ].copy()\n",
    "    else:\n",
    "        candidates = option_chain.copy()\n",
    "    \n",
    "    if len(candidates) == 0:\n",
    "        print(f\"    No calls with strike >= cost basis ${stock_cost_per_share:.2f}\")\n",
    "        return None\n",
    "    \n",
    "    # Apply liquidity model\n",
    "    candidates = apply_liquidity_model(candidates, config)\n",
    "    \n",
    "    if len(candidates) == 0:\n",
    "        print(f\"    No calls passed liquidity filter\")\n",
    "        return None\n",
    "    \n",
    "    # Tie-breaking\n",
    "    method = cc_config.get('tie_break_method', 'highest_premium')\n",
    "    \n",
    "    if method == 'highest_premium':\n",
    "        selected = candidates.loc[candidates['mid'].idxmax()]\n",
    "    elif method == 'closest_delta':\n",
    "        target_delta = (cc_config['delta_min'] + cc_config['delta_max']) / 2\n",
    "        candidates['delta_dist'] = (candidates['delta'].abs() - target_delta).abs()\n",
    "        selected = candidates.loc[candidates['delta_dist'].idxmin()]\n",
    "    elif method == 'highest_strike':\n",
    "        selected = candidates.loc[candidates['strike'].idxmax()]\n",
    "    else:\n",
    "        selected = candidates.iloc[0]  # Fallback\n",
    "    \n",
    "    print(f\"    Selected CC: {selected['symbol']}\")\n",
    "    print(f\"      Strike: ${selected['strike']:.2f}, Delta: {selected['delta']:.3f}, Premium: ${selected['mid']:.2f}/share\")\n",
    "    print(f\"      DTE: {selected['dte']}, Expiration: {selected['expiration'].date()}\")\n",
    "    \n",
    "    return selected\n",
    "\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"WHEEL MODULE: Assignment and Covered Call Functions Loaded\")\n",
    "print(\"=\" * 60)\n",
    "print(\"  - handle_assignment(): Create assignment record from CSP exit\")\n",
    "print(\"  - fetch_option_chain_for_cc(): Fetch call chain for CC selection\")\n",
    "print(\"  - select_covered_call(): Select optimal call to sell\")\n",
    "print(\"=\" * 60)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "df4ee937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "COVERED CALL BACKTEST FUNCTION LOADED\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# COVERED CALL BACKTEST FUNCTION\n",
    "# =============================================================================\n",
    "\n",
    "def backtest_covered_call(assignment_record, cc_selection, client, config, cc_config):\n",
    "    \"\"\"\n",
    "    Backtest a covered call position after assignment.\n",
    "    \n",
    "    Uses same exit framework as CSP with CC-specific adjustments:\n",
    "    - Profit target: Buy back call at cc_config exit_pct\n",
    "    - Stop loss: Not typically used for CC (we own the shares)\n",
    "    - Called away: Underlying >= strike at expiration\n",
    "    - Expired worthless: Underlying < strike at expiration\n",
    "    \n",
    "    Args:\n",
    "        assignment_record: Dict from handle_assignment()\n",
    "        cc_selection: Series from select_covered_call()\n",
    "        client: Databento client\n",
    "        config: Main CONFIG dict\n",
    "        cc_config: CC_CONFIG dict\n",
    "    \n",
    "    Returns:\n",
    "        dict: Exit record for covered call phase\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    \n",
    "    wheel_id = assignment_record['wheel_id']\n",
    "    underlying_symbol = assignment_record['symbol']\n",
    "    initial_capital = assignment_record['initial_capital']\n",
    "    net_stock_cost = assignment_record['net_stock_cost']\n",
    "    \n",
    "    symbol = cc_selection['symbol']\n",
    "    strike = cc_selection['strike']\n",
    "    expiration_date = pd.Timestamp(cc_selection['expiration']).tz_localize(None)\n",
    "    \n",
    "    # Entry details\n",
    "    entry_date = assignment_record['assignment_date']\n",
    "    if hasattr(entry_date, 'tz') and entry_date.tz:\n",
    "        entry_date = entry_date.tz_localize(None)\n",
    "    \n",
    "    # CC entry is next trading day after assignment\n",
    "    # For simplicity, use assignment date as CC entry (could be refined with market calendar)\n",
    "    cc_entry_date = pd.Timestamp(entry_date) + pd.Timedelta(days=1)\n",
    "    cc_entry_date = cc_entry_date.tz_localize(None)\n",
    "    \n",
    "    # Calculate entry price with liquidity penalty\n",
    "    liquidity_penalty = cc_selection.get('liquidity_penalty', 1.0)\n",
    "    premium_per_share = get_entry_price(cc_selection, config['fill_mode'], liquidity_penalty)\n",
    "    premium = premium_per_share * 100\n",
    "    cost_basis = strike * 100  # CC cost basis is the strike\n",
    "    \n",
    "    # Exit parameters (use main config for exit_pct)\n",
    "    exit_pct = config.get('exit_pct', 0.50)\n",
    "    exit_price_per_share = premium_per_share * exit_pct\n",
    "    \n",
    "    # Initialize state\n",
    "    current_state = advance_wheel_state('CSP_ASSIGNED', 'sell_call')  # CSP_ASSIGNED → CC_OPEN\n",
    "    \n",
    "    print(f\"\\n  CC Position: {symbol}\")\n",
    "    print(f\"    Wheel ID: {wheel_id}, State: {current_state}\")\n",
    "    print(f\"    Entry: {cc_entry_date.date()}, Strike: ${strike:.2f}, Premium: ${premium:.2f}\")\n",
    "    print(f\"    Exit target: ${exit_price_per_share*100:.2f} (${exit_price_per_share:.2f}/share)\")\n",
    "    \n",
    "    # Initialize RNG\n",
    "    rng = np.random.RandomState(config.get('execution_seed', 42) + hash(wheel_id) % 1000)\n",
    "    \n",
    "    # Tracking variables\n",
    "    touch_count = 0\n",
    "    touch_profit_target = False\n",
    "    filled_profit_target = False\n",
    "    p_fill_profit = None\n",
    "    u_fill_profit = None\n",
    "    exit_date = None\n",
    "    exit_daily_row = None\n",
    "    exit_reason = None\n",
    "    exit_price = None\n",
    "    underlying_at_exp = None\n",
    "    \n",
    "    try:\n",
    "        # Fetch daily prices for the call option\n",
    "        df_daily = fetch_daily_prices_for_option(symbol, cc_entry_date, expiration_date, client, config)\n",
    "        \n",
    "        # Compute fill probability\n",
    "        if config.get('use_probabilistic_exit_fills', True):\n",
    "            p_fill_profit = compute_p_fill_profit(cc_selection, config)\n",
    "        \n",
    "        # Loop through trading days\n",
    "        for check_date, daily_row in df_daily.iterrows():\n",
    "            check_date_normalized = check_date.tz_localize(None) if hasattr(check_date, 'tz_localize') and check_date.tz else check_date\n",
    "            \n",
    "            if check_date_normalized.date() <= cc_entry_date.date():\n",
    "                continue\n",
    "            \n",
    "            daily_low = daily_row['low']\n",
    "            daily_high = daily_row['high']\n",
    "            \n",
    "            # Check profit target (call decays)\n",
    "            if daily_low <= exit_price_per_share:\n",
    "                touch_profit_target = True\n",
    "                touch_count += 1\n",
    "                \n",
    "                if config.get('use_probabilistic_exit_fills', True) and p_fill_profit is not None:\n",
    "                    filled, u = try_probabilistic_fill(p_fill_profit, rng)\n",
    "                    u_fill_profit = u\n",
    "                    \n",
    "                    if filled:\n",
    "                        exit_date = check_date_normalized\n",
    "                        exit_daily_row = daily_row\n",
    "                        exit_reason = 'profit_target'\n",
    "                        current_state = advance_wheel_state(current_state, 'profit_target')\n",
    "                        filled_profit_target = True\n",
    "                        actual_exit_per_share = get_exit_price(daily_row, config.get('fill_mode', 'realistic'), penalty=liquidity_penalty)\n",
    "                        exit_price = actual_exit_per_share * 100\n",
    "                        print(f\"    ✓ CC profit target on {exit_date.date()} → State: {current_state}\")\n",
    "                        break\n",
    "                else:\n",
    "                    exit_date = check_date_normalized\n",
    "                    exit_daily_row = daily_row\n",
    "                    exit_reason = 'profit_target'\n",
    "                    current_state = advance_wheel_state(current_state, 'profit_target')\n",
    "                    filled_profit_target = True\n",
    "                    actual_exit_per_share = get_exit_price(daily_row, config.get('fill_mode', 'realistic'), penalty=liquidity_penalty)\n",
    "                    exit_price = actual_exit_per_share * 100\n",
    "                    print(f\"    ✓ CC profit target on {exit_date.date()} (deterministic) → State: {current_state}\")\n",
    "                    break\n",
    "        \n",
    "        # Handle expiration - check for assignment\n",
    "        if exit_date is None:\n",
    "            exit_date = expiration_date\n",
    "            exit_daily_row = None\n",
    "            exit_price = 0.0\n",
    "            \n",
    "            # Fetch underlying price at expiration\n",
    "            underlying_at_exp = fetch_underlying_price_at_expiration(\n",
    "                underlying_symbol, expiration_date, client, config\n",
    "            )\n",
    "            \n",
    "            if underlying_at_exp is not None:\n",
    "                # For calls: ITM when underlying >= strike → called away\n",
    "                if underlying_at_exp >= strike:\n",
    "                    exit_reason = 'called_away'\n",
    "                    current_state = advance_wheel_state(current_state, 'called_away')\n",
    "                    print(f\"    📤 CC CALLED AWAY on {expiration_date.date()} → State: {current_state}\")\n",
    "                    print(f\"      Underlying: ${underlying_at_exp:.2f} >= Strike: ${strike:.2f}\")\n",
    "                else:\n",
    "                    exit_reason = 'expired_worthless'\n",
    "                    current_state = advance_wheel_state(current_state, 'expired_worthless')\n",
    "                    print(f\"    🎉 CC expired worthless on {expiration_date.date()} → State: {current_state}\")\n",
    "            else:\n",
    "                exit_reason = 'expired_worthless'\n",
    "                current_state = advance_wheel_state(current_state, 'expired_worthless')\n",
    "                print(f\"    CC expired (assumed worthless) → State: {current_state}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"    ✗ CC Error: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        exit_date = expiration_date\n",
    "        exit_reason = 'error'\n",
    "        exit_price = 0.0\n",
    "        current_state = 'CC_CLOSED_WORTHLESS'\n",
    "    \n",
    "    # Create exit record\n",
    "    cc_exit_record = {\n",
    "        'wheel_id': wheel_id,\n",
    "        'phase': 'cc',\n",
    "        'state': current_state,\n",
    "        'symbol': symbol,\n",
    "        'strike': strike,\n",
    "        'entry_date': cc_entry_date,\n",
    "        'exit_date': exit_date,\n",
    "        'expiration': expiration_date,\n",
    "        'cost_basis': cost_basis,\n",
    "        'initial_capital': initial_capital,\n",
    "        'premium': premium,\n",
    "        'exit_pct': exit_pct,\n",
    "        'exit_price': exit_price,\n",
    "        'exit_reason': exit_reason,\n",
    "        'days_held': (exit_date - cc_entry_date).days if exit_date else None,\n",
    "        'underlying_at_expiration': underlying_at_exp,\n",
    "        'daily_low': exit_daily_row['low'] if exit_daily_row is not None else None,\n",
    "        'daily_high': exit_daily_row['high'] if exit_daily_row is not None else None,\n",
    "        'touch_profit_target': touch_profit_target,\n",
    "        'p_fill_profit_target': p_fill_profit,\n",
    "        'u_fill_profit_target': u_fill_profit,\n",
    "        'filled_profit_target': filled_profit_target,\n",
    "        'touch_count': touch_count,\n",
    "        'fill_model': 'ohlc_touch_prob_v1',\n",
    "        # Stock position info for P&L\n",
    "        'net_stock_cost': net_stock_cost,\n",
    "    }\n",
    "    \n",
    "    return cc_exit_record, current_state\n",
    "\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"COVERED CALL BACKTEST FUNCTION LOADED\")\n",
    "print(\"=\" * 60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "76c84167",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "WHEEL ORCHESTRATION FUNCTIONS LOADED\n",
      "============================================================\n",
      "  - calculate_wheel_pnl(): Calculate complete wheel P&L\n",
      "  - run_full_wheel_backtest(): Process CSP exits and handle CCs\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# WHEEL ORCHESTRATION AND P&L CALCULATION\n",
    "# =============================================================================\n",
    "\n",
    "def calculate_wheel_pnl(csp_exit, cc_exit=None, assignment_record=None):\n",
    "    \"\"\"\n",
    "    Calculate complete wheel P&L including CSP, CC, and stock legs.\n",
    "    \n",
    "    P&L Components:\n",
    "    - CSP P&L: premium - exit_price - fees (already calculated)\n",
    "    - CC P&L: call_premium - exit_price - call_fees\n",
    "    - Stock P&L: (call_strike * 100) - net_stock_cost (only if called away)\n",
    "    \n",
    "    Wheel-level ROC is based on initial CSP capital (strike * 100).\n",
    "    \n",
    "    Args:\n",
    "        csp_exit: CSP exit record dict\n",
    "        cc_exit: CC exit record dict (optional, only if assigned)\n",
    "        assignment_record: Assignment record dict (optional, only if assigned)\n",
    "    \n",
    "    Returns:\n",
    "        dict: Wheel summary with total P&L\n",
    "    \"\"\"\n",
    "    wheel_id = csp_exit['wheel_id']\n",
    "    initial_capital = csp_exit.get('initial_capital', csp_exit['cost_basis'])\n",
    "    \n",
    "    # CSP P&L\n",
    "    csp_premium = csp_exit['premium']\n",
    "    csp_exit_price = csp_exit['exit_price']\n",
    "    csp_fees = get_transaction_costs(CONFIG, is_round_trip=(csp_exit['exit_reason'] not in ['expired_worthless', 'assigned']))\n",
    "    csp_pnl = csp_premium - csp_exit_price - csp_fees\n",
    "    \n",
    "    # Initialize totals\n",
    "    cc_pnl = 0.0\n",
    "    stock_pnl = 0.0\n",
    "    cc_fees = 0.0\n",
    "    total_days = csp_exit.get('days_held', 0) or 0\n",
    "    \n",
    "    # CC P&L (if applicable)\n",
    "    if cc_exit is not None:\n",
    "        cc_premium = cc_exit['premium']\n",
    "        cc_exit_price = cc_exit['exit_price']\n",
    "        cc_fees = get_transaction_costs(CONFIG, is_round_trip=(cc_exit['exit_reason'] not in ['expired_worthless', 'called_away']))\n",
    "        cc_pnl = cc_premium - cc_exit_price - cc_fees\n",
    "        total_days += cc_exit.get('days_held', 0) or 0\n",
    "        \n",
    "        # Stock P&L (only if called away)\n",
    "        if cc_exit['exit_reason'] == 'called_away' and assignment_record is not None:\n",
    "            net_stock_cost = assignment_record['net_stock_cost']\n",
    "            call_strike = cc_exit['strike']\n",
    "            stock_pnl = (call_strike * 100) - net_stock_cost\n",
    "    \n",
    "    # Total wheel P&L\n",
    "    total_pnl = csp_pnl + cc_pnl + stock_pnl\n",
    "    total_fees = csp_fees + cc_fees\n",
    "    \n",
    "    # ROC calculations\n",
    "    csp_roc = (csp_pnl / initial_capital) * 100\n",
    "    wheel_roc = (total_pnl / initial_capital) * 100\n",
    "    \n",
    "    # Determine final state using state machine\n",
    "    if cc_exit is not None:\n",
    "        # CC was processed - use CC's final state or advance to complete\n",
    "        cc_state = cc_exit.get('state', 'CC_ASSIGNED')\n",
    "        if cc_state == 'WHEEL_COMPLETE':\n",
    "            final_state = 'WHEEL_COMPLETE'\n",
    "        else:\n",
    "            final_state = advance_wheel_state(cc_state, 'complete')\n",
    "    else:\n",
    "        # No CC processed - advance CSP state to complete\n",
    "        # This works for both assigned (incomplete) and non-assigned CSPs\n",
    "        final_state = advance_wheel_state(csp_exit['state'], 'complete')\n",
    "    \n",
    "    return {\n",
    "        'wheel_id': wheel_id,\n",
    "        'phase': 'total',\n",
    "        'state': final_state,\n",
    "        'initial_capital': initial_capital,\n",
    "        \n",
    "        # CSP details\n",
    "        'csp_premium': csp_premium,\n",
    "        'csp_exit_price': csp_exit_price,\n",
    "        'csp_pnl': csp_pnl,\n",
    "        'csp_fees': csp_fees,\n",
    "        \n",
    "        # CC details\n",
    "        'cc_premium': cc_exit['premium'] if cc_exit else 0.0,\n",
    "        'cc_exit_price': cc_exit['exit_price'] if cc_exit else 0.0,\n",
    "        'cc_pnl': cc_pnl,\n",
    "        'cc_fees': cc_fees,\n",
    "        \n",
    "        # Stock details\n",
    "        'stock_pnl': stock_pnl,\n",
    "        \n",
    "        # Totals\n",
    "        'total_pnl': total_pnl,\n",
    "        'total_fees': total_fees,\n",
    "        'csp_roc': csp_roc,\n",
    "        'wheel_roc': wheel_roc,\n",
    "        'total_days': total_days,\n",
    "        \n",
    "        # Exit info\n",
    "        'csp_exit_reason': csp_exit['exit_reason'],\n",
    "        'cc_exit_reason': cc_exit['exit_reason'] if cc_exit else None,\n",
    "    }\n",
    "\n",
    "\n",
    "def run_full_wheel_backtest(csp_exits_df, client, config, cc_config):\n",
    "    \"\"\"\n",
    "    Run full wheel backtest: process CSP exits and handle assignments with CC.\n",
    "    \n",
    "    For each CSP that was assigned:\n",
    "    1. Create assignment record\n",
    "    2. Fetch call chain for next trading day\n",
    "    3. Select covered call\n",
    "    4. Backtest CC position\n",
    "    5. Calculate wheel P&L\n",
    "    \n",
    "    Args:\n",
    "        csp_exits_df: DataFrame with CSP exit records\n",
    "        client: Databento client\n",
    "        config: Main CONFIG dict\n",
    "        cc_config: CC_CONFIG dict\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (all_exits_df, wheel_summaries_df)\n",
    "    \"\"\"\n",
    "    all_exits = []\n",
    "    wheel_summaries = []\n",
    "    \n",
    "    for idx, csp_exit in csp_exits_df.iterrows():\n",
    "        # Convert row to dict\n",
    "        csp_exit_dict = csp_exit.to_dict()\n",
    "        all_exits.append(csp_exit_dict)\n",
    "        \n",
    "        # Check if assigned\n",
    "        if csp_exit['exit_reason'] != 'assigned':\n",
    "            # No assignment - calculate simple wheel P&L (CSP only)\n",
    "            wheel_summary = calculate_wheel_pnl(csp_exit_dict)\n",
    "            wheel_summaries.append(wheel_summary)\n",
    "            print(f\"\\n  Wheel {csp_exit['wheel_id']}: CSP {csp_exit['exit_reason']} → {wheel_summary['state']}\")\n",
    "            print(f\"    CSP P&L: ${wheel_summary['csp_pnl']:.2f}, ROC: {wheel_summary['csp_roc']:.2f}%\")\n",
    "            continue\n",
    "        \n",
    "        # Handle assignment\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"PROCESSING ASSIGNMENT: Wheel {csp_exit['wheel_id']}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        assignment_record = handle_assignment(csp_exit_dict)\n",
    "        print(f\"  Assignment: {assignment_record['shares']} shares at ${assignment_record['strike']:.2f}\")\n",
    "        print(f\"  Net stock cost: ${assignment_record['net_stock_cost']:.2f} (${assignment_record['stock_cost_per_share']:.2f}/share)\")\n",
    "        \n",
    "        # Fetch call chain for CC selection (next trading day)\n",
    "        underlying_symbol = assignment_record['symbol']\n",
    "        cc_entry_date = pd.Timestamp(assignment_record['assignment_date']) + pd.Timedelta(days=1)\n",
    "        \n",
    "        call_chain = fetch_option_chain_for_cc(\n",
    "            underlying_symbol, cc_entry_date, client, config, cc_config\n",
    "        )\n",
    "        \n",
    "        if len(call_chain) == 0:\n",
    "            print(f\"    ⚠ No suitable calls found - wheel incomplete\")\n",
    "            wheel_summary = calculate_wheel_pnl(csp_exit_dict)\n",
    "            wheel_summaries.append(wheel_summary)\n",
    "            continue\n",
    "        \n",
    "        # Select covered call\n",
    "        cc_selection = select_covered_call(assignment_record, call_chain, cc_config, config)\n",
    "        \n",
    "        if cc_selection is None:\n",
    "            print(f\"    ⚠ No call selected - wheel incomplete\")\n",
    "            wheel_summary = calculate_wheel_pnl(csp_exit_dict)\n",
    "            wheel_summaries.append(wheel_summary)\n",
    "            continue\n",
    "        \n",
    "        # Backtest covered call\n",
    "        cc_exit_dict, final_cc_state = backtest_covered_call(\n",
    "            assignment_record, cc_selection, client, config, cc_config\n",
    "        )\n",
    "        all_exits.append(cc_exit_dict)\n",
    "        \n",
    "        # Calculate complete wheel P&L\n",
    "        wheel_summary = calculate_wheel_pnl(csp_exit_dict, cc_exit_dict, assignment_record)\n",
    "        wheel_summaries.append(wheel_summary)\n",
    "        \n",
    "        print(f\"\\n  WHEEL COMPLETE: {wheel_summary['wheel_id']}\")\n",
    "        print(f\"    CSP P&L:   ${wheel_summary['csp_pnl']:.2f}\")\n",
    "        print(f\"    CC P&L:    ${wheel_summary['cc_pnl']:.2f}\")\n",
    "        print(f\"    Stock P&L: ${wheel_summary['stock_pnl']:.2f}\")\n",
    "        print(f\"    ────────────────────────\")\n",
    "        print(f\"    TOTAL:     ${wheel_summary['total_pnl']:.2f} ({wheel_summary['wheel_roc']:.2f}% ROC)\")\n",
    "        print(f\"    Days:      {wheel_summary['total_days']}\")\n",
    "    \n",
    "    # Create DataFrames\n",
    "    all_exits_df = pd.DataFrame(all_exits)\n",
    "    wheel_summaries_df = pd.DataFrame(wheel_summaries)\n",
    "    \n",
    "    return all_exits_df, wheel_summaries_df\n",
    "\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"WHEEL ORCHESTRATION FUNCTIONS LOADED\")\n",
    "print(\"=\" * 60)\n",
    "print(\"  - calculate_wheel_pnl(): Calculate complete wheel P&L\")\n",
    "print(\"  - run_full_wheel_backtest(): Process CSP exits and handle CCs\")\n",
    "print(\"=\" * 60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "215dcbc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "V5 SINGLE WHEEL WRAPPER LOADED\n",
      "============================================================\n",
      "  - run_single_wheel(candidate, config, cc_config, wheel_id, client)\n",
      "  - run_csp_backtest_silent(backtest_candidates, client, config, wheel_id)\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# V5 SINGLE WHEEL WRAPPER\n",
    "# =============================================================================\n",
    "# Wraps the existing wheel engine to process a single candidate\n",
    "\n",
    "def run_single_wheel(candidate, config, cc_config, wheel_id, client):\n",
    "    \"\"\"\n",
    "    Run a complete wheel cycle for a single CSP candidate.\n",
    "    \n",
    "    This wrapper:\n",
    "    1. Calls backtest_exit_strategy() for CSP lifecycle\n",
    "    2. If assigned, handles CC phase via existing functions\n",
    "    3. Calculates wheel P&L\n",
    "    4. Stamps results with execution_version for downstream tracking\n",
    "    \n",
    "    Args:\n",
    "        candidate: Series with CSP candidate data (from get_entry_candidates)\n",
    "        config: CONFIG dict\n",
    "        cc_config: CC_CONFIG dict\n",
    "        wheel_id: Unique identifier for this wheel instance\n",
    "        client: Databento client\n",
    "    \n",
    "    Returns:\n",
    "        List[dict]: Exit records for this wheel (CSP + optional CC + summary)\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    \n",
    "    # Convert candidate Series to single-row DataFrame for backtest_exit_strategy\n",
    "    candidate_df = pd.DataFrame([candidate])\n",
    "    \n",
    "    # Initialize RNG with unique seed per wheel\n",
    "    wheel_seed = config.get('execution_seed', 42) + hash(wheel_id) % 10000\n",
    "    \n",
    "    # Create a copy of config with wheel-specific seed\n",
    "    wheel_config = config.copy()\n",
    "    wheel_config['execution_seed'] = wheel_seed\n",
    "    \n",
    "    # Run CSP backtest (silent version)\n",
    "    csp_exit = run_csp_backtest_silent(candidate_df, client, wheel_config, wheel_id)\n",
    "    \n",
    "    if csp_exit is None:\n",
    "        return []\n",
    "    \n",
    "    wheel_results = []\n",
    "    \n",
    "    # Add CSP exit with phase marker\n",
    "    csp_exit['phase'] = 'csp'\n",
    "    csp_exit['execution_version'] = 'v5_scheduler'\n",
    "    wheel_results.append(csp_exit)\n",
    "    \n",
    "    # Check if assigned\n",
    "    if csp_exit['exit_reason'] == 'assigned':\n",
    "        # Handle assignment and CC\n",
    "        assignment_record = handle_assignment(csp_exit)\n",
    "        \n",
    "        # Fetch call chain\n",
    "        underlying_symbol = assignment_record['symbol']\n",
    "        cc_entry_date = pd.Timestamp(assignment_record['assignment_date']) + pd.Timedelta(days=1)\n",
    "        \n",
    "        call_chain = fetch_option_chain_for_cc(\n",
    "            underlying_symbol, cc_entry_date, client, config, cc_config\n",
    "        )\n",
    "        \n",
    "        if len(call_chain) > 0:\n",
    "            cc_selection = select_covered_call(assignment_record, call_chain, cc_config, config)\n",
    "            \n",
    "            if cc_selection is not None:\n",
    "                cc_exit, _ = backtest_covered_call(\n",
    "                    assignment_record, cc_selection, client, wheel_config, cc_config\n",
    "                )\n",
    "                cc_exit['execution_version'] = 'v5_scheduler'\n",
    "                wheel_results.append(cc_exit)\n",
    "                \n",
    "                # Calculate wheel P&L with CC\n",
    "                wheel_summary = calculate_wheel_pnl(csp_exit, cc_exit, assignment_record)\n",
    "            else:\n",
    "                # No CC selected\n",
    "                wheel_summary = calculate_wheel_pnl(csp_exit)\n",
    "        else:\n",
    "            # No call chain available\n",
    "            wheel_summary = calculate_wheel_pnl(csp_exit)\n",
    "    else:\n",
    "        # Not assigned - simple CSP wheel\n",
    "        wheel_summary = calculate_wheel_pnl(csp_exit)\n",
    "    \n",
    "    # Add summary with execution version\n",
    "    wheel_summary['execution_version'] = 'v5_scheduler'\n",
    "    wheel_results.append(wheel_summary)\n",
    "    \n",
    "    return wheel_results\n",
    "\n",
    "\n",
    "def run_csp_backtest_silent(backtest_candidates, client, config, wheel_id):\n",
    "    \"\"\"\n",
    "    Run CSP backtest for a single candidate, returning dict instead of DataFrame.\n",
    "    Silent version for scheduler use.\n",
    "    \n",
    "    Args:\n",
    "        backtest_candidates: Single-row DataFrame with CSP candidate\n",
    "        client: Databento client\n",
    "        config: CONFIG dict\n",
    "        wheel_id: Wheel identifier\n",
    "    \n",
    "    Returns:\n",
    "        dict: Exit record for the CSP, or None if error\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    \n",
    "    rng = np.random.RandomState(config.get('execution_seed', 42))\n",
    "    \n",
    "    for idx, row in backtest_candidates.iterrows():\n",
    "        symbol = row['symbol']\n",
    "        initial_capital = row['cost_basis']\n",
    "        \n",
    "        # Normalize dates\n",
    "        entry_date = pd.Timestamp(row['date']).tz_localize(None)\n",
    "        expiration_date = pd.Timestamp(row['expiration']).tz_localize(None)\n",
    "        \n",
    "        # Entry details\n",
    "        premium_per_share = row['entry_price']\n",
    "        premium = premium_per_share * 100\n",
    "        exit_pct = row['exit_pct']\n",
    "        exit_price_per_share = premium_per_share * exit_pct\n",
    "        stop_loss_per_share = premium_per_share * config.get('stop_loss_multiplier', 2.0)\n",
    "        cost_basis = row['strike'] * 100\n",
    "        liquidity_penalty = row.get('liquidity_penalty', 1.0)\n",
    "        spread_pct_entry = row.get('spread_pct_entry', 0.05)\n",
    "        ivp_entry = row.get('ivp_entry', 0.5)\n",
    "        \n",
    "        try:\n",
    "            df_daily = fetch_daily_prices_for_option(symbol, entry_date, expiration_date, client, config)\n",
    "            \n",
    "            touch_count = 0\n",
    "            touch_profit_target = False\n",
    "            filled_profit_target = False\n",
    "            p_fill_profit = None\n",
    "            u_fill_profit = None\n",
    "            exit_date = None\n",
    "            exit_daily_row = None\n",
    "            exit_reason = None\n",
    "            exit_price = None\n",
    "            \n",
    "            if config.get('use_probabilistic_exit_fills', True):\n",
    "                p_fill_profit = compute_p_fill_profit(row, config)\n",
    "            \n",
    "            for check_date, daily_row in df_daily.iterrows():\n",
    "                check_date_normalized = check_date.tz_localize(None) if hasattr(check_date, 'tz_localize') and check_date.tz else check_date\n",
    "                \n",
    "                if check_date_normalized.date() <= entry_date.date():\n",
    "                    continue\n",
    "                \n",
    "                daily_low = daily_row['low']\n",
    "                daily_high = daily_row['high']\n",
    "                \n",
    "                # Stop-loss check\n",
    "                if daily_high >= stop_loss_per_share:\n",
    "                    exit_date = check_date_normalized\n",
    "                    exit_daily_row = daily_row\n",
    "                    exit_reason = 'stop_loss'\n",
    "                    actual_exit_per_share = get_exit_price(daily_row, config.get('fill_mode', 'realistic'), penalty=liquidity_penalty)\n",
    "                    exit_price = actual_exit_per_share * 100\n",
    "                    break\n",
    "                \n",
    "                # Profit target check\n",
    "                if daily_low <= exit_price_per_share:\n",
    "                    touch_profit_target = True\n",
    "                    touch_count += 1\n",
    "                    \n",
    "                    if config.get('use_probabilistic_exit_fills', True) and p_fill_profit is not None:\n",
    "                        filled, u = try_probabilistic_fill(p_fill_profit, rng)\n",
    "                        u_fill_profit = u\n",
    "                        \n",
    "                        if filled:\n",
    "                            exit_date = check_date_normalized\n",
    "                            exit_daily_row = daily_row\n",
    "                            exit_reason = 'profit_target'\n",
    "                            filled_profit_target = True\n",
    "                            actual_exit_per_share = get_exit_price(daily_row, config.get('fill_mode', 'realistic'), penalty=liquidity_penalty)\n",
    "                            exit_price = actual_exit_per_share * 100\n",
    "                            break\n",
    "                    else:\n",
    "                        exit_date = check_date_normalized\n",
    "                        exit_daily_row = daily_row\n",
    "                        exit_reason = 'profit_target'\n",
    "                        filled_profit_target = True\n",
    "                        actual_exit_per_share = get_exit_price(daily_row, config.get('fill_mode', 'realistic'), penalty=liquidity_penalty)\n",
    "                        exit_price = actual_exit_per_share * 100\n",
    "                        break\n",
    "            \n",
    "            # Handle expiration\n",
    "            if exit_date is None:\n",
    "                exit_date = expiration_date\n",
    "                exit_daily_row = None\n",
    "                \n",
    "                # Check if assigned (ITM at expiration)\n",
    "                underlying_at_exp = fetch_underlying_price_at_expiration(\n",
    "                    symbol.split()[0], expiration_date, client, config\n",
    "                )\n",
    "                \n",
    "                if underlying_at_exp is not None and underlying_at_exp < row['strike']:\n",
    "                    exit_reason = 'assigned'\n",
    "                    exit_price = 0.0  # Put exercised\n",
    "                else:\n",
    "                    exit_reason = 'expired_worthless'\n",
    "                    exit_price = 0.0\n",
    "            \n",
    "            # Create exit record\n",
    "            exit_record = create_exit_record(\n",
    "                symbol, entry_date, expiration_date, premium, exit_pct,\n",
    "                exit_price, exit_reason, exit_date, exit_daily_row, cost_basis,\n",
    "                wheel_id=wheel_id,\n",
    "                initial_capital=initial_capital,\n",
    "                touch_profit_target=touch_profit_target,\n",
    "                p_fill_profit_target=p_fill_profit,\n",
    "                u_fill_profit_target=u_fill_profit,\n",
    "                filled_profit_target=filled_profit_target,\n",
    "                spread_pct_entry=spread_pct_entry,\n",
    "                ivp_entry=ivp_entry,\n",
    "                touch_count=touch_count if touch_profit_target else 0\n",
    "            )\n",
    "            \n",
    "            # Add strike for assignment handling\n",
    "            exit_record['strike'] = row['strike']\n",
    "            \n",
    "            # Calculate P&L\n",
    "            is_round_trip = exit_reason not in ['expired_worthless', 'assigned']\n",
    "            fees = get_transaction_costs(config, is_round_trip=is_round_trip)\n",
    "            exit_record['fees'] = fees\n",
    "            exit_record['exit_pnl'] = premium - exit_price - fees\n",
    "            exit_record['exit_pnl_pct'] = (exit_record['exit_pnl'] / premium) * 100 if premium > 0 else 0\n",
    "            exit_record['roc'] = (exit_record['exit_pnl'] / cost_basis) * 100\n",
    "            \n",
    "            return exit_record\n",
    "            \n",
    "        except Exception as e:\n",
    "            return None\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"V5 SINGLE WHEEL WRAPPER LOADED\")\n",
    "print(\"=\" * 60)\n",
    "print(\"  - run_single_wheel(candidate, config, cc_config, wheel_id, client)\")\n",
    "print(\"  - run_csp_backtest_silent(backtest_candidates, client, config, wheel_id)\")\n",
    "print(\"=\" * 60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "84548dea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "V5 MAIN SCHEDULER LOADED\n",
      "============================================================\n",
      "  - run_v5_scheduler(CONFIG, CC_CONFIG, SCHEDULER_CONFIG, client)\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# V5 MAIN SCHEDULER LOOP\n",
    "# =============================================================================\n",
    "\n",
    "def run_v5_scheduler(CONFIG, CC_CONFIG, SCHEDULER_CONFIG, client):\n",
    "    \"\"\"\n",
    "    Main V5 scheduler: iterate over trading dates and symbols, launch wheels.\n",
    "    \n",
    "    For each trading day in the date range:\n",
    "        For each symbol:\n",
    "            1. Get entry candidates\n",
    "            2. For each candidate, run a wheel instance\n",
    "            3. Collect all results\n",
    "    \n",
    "    Args:\n",
    "        CONFIG: Main configuration dict\n",
    "        CC_CONFIG: Covered call configuration dict\n",
    "        SCHEDULER_CONFIG: Scheduler configuration dict\n",
    "        client: Databento client\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with all wheel results (CSP + CC + summaries)\n",
    "    \"\"\"\n",
    "    from copy import deepcopy\n",
    "    \n",
    "    all_wheel_results = []\n",
    "    wheel_counter = 0\n",
    "    log_info = SCHEDULER_CONFIG.get('log_level', 'INFO') == 'INFO'\n",
    "    \n",
    "    # Get trading days\n",
    "    trading_days = get_trading_days(\n",
    "        SCHEDULER_CONFIG['start_date'],\n",
    "        SCHEDULER_CONFIG['end_date'],\n",
    "        SCHEDULER_CONFIG['trading_calendar'],\n",
    "    )\n",
    "    \n",
    "    if log_info:\n",
    "        print(\"=\" * 60)\n",
    "        print(\"V5 SCHEDULER STARTING\")\n",
    "        print(\"=\" * 60)\n",
    "        print(f\"Date range: {SCHEDULER_CONFIG['start_date']} to {SCHEDULER_CONFIG['end_date']}\")\n",
    "        print(f\"Trading days: {len(trading_days)}\")\n",
    "        print(f\"Symbols: {SCHEDULER_CONFIG['symbols']}\")\n",
    "        print(\"=\" * 60)\n",
    "    \n",
    "    # Track candidates per day for summary\n",
    "    daily_stats = []\n",
    "    \n",
    "    for trade_date in trading_days:\n",
    "        for symbol in SCHEDULER_CONFIG['symbols']:\n",
    "            # Create day-specific config\n",
    "            config_day = deepcopy(CONFIG)\n",
    "            config_day['symbol'] = symbol\n",
    "            config_day['entry_date'] = trade_date.strftime('%Y-%m-%d')\n",
    "            \n",
    "            # Get entry candidates\n",
    "            entry_candidates = get_entry_candidates(symbol, trade_date, config_day, client)\n",
    "            \n",
    "            if len(entry_candidates) == 0:\n",
    "                continue\n",
    "            \n",
    "            if log_info:\n",
    "                print(f\"[{trade_date.date()}] {symbol}: {len(entry_candidates)} candidates\")\n",
    "            \n",
    "            daily_stats.append({\n",
    "                'date': trade_date.date(),\n",
    "                'symbol': symbol,\n",
    "                'candidates': len(entry_candidates)\n",
    "            })\n",
    "            \n",
    "            # Process each candidate\n",
    "            for idx, candidate in entry_candidates.iterrows():\n",
    "                wheel_id = f\"{symbol}_{trade_date.strftime('%Y%m%d')}_{wheel_counter}\"\n",
    "                wheel_counter += 1\n",
    "                \n",
    "                wheel_results = run_single_wheel(\n",
    "                    candidate, config_day, CC_CONFIG, wheel_id, client\n",
    "                )\n",
    "                \n",
    "                # Add symbol and entry_date to each result\n",
    "                for result in wheel_results:\n",
    "                    result['scheduler_symbol'] = symbol\n",
    "                    result['scheduler_entry_date'] = trade_date.strftime('%Y-%m-%d')\n",
    "                \n",
    "                all_wheel_results.extend(wheel_results)\n",
    "    \n",
    "    if log_info:\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"SCHEDULER COMPLETE\")\n",
    "        print(f\"{'='*60}\")\n",
    "        print(f\"Wheels launched: {wheel_counter}\")\n",
    "        print(f\"Total result records: {len(all_wheel_results)}\")\n",
    "    \n",
    "    # Handle empty results case\n",
    "    if len(all_wheel_results) == 0:\n",
    "        print(\"⚠ No wheel results - check date range and data availability\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # Combine all results\n",
    "    results_df = pd.DataFrame(all_wheel_results)\n",
    "    \n",
    "    return results_df\n",
    "\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"V5 MAIN SCHEDULER LOADED\")\n",
    "print(\"=\" * 60)\n",
    "print(\"  - run_v5_scheduler(CONFIG, CC_CONFIG, SCHEDULER_CONFIG, client)\")\n",
    "print(\"=\" * 60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9cbaf912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "V5 AGGREGATION FUNCTIONS LOADED\n",
      "============================================================\n",
      "  - aggregate_v5_results(df)\n",
      "  - print_v5_summary(results_df, agg_stats)\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# V5 AGGREGATION FUNCTIONS\n",
    "# =============================================================================\n",
    "\n",
    "def aggregate_v5_results(df):\n",
    "    \"\"\"\n",
    "    Aggregate V5 scheduler results into summary statistics.\n",
    "    \n",
    "    Uses the 'total' phase rows which contain wheel-level P&L.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame from run_v5_scheduler() with all exit records\n",
    "    \n",
    "    Returns:\n",
    "        dict: Summary statistics for the backtest\n",
    "    \"\"\"\n",
    "    if len(df) == 0:\n",
    "        return {\n",
    "            'total_wheels': 0,\n",
    "            'total_pnl': 0.0,\n",
    "            'avg_wheel_roc': 0.0,\n",
    "            'median_wheel_roc': 0.0,\n",
    "            'max_drawdown_proxy': 0.0,\n",
    "        }\n",
    "    \n",
    "    # Get wheel summary rows (phase == 'total')\n",
    "    totals = df[df['phase'] == 'total'].copy()\n",
    "    \n",
    "    if len(totals) == 0:\n",
    "        return {\n",
    "            'total_wheels': 0,\n",
    "            'total_pnl': 0.0,\n",
    "            'avg_wheel_roc': 0.0,\n",
    "            'median_wheel_roc': 0.0,\n",
    "            'max_drawdown_proxy': 0.0,\n",
    "        }\n",
    "    \n",
    "    # Use 'total_pnl' for wheel summaries, 'exit_pnl' for phase exits\n",
    "    pnl_col = 'total_pnl' if 'total_pnl' in totals.columns else 'exit_pnl'\n",
    "    roc_col = 'wheel_roc' if 'wheel_roc' in totals.columns else 'roc'\n",
    "    \n",
    "    return {\n",
    "        'total_wheels': df['wheel_id'].nunique(),\n",
    "        'total_pnl': totals[pnl_col].sum() if pnl_col in totals.columns else 0.0,\n",
    "        'avg_wheel_roc': totals[roc_col].mean() if roc_col in totals.columns else 0.0,\n",
    "        'median_wheel_roc': totals[roc_col].median() if roc_col in totals.columns else 0.0,\n",
    "        'max_drawdown_proxy': totals[pnl_col].min() if pnl_col in totals.columns else 0.0,\n",
    "        'win_rate': (totals[pnl_col] > 0).mean() * 100 if pnl_col in totals.columns else 0.0,\n",
    "        'avg_days_held': totals['total_days'].mean() if 'total_days' in totals.columns else 0.0,\n",
    "    }\n",
    "\n",
    "\n",
    "def print_v5_summary(results_df, agg_stats):\n",
    "    \"\"\"\n",
    "    Print formatted summary of V5 backtest results.\n",
    "    \n",
    "    Args:\n",
    "        results_df: DataFrame from run_v5_scheduler()\n",
    "        agg_stats: dict from aggregate_v5_results()\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"V5 SCHEDULER RESULTS SUMMARY\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    print(f\"\\n{'─'*40}\")\n",
    "    print(\"AGGREGATE STATISTICS\")\n",
    "    print(f\"{'─'*40}\")\n",
    "    print(f\"Total Wheels:      {agg_stats['total_wheels']}\")\n",
    "    print(f\"Total P&L:         ${agg_stats['total_pnl']:,.2f}\")\n",
    "    print(f\"Avg Wheel ROC:     {agg_stats['avg_wheel_roc']:.2f}%\")\n",
    "    print(f\"Median Wheel ROC:  {agg_stats['median_wheel_roc']:.2f}%\")\n",
    "    print(f\"Win Rate:          {agg_stats['win_rate']:.1f}%\")\n",
    "    print(f\"Avg Days Held:     {agg_stats['avg_days_held']:.1f}\")\n",
    "    print(f\"Max Loss (proxy):  ${agg_stats['max_drawdown_proxy']:,.2f}\")\n",
    "    \n",
    "    # Phase breakdown\n",
    "    if 'phase' in results_df.columns:\n",
    "        print(f\"\\n{'─'*40}\")\n",
    "        print(\"PHASE BREAKDOWN\")\n",
    "        print(f\"{'─'*40}\")\n",
    "        print(results_df['phase'].value_counts().to_string())\n",
    "    \n",
    "    # Exit reason breakdown for CSP phase\n",
    "    csp_exits = results_df[results_df['phase'] == 'csp']\n",
    "    if len(csp_exits) > 0 and 'exit_reason' in csp_exits.columns:\n",
    "        print(f\"\\n{'─'*40}\")\n",
    "        print(\"CSP EXIT REASONS\")\n",
    "        print(f\"{'─'*40}\")\n",
    "        print(csp_exits['exit_reason'].value_counts().to_string())\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"V5 AGGREGATION FUNCTIONS LOADED\")\n",
    "print(\"=\" * 60)\n",
    "print(\"  - aggregate_v5_results(df)\")\n",
    "print(\"  - print_v5_summary(results_df, agg_stats)\")\n",
    "print(\"=\" * 60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8e768806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "V5 VALIDATION FUNCTIONS LOADED\n",
      "============================================================\n",
      "  - validate_v5_results(exits_df)\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# V5 DATA MODEL VALIDATION\n",
    "# =============================================================================\n",
    "\n",
    "def validate_v5_results(exits_df):\n",
    "    \"\"\"\n",
    "    Validate V5 scheduler results for data integrity.\n",
    "    \n",
    "    Checks:\n",
    "    1. Every wheel_id has at least one phase\n",
    "    2. Required fields are present\n",
    "    3. Execution version is consistent\n",
    "    4. Exactly one 'total' row per wheel_id\n",
    "    \n",
    "    Args:\n",
    "        exits_df: DataFrame from run_v5_scheduler()\n",
    "    \n",
    "    Returns:\n",
    "        bool: True if all validations pass\n",
    "    \n",
    "    Raises:\n",
    "        AssertionError if any validation fails\n",
    "    \"\"\"\n",
    "    if len(exits_df) == 0:\n",
    "        print(\"⚠ Empty results - skipping validation\")\n",
    "        return True\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"V5 DATA MODEL VALIDATION\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Check 1: Every wheel_id has at least one phase\n",
    "    phase_counts = exits_df.groupby('wheel_id')['phase'].nunique()\n",
    "    assert phase_counts.ge(1).all(), \"Some wheel_ids have no phases\"\n",
    "    print(\"  ✓ Every wheel_id has at least one phase\")\n",
    "    \n",
    "    # Check 2: Required fields present\n",
    "    required_fields = ['wheel_id', 'phase', 'execution_version']\n",
    "    missing = [col for col in required_fields if col not in exits_df.columns]\n",
    "    assert len(missing) == 0, f\"Missing required fields: {missing}\"\n",
    "    print(f\"  ✓ Required fields present: {required_fields}\")\n",
    "    \n",
    "    # Check 3: Execution version is consistent\n",
    "    versions = exits_df['execution_version'].unique()\n",
    "    assert len(versions) == 1 and versions[0] == 'v5_scheduler', \\\n",
    "        f\"Inconsistent execution_version: {versions}\"\n",
    "    print(\"  ✓ Execution version is 'v5_scheduler'\")\n",
    "    \n",
    "    # Check 4: Exactly one 'total' row per wheel_id\n",
    "    totals = exits_df[exits_df['phase'] == 'total']\n",
    "    if len(totals) > 0:\n",
    "        assert totals['wheel_id'].is_unique, \"Duplicate 'total' rows detected for same wheel_id\"\n",
    "        print(\"  ✓ Exactly one 'total' row per wheel_id\")\n",
    "    else:\n",
    "        print(\"  ⚠ No 'total' phase rows found\")\n",
    "    \n",
    "    # Check 5: CSP exits have required fields\n",
    "    csp_exits = exits_df[exits_df['phase'] == 'csp']\n",
    "    if len(csp_exits) > 0:\n",
    "        csp_required = ['symbol', 'entry_date', 'exit_reason']\n",
    "        csp_missing = [col for col in csp_required if col not in csp_exits.columns]\n",
    "        assert len(csp_missing) == 0, f\"CSP exits missing fields: {csp_missing}\"\n",
    "        print(f\"  ✓ CSP exits have required fields: {csp_required}\")\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"ALL VALIDATIONS PASSED\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    return True\n",
    "\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"V5 VALIDATION FUNCTIONS LOADED\")\n",
    "print(\"=\" * 60)\n",
    "print(\"  - validate_v5_results(exits_df)\")\n",
    "print(\"=\" * 60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47db436c",
   "metadata": {},
   "source": [
    "## V5 Scheduler Execution\n",
    "\n",
    "Run the scheduler over the configured date range and symbols.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "46f7da4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "RUNNING V5 SCHEDULER BACKTEST\n",
      "============================================================\n",
      "============================================================\n",
      "V5 SCHEDULER STARTING\n",
      "============================================================\n",
      "Date range: 2023-06-06 to 2023-09-13\n",
      "Trading days: 69\n",
      "Symbols: ['TSLA']\n",
      "============================================================\n",
      "[2023-06-06] TSLA: 7 candidates\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230707P00205000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230707P00210000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230714P00200000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230714P00205000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230714P00210000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230721P00200000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230721P00205000\n",
      "[2023-06-07] TSLA: 5 candidates\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230707P00210000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230714P00205000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230714P00210000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230721P00205000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230721P00210000\n",
      "[2023-06-08] TSLA: 4 candidates\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230714P00215000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230714P00220000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230721P00215000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230721P00220000\n",
      "[2023-06-09] TSLA: 5 candidates\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230714P00225000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230714P00230000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230721P00220000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230721P00225000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230721P00230000\n",
      "[2023-06-12] TSLA: 5 candidates\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230714P00230000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230714P00235000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230721P00225000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230721P00230000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230721P00235000\n",
      "[2023-06-13] TSLA: 8 candidates\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230714P00235000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230714P00240000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230714P00245000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230721P00235000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230721P00240000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230721P00245000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230728P00235000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230728P00240000\n",
      "[2023-06-14] TSLA: 8 candidates\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230714P00235000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230714P00240000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230721P00230000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230721P00235000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230721P00240000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230728P00230000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230728P00235000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230728P00240000\n",
      "[2023-06-15] TSLA: 6 candidates\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230721P00230000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230721P00235000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230721P00240000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230728P00230000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230728P00235000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230728P00240000\n",
      "[2023-06-16] TSLA: 6 candidates\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230721P00235000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230721P00240000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230721P00245000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230728P00235000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230728P00240000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230728P00245000\n",
      "[2023-06-20] TSLA: 5 candidates\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230721P00250000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230721P00255000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230728P00245000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230728P00250000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230728P00255000\n",
      "[2023-06-21] TSLA: 9 candidates\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230721P00235000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230721P00237500\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230721P00240000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230721P00242500\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230721P00245000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230721P00247500\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230728P00235000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230728P00240000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230728P00245000\n",
      "[2023-06-22] TSLA: 6 candidates\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230728P00240000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230728P00245000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230728P00250000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230804P00240000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230804P00245000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230804P00250000\n",
      "[2023-06-23] TSLA: 6 candidates\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230728P00230000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230728P00235000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230728P00240000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230804P00230000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230804P00235000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230804P00240000\n",
      "[2023-06-26] TSLA: 5 candidates\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230728P00220000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230728P00225000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230728P00230000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230804P00220000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230804P00225000\n",
      "[2023-06-27] TSLA: 5 candidates\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230728P00230000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230728P00235000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230804P00225000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230804P00230000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230804P00235000\n",
      "[2023-06-28] TSLA: 4 candidates\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230728P00235000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230728P00240000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230804P00235000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230804P00240000\n",
      "[2023-06-29] TSLA: 4 candidates\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230804P00235000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230804P00240000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230811P00235000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230811P00240000\n",
      "[2023-06-30] TSLA: 4 candidates\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230804P00240000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230804P00245000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230811P00240000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230811P00245000\n",
      "[2023-07-05] TSLA: 8 candidates\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230804P00260000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230804P00265000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230804P00270000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230811P00260000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230811P00265000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230818P00255000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230818P00260000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230818P00265000\n",
      "[2023-07-06] TSLA: 5 candidates\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230811P00255000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230811P00260000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230818P00250000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230818P00255000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230818P00260000\n",
      "[2023-07-07] TSLA: 6 candidates\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230811P00250000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230811P00255000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230811P00260000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230818P00250000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230818P00255000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230818P00260000\n",
      "[2023-07-10] TSLA: 6 candidates\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230811P00245000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230811P00250000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230811P00255000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230818P00245000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230818P00250000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230818P00255000\n",
      "[2023-07-11] TSLA: 8 candidates\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230811P00250000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230811P00255000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230818P00245000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230818P00250000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230818P00255000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230825P00245000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230825P00250000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230825P00255000\n",
      "[2023-07-12] TSLA: 7 candidates\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230811P00250000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230811P00255000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230811P00260000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230818P00250000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230818P00255000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230825P00250000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230825P00255000\n",
      "[2023-07-13] TSLA: 6 candidates\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230818P00255000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6k/0v57cgbd2k37vp0lh44zby640000gn/T/ipykernel_14665/644160136.py:41: BentoWarning: No data found for the request you submitted.\n",
      "  equity_data = client.timeseries.get_range(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [CACHE HIT] Loading daily prices for TSLA  230818P00260000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6k/0v57cgbd2k37vp0lh44zby640000gn/T/ipykernel_14665/644160136.py:41: BentoWarning: No data found for the request you submitted.\n",
      "  equity_data = client.timeseries.get_range(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [CACHE HIT] Loading daily prices for TSLA  230818P00265000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6k/0v57cgbd2k37vp0lh44zby640000gn/T/ipykernel_14665/644160136.py:41: BentoWarning: No data found for the request you submitted.\n",
      "  equity_data = client.timeseries.get_range(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [CACHE HIT] Loading daily prices for TSLA  230825P00255000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6k/0v57cgbd2k37vp0lh44zby640000gn/T/ipykernel_14665/644160136.py:41: BentoWarning: No data found for the request you submitted.\n",
      "  equity_data = client.timeseries.get_range(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [CACHE HIT] Loading daily prices for TSLA  230825P00260000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6k/0v57cgbd2k37vp0lh44zby640000gn/T/ipykernel_14665/644160136.py:41: BentoWarning: No data found for the request you submitted.\n",
      "  equity_data = client.timeseries.get_range(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [CACHE HIT] Loading daily prices for TSLA  230825P00265000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6k/0v57cgbd2k37vp0lh44zby640000gn/T/ipykernel_14665/644160136.py:41: BentoWarning: No data found for the request you submitted.\n",
      "  equity_data = client.timeseries.get_range(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-07-14] TSLA: 5 candidates\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230818P00260000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6k/0v57cgbd2k37vp0lh44zby640000gn/T/ipykernel_14665/644160136.py:41: BentoWarning: No data found for the request you submitted.\n",
      "  equity_data = client.timeseries.get_range(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [CACHE HIT] Loading daily prices for TSLA  230818P00265000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6k/0v57cgbd2k37vp0lh44zby640000gn/T/ipykernel_14665/644160136.py:41: BentoWarning: No data found for the request you submitted.\n",
      "  equity_data = client.timeseries.get_range(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [CACHE HIT] Loading daily prices for TSLA  230825P00255000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6k/0v57cgbd2k37vp0lh44zby640000gn/T/ipykernel_14665/644160136.py:41: BentoWarning: No data found for the request you submitted.\n",
      "  equity_data = client.timeseries.get_range(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [CACHE HIT] Loading daily prices for TSLA  230825P00260000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6k/0v57cgbd2k37vp0lh44zby640000gn/T/ipykernel_14665/644160136.py:41: BentoWarning: No data found for the request you submitted.\n",
      "  equity_data = client.timeseries.get_range(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [CACHE HIT] Loading daily prices for TSLA  230825P00265000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6k/0v57cgbd2k37vp0lh44zby640000gn/T/ipykernel_14665/644160136.py:41: BentoWarning: No data found for the request you submitted.\n",
      "  equity_data = client.timeseries.get_range(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-07-17] TSLA: 6 candidates\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230818P00265000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6k/0v57cgbd2k37vp0lh44zby640000gn/T/ipykernel_14665/644160136.py:41: BentoWarning: No data found for the request you submitted.\n",
      "  equity_data = client.timeseries.get_range(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [CACHE HIT] Loading daily prices for TSLA  230818P00270000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6k/0v57cgbd2k37vp0lh44zby640000gn/T/ipykernel_14665/644160136.py:41: BentoWarning: No data found for the request you submitted.\n",
      "  equity_data = client.timeseries.get_range(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [CACHE HIT] Loading daily prices for TSLA  230818P00275000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6k/0v57cgbd2k37vp0lh44zby640000gn/T/ipykernel_14665/644160136.py:41: BentoWarning: No data found for the request you submitted.\n",
      "  equity_data = client.timeseries.get_range(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [CACHE HIT] Loading daily prices for TSLA  230825P00265000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6k/0v57cgbd2k37vp0lh44zby640000gn/T/ipykernel_14665/644160136.py:41: BentoWarning: No data found for the request you submitted.\n",
      "  equity_data = client.timeseries.get_range(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [CACHE HIT] Loading daily prices for TSLA  230825P00270000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6k/0v57cgbd2k37vp0lh44zby640000gn/T/ipykernel_14665/644160136.py:41: BentoWarning: No data found for the request you submitted.\n",
      "  equity_data = client.timeseries.get_range(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [CACHE HIT] Loading daily prices for TSLA  230825P00275000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6k/0v57cgbd2k37vp0lh44zby640000gn/T/ipykernel_14665/644160136.py:41: BentoWarning: No data found for the request you submitted.\n",
      "  equity_data = client.timeseries.get_range(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-07-18] TSLA: 9 candidates\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230818P00270000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6k/0v57cgbd2k37vp0lh44zby640000gn/T/ipykernel_14665/644160136.py:41: BentoWarning: No data found for the request you submitted.\n",
      "  equity_data = client.timeseries.get_range(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [CACHE HIT] Loading daily prices for TSLA  230818P00275000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6k/0v57cgbd2k37vp0lh44zby640000gn/T/ipykernel_14665/644160136.py:41: BentoWarning: No data found for the request you submitted.\n",
      "  equity_data = client.timeseries.get_range(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [CACHE HIT] Loading daily prices for TSLA  230818P00280000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6k/0v57cgbd2k37vp0lh44zby640000gn/T/ipykernel_14665/644160136.py:41: BentoWarning: No data found for the request you submitted.\n",
      "  equity_data = client.timeseries.get_range(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [CACHE HIT] Loading daily prices for TSLA  230825P00270000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6k/0v57cgbd2k37vp0lh44zby640000gn/T/ipykernel_14665/644160136.py:41: BentoWarning: No data found for the request you submitted.\n",
      "  equity_data = client.timeseries.get_range(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [CACHE HIT] Loading daily prices for TSLA  230825P00275000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6k/0v57cgbd2k37vp0lh44zby640000gn/T/ipykernel_14665/644160136.py:41: BentoWarning: No data found for the request you submitted.\n",
      "  equity_data = client.timeseries.get_range(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [CACHE HIT] Loading daily prices for TSLA  230825P00280000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6k/0v57cgbd2k37vp0lh44zby640000gn/T/ipykernel_14665/644160136.py:41: BentoWarning: No data found for the request you submitted.\n",
      "  equity_data = client.timeseries.get_range(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [CACHE HIT] Loading daily prices for TSLA  230901P00265000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6k/0v57cgbd2k37vp0lh44zby640000gn/T/ipykernel_14665/644160136.py:41: BentoWarning: No data found for the request you submitted.\n",
      "  equity_data = client.timeseries.get_range(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [CACHE HIT] Loading daily prices for TSLA  230901P00270000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6k/0v57cgbd2k37vp0lh44zby640000gn/T/ipykernel_14665/644160136.py:41: BentoWarning: No data found for the request you submitted.\n",
      "  equity_data = client.timeseries.get_range(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [CACHE HIT] Loading daily prices for TSLA  230901P00275000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6k/0v57cgbd2k37vp0lh44zby640000gn/T/ipykernel_14665/644160136.py:41: BentoWarning: No data found for the request you submitted.\n",
      "  equity_data = client.timeseries.get_range(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-07-19] TSLA: 8 candidates\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230818P00270000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6k/0v57cgbd2k37vp0lh44zby640000gn/T/ipykernel_14665/644160136.py:41: BentoWarning: No data found for the request you submitted.\n",
      "  equity_data = client.timeseries.get_range(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [CACHE HIT] Loading daily prices for TSLA  230818P00275000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6k/0v57cgbd2k37vp0lh44zby640000gn/T/ipykernel_14665/644160136.py:41: BentoWarning: No data found for the request you submitted.\n",
      "  equity_data = client.timeseries.get_range(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [CACHE HIT] Loading daily prices for TSLA  230825P00265000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6k/0v57cgbd2k37vp0lh44zby640000gn/T/ipykernel_14665/644160136.py:41: BentoWarning: No data found for the request you submitted.\n",
      "  equity_data = client.timeseries.get_range(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [CACHE HIT] Loading daily prices for TSLA  230825P00270000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6k/0v57cgbd2k37vp0lh44zby640000gn/T/ipykernel_14665/644160136.py:41: BentoWarning: No data found for the request you submitted.\n",
      "  equity_data = client.timeseries.get_range(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [CACHE HIT] Loading daily prices for TSLA  230825P00275000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6k/0v57cgbd2k37vp0lh44zby640000gn/T/ipykernel_14665/644160136.py:41: BentoWarning: No data found for the request you submitted.\n",
      "  equity_data = client.timeseries.get_range(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [CACHE HIT] Loading daily prices for TSLA  230901P00265000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6k/0v57cgbd2k37vp0lh44zby640000gn/T/ipykernel_14665/644160136.py:41: BentoWarning: No data found for the request you submitted.\n",
      "  equity_data = client.timeseries.get_range(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [CACHE HIT] Loading daily prices for TSLA  230901P00270000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6k/0v57cgbd2k37vp0lh44zby640000gn/T/ipykernel_14665/644160136.py:41: BentoWarning: No data found for the request you submitted.\n",
      "  equity_data = client.timeseries.get_range(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [CACHE HIT] Loading daily prices for TSLA  230901P00275000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6k/0v57cgbd2k37vp0lh44zby640000gn/T/ipykernel_14665/644160136.py:41: BentoWarning: No data found for the request you submitted.\n",
      "  equity_data = client.timeseries.get_range(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-07-20] TSLA: 4 candidates\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230825P00245000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230825P00250000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230901P00245000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230901P00250000\n",
      "[2023-07-21] TSLA: 4 candidates\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230825P00245000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230825P00250000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230901P00240000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230901P00245000\n",
      "[2023-07-24] TSLA: 4 candidates\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230825P00250000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6k/0v57cgbd2k37vp0lh44zby640000gn/T/ipykernel_14665/644160136.py:41: BentoWarning: No data found for the request you submitted.\n",
      "  equity_data = client.timeseries.get_range(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [CACHE HIT] Loading daily prices for TSLA  230825P00255000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6k/0v57cgbd2k37vp0lh44zby640000gn/T/ipykernel_14665/644160136.py:41: BentoWarning: No data found for the request you submitted.\n",
      "  equity_data = client.timeseries.get_range(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [CACHE HIT] Loading daily prices for TSLA  230901P00250000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230901P00255000\n",
      "[2023-07-25] TSLA: 5 candidates\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230825P00250000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6k/0v57cgbd2k37vp0lh44zby640000gn/T/ipykernel_14665/644160136.py:41: BentoWarning: No data found for the request you submitted.\n",
      "  equity_data = client.timeseries.get_range(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [CACHE HIT] Loading daily prices for TSLA  230825P00255000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6k/0v57cgbd2k37vp0lh44zby640000gn/T/ipykernel_14665/644160136.py:41: BentoWarning: No data found for the request you submitted.\n",
      "  equity_data = client.timeseries.get_range(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [CACHE HIT] Loading daily prices for TSLA  230901P00245000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230901P00250000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230901P00255000\n",
      "[2023-07-26] TSLA: 3 candidates\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230825P00250000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6k/0v57cgbd2k37vp0lh44zby640000gn/T/ipykernel_14665/644160136.py:41: BentoWarning: No data found for the request you submitted.\n",
      "  equity_data = client.timeseries.get_range(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [CACHE HIT] Loading daily prices for TSLA  230901P00245000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230901P00250000\n",
      "[2023-07-27] TSLA: 5 candidates\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230901P00240000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230901P00245000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230908P00235000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230908P00240000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230908P00245000\n",
      "[2023-07-28] TSLA: 4 candidates\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230901P00250000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230901P00255000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230908P00245000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230908P00250000\n",
      "[2023-07-31] TSLA: 4 candidates\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230901P00250000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230901P00255000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230908P00250000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230908P00255000\n",
      "[2023-08-01] TSLA: 8 candidates\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230901P00245000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230901P00250000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230908P00245000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230908P00250000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230915P00240000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230915P00241670\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230915P00245000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230915P00246670\n",
      "[2023-08-02] TSLA: 8 candidates\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230901P00235000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230901P00240000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230908P00235000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230908P00240000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230915P00233330\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230915P00235000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230915P00240000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230915P00241670\n",
      "[2023-08-03] TSLA: 6 candidates\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230908P00240000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230908P00245000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230915P00240000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230915P00241670\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230915P00245000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230915P00246670\n",
      "[2023-08-04] TSLA: 6 candidates\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230908P00235000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230908P00240000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230915P00233330\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230915P00235000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230915P00240000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230915P00241670\n",
      "[2023-08-07] TSLA: 5 candidates\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230908P00235000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230908P00240000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230915P00230000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230915P00233330\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230915P00235000\n",
      "[2023-08-08] TSLA: 7 candidates\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230908P00235000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230908P00240000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230915P00230000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230915P00233330\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230915P00235000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230922P00230000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230922P00235000\n",
      "[2023-08-09] TSLA: 7 candidates\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230908P00230000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230915P00225000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230915P00226670\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230915P00230000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230915P00233330\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230922P00225000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230922P00230000\n",
      "[2023-08-10] TSLA: 5 candidates\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230915P00226670\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230915P00230000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230915P00233330\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230922P00225000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230922P00230000\n",
      "[2023-08-11] TSLA: 5 candidates\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230915P00225000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230915P00226670\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230915P00230000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230922P00225000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230922P00230000\n",
      "[2023-08-14] TSLA: 5 candidates\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230915P00225000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230915P00226670\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230915P00230000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230922P00220000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230922P00225000\n",
      "[2023-08-15] TSLA: 6 candidates\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230915P00216670\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230915P00220000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230922P00215000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230922P00220000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230929P00215000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230929P00220000\n",
      "[2023-08-16] TSLA: 8 candidates\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230915P00210000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230915P00213330\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230915P00215000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230915P00216670\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230922P00210000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230922P00215000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230929P00210000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230929P00215000\n",
      "[2023-08-17] TSLA: 4 candidates\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230922P00205000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230922P00210000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230929P00200000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230929P00205000\n",
      "[2023-08-18] TSLA: 4 candidates\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230922P00200000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230922P00205000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230929P00200000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230929P00205000\n",
      "[2023-08-21] TSLA: 4 candidates\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230922P00215000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230922P00220000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230929P00215000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230929P00220000\n",
      "[2023-08-22] TSLA: 4 candidates\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230922P00215000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230922P00220000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230929P00215000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230929P00220000\n",
      "[2023-08-23] TSLA: 4 candidates\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230922P00220000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230922P00225000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230929P00220000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230929P00225000\n",
      "[2023-08-24] TSLA: 4 candidates\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230929P00215000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230929P00220000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  231006P00210000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  231006P00215000\n",
      "[2023-08-25] TSLA: 4 candidates\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230929P00220000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230929P00225000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  231006P00220000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  231006P00225000\n",
      "[2023-08-28] TSLA: 3 candidates\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230929P00225000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  231006P00220000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  231006P00225000\n",
      "[2023-08-29] TSLA: 5 candidates\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230929P00240000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230929P00245000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  231006P00235000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  231006P00240000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  231006P00245000\n",
      "[2023-08-30] TSLA: 5 candidates\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230929P00240000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  230929P00245000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  231006P00235000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  231006P00240000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  231006P00245000\n",
      "[2023-08-31] TSLA: 4 candidates\n",
      "    [CACHE HIT] Loading daily prices for TSLA  231006P00240000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  231006P00245000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  231013P00240000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  231013P00245000\n",
      "[2023-09-01] TSLA: 4 candidates\n",
      "    [CACHE HIT] Loading daily prices for TSLA  231006P00225000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  231006P00230000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  231013P00225000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  231013P00230000\n",
      "[2023-09-05] TSLA: 7 candidates\n",
      "    [CACHE HIT] Loading daily prices for TSLA  231006P00240000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  231006P00245000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  231013P00235000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  231013P00240000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  231013P00245000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  231020P00235000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  231020P00240000\n",
      "[2023-09-06] TSLA: 7 candidates\n",
      "    [CACHE HIT] Loading daily prices for TSLA  231006P00235000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  231006P00240000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  231013P00235000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  231013P00240000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  231020P00230000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  231020P00235000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  231020P00240000\n",
      "[2023-09-07] TSLA: 5 candidates\n",
      "    [CACHE HIT] Loading daily prices for TSLA  231013P00235000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  231013P00240000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  231020P00230000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  231020P00235000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  231020P00240000\n",
      "[2023-09-08] TSLA: 5 candidates\n",
      "    [CACHE HIT] Loading daily prices for TSLA  231013P00230000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  231013P00235000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  231020P00225000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  231020P00230000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  231020P00235000\n",
      "[2023-09-11] TSLA: 5 candidates\n",
      "    [CACHE HIT] Loading daily prices for TSLA  231013P00255000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  231013P00260000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  231020P00250000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  231020P00255000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  231020P00260000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6k/0v57cgbd2k37vp0lh44zby640000gn/T/ipykernel_14665/644160136.py:41: BentoWarning: No data found for the request you submitted.\n",
      "  equity_data = client.timeseries.get_range(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-09-12] TSLA: 7 candidates\n",
      "    [CACHE HIT] Loading daily prices for TSLA  231013P00250000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  231013P00255000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  231020P00245000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  231020P00250000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  231020P00255000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  231027P00245000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  231027P00250000\n",
      "[2023-09-13] TSLA: 7 candidates\n",
      "    [CACHE HIT] Loading daily prices for TSLA  231013P00250000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  231013P00255000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  231020P00250000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  231020P00255000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  231027P00245000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  231027P00250000\n",
      "    [CACHE HIT] Loading daily prices for TSLA  231027P00255000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6k/0v57cgbd2k37vp0lh44zby640000gn/T/ipykernel_14665/644160136.py:41: BentoWarning: No data found for the request you submitted.\n",
      "  equity_data = client.timeseries.get_range(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "SCHEDULER COMPLETE\n",
      "============================================================\n",
      "Wheels launched: 377\n",
      "Total result records: 754\n",
      "============================================================\n",
      "V5 DATA MODEL VALIDATION\n",
      "============================================================\n",
      "  ✓ Every wheel_id has at least one phase\n",
      "  ✓ Required fields present: ['wheel_id', 'phase', 'execution_version']\n",
      "  ✓ Execution version is 'v5_scheduler'\n",
      "  ✓ Exactly one 'total' row per wheel_id\n",
      "  ✓ CSP exits have required fields: ['symbol', 'entry_date', 'exit_reason']\n",
      "============================================================\n",
      "ALL VALIDATIONS PASSED\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "V5 SCHEDULER RESULTS SUMMARY\n",
      "============================================================\n",
      "\n",
      "────────────────────────────────────────\n",
      "AGGREGATE STATISTICS\n",
      "────────────────────────────────────────\n",
      "Total Wheels:      377\n",
      "Total P&L:         $190,932.18\n",
      "Avg Wheel ROC:     2.09%\n",
      "Median Wheel ROC:  1.88%\n",
      "Win Rate:          100.0%\n",
      "Avg Days Held:     15.6\n",
      "Max Loss (proxy):  $58.58\n",
      "\n",
      "────────────────────────────────────────\n",
      "PHASE BREAKDOWN\n",
      "────────────────────────────────────────\n",
      "phase\n",
      "csp      377\n",
      "total    377\n",
      "\n",
      "────────────────────────────────────────\n",
      "CSP EXIT REASONS\n",
      "────────────────────────────────────────\n",
      "exit_reason\n",
      "profit_target        336\n",
      "expired_worthless     41\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# RUN V5 SCHEDULER\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"RUNNING V5 SCHEDULER BACKTEST\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Run the scheduler\n",
    "v5_results_df = run_v5_scheduler(CONFIG, CC_CONFIG, SCHEDULER_CONFIG, client)\n",
    "\n",
    "# Validate results\n",
    "if len(v5_results_df) > 0:\n",
    "    validate_v5_results(v5_results_df)\n",
    "    \n",
    "    # Aggregate and print summary\n",
    "    v5_stats = aggregate_v5_results(v5_results_df)\n",
    "    print_v5_summary(v5_results_df, v5_stats)\n",
    "else:\n",
    "    print(\"⚠ No results to analyze\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "342adef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "V5 RESULTS DATA\n",
      "============================================================\n",
      "\n",
      "Total records: 754\n",
      "Unique wheels: 377\n",
      "\n",
      "Phase breakdown:\n",
      "phase\n",
      "csp      377\n",
      "total    377\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample wheel summaries (first 10):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wheel_id</th>\n",
       "      <th>state</th>\n",
       "      <th>total_pnl</th>\n",
       "      <th>wheel_roc</th>\n",
       "      <th>total_days</th>\n",
       "      <th>csp_exit_reason</th>\n",
       "      <th>cc_exit_reason</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TSLA_20230606_0</td>\n",
       "      <td>WHEEL_COMPLETE</td>\n",
       "      <td>411.28</td>\n",
       "      <td>2.01</td>\n",
       "      <td>2.0</td>\n",
       "      <td>profit_target</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TSLA_20230606_1</td>\n",
       "      <td>WHEEL_COMPLETE</td>\n",
       "      <td>484.68</td>\n",
       "      <td>2.31</td>\n",
       "      <td>2.0</td>\n",
       "      <td>profit_target</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TSLA_20230606_2</td>\n",
       "      <td>WHEEL_COMPLETE</td>\n",
       "      <td>347.38</td>\n",
       "      <td>1.74</td>\n",
       "      <td>2.0</td>\n",
       "      <td>profit_target</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>TSLA_20230606_3</td>\n",
       "      <td>WHEEL_COMPLETE</td>\n",
       "      <td>442.68</td>\n",
       "      <td>2.16</td>\n",
       "      <td>2.0</td>\n",
       "      <td>profit_target</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TSLA_20230606_4</td>\n",
       "      <td>WHEEL_COMPLETE</td>\n",
       "      <td>553.58</td>\n",
       "      <td>2.64</td>\n",
       "      <td>2.0</td>\n",
       "      <td>profit_target</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>TSLA_20230606_5</td>\n",
       "      <td>WHEEL_COMPLETE</td>\n",
       "      <td>388.68</td>\n",
       "      <td>1.94</td>\n",
       "      <td>2.0</td>\n",
       "      <td>profit_target</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>TSLA_20230606_6</td>\n",
       "      <td>WHEEL_COMPLETE</td>\n",
       "      <td>467.68</td>\n",
       "      <td>2.28</td>\n",
       "      <td>2.0</td>\n",
       "      <td>profit_target</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>TSLA_20230607_7</td>\n",
       "      <td>WHEEL_COMPLETE</td>\n",
       "      <td>343.68</td>\n",
       "      <td>1.64</td>\n",
       "      <td>1.0</td>\n",
       "      <td>profit_target</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>TSLA_20230607_8</td>\n",
       "      <td>WHEEL_COMPLETE</td>\n",
       "      <td>289.50</td>\n",
       "      <td>1.41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>profit_target</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>TSLA_20230607_9</td>\n",
       "      <td>WHEEL_COMPLETE</td>\n",
       "      <td>374.68</td>\n",
       "      <td>1.78</td>\n",
       "      <td>1.0</td>\n",
       "      <td>profit_target</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           wheel_id           state  total_pnl  wheel_roc  total_days  \\\n",
       "1   TSLA_20230606_0  WHEEL_COMPLETE     411.28       2.01         2.0   \n",
       "3   TSLA_20230606_1  WHEEL_COMPLETE     484.68       2.31         2.0   \n",
       "5   TSLA_20230606_2  WHEEL_COMPLETE     347.38       1.74         2.0   \n",
       "7   TSLA_20230606_3  WHEEL_COMPLETE     442.68       2.16         2.0   \n",
       "9   TSLA_20230606_4  WHEEL_COMPLETE     553.58       2.64         2.0   \n",
       "11  TSLA_20230606_5  WHEEL_COMPLETE     388.68       1.94         2.0   \n",
       "13  TSLA_20230606_6  WHEEL_COMPLETE     467.68       2.28         2.0   \n",
       "15  TSLA_20230607_7  WHEEL_COMPLETE     343.68       1.64         1.0   \n",
       "17  TSLA_20230607_8  WHEEL_COMPLETE     289.50       1.41         1.0   \n",
       "19  TSLA_20230607_9  WHEEL_COMPLETE     374.68       1.78         1.0   \n",
       "\n",
       "   csp_exit_reason  cc_exit_reason  \n",
       "1    profit_target             NaN  \n",
       "3    profit_target             NaN  \n",
       "5    profit_target             NaN  \n",
       "7    profit_target             NaN  \n",
       "9    profit_target             NaN  \n",
       "11   profit_target             NaN  \n",
       "13   profit_target             NaN  \n",
       "15   profit_target             NaN  \n",
       "17   profit_target             NaN  \n",
       "19   profit_target             NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample CSP exits (first 10):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wheel_id</th>\n",
       "      <th>symbol</th>\n",
       "      <th>entry_date</th>\n",
       "      <th>exit_date</th>\n",
       "      <th>exit_reason</th>\n",
       "      <th>premium</th>\n",
       "      <th>exit_price</th>\n",
       "      <th>exit_pnl</th>\n",
       "      <th>roc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TSLA_20230606_0</td>\n",
       "      <td>TSLA  230707P00205000</td>\n",
       "      <td>2023-06-06</td>\n",
       "      <td>2023-06-08 20:00:00</td>\n",
       "      <td>profit_target</td>\n",
       "      <td>634.00</td>\n",
       "      <td>221.40</td>\n",
       "      <td>411.28</td>\n",
       "      <td>2.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TSLA_20230606_1</td>\n",
       "      <td>TSLA  230707P00210000</td>\n",
       "      <td>2023-06-06</td>\n",
       "      <td>2023-06-08 20:00:00</td>\n",
       "      <td>profit_target</td>\n",
       "      <td>806.00</td>\n",
       "      <td>320.00</td>\n",
       "      <td>484.68</td>\n",
       "      <td>2.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TSLA_20230606_2</td>\n",
       "      <td>TSLA  230714P00200000</td>\n",
       "      <td>2023-06-06</td>\n",
       "      <td>2023-06-08 20:00:00</td>\n",
       "      <td>profit_target</td>\n",
       "      <td>599.00</td>\n",
       "      <td>250.30</td>\n",
       "      <td>347.38</td>\n",
       "      <td>1.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TSLA_20230606_3</td>\n",
       "      <td>TSLA  230714P00205000</td>\n",
       "      <td>2023-06-06</td>\n",
       "      <td>2023-06-08 20:00:00</td>\n",
       "      <td>profit_target</td>\n",
       "      <td>749.00</td>\n",
       "      <td>305.00</td>\n",
       "      <td>442.68</td>\n",
       "      <td>2.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>TSLA_20230606_4</td>\n",
       "      <td>TSLA  230714P00210000</td>\n",
       "      <td>2023-06-06</td>\n",
       "      <td>2023-06-08 20:00:00</td>\n",
       "      <td>profit_target</td>\n",
       "      <td>918.00</td>\n",
       "      <td>363.10</td>\n",
       "      <td>553.58</td>\n",
       "      <td>2.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>TSLA_20230606_5</td>\n",
       "      <td>TSLA  230721P00200000</td>\n",
       "      <td>2023-06-06</td>\n",
       "      <td>2023-06-08 20:00:00</td>\n",
       "      <td>profit_target</td>\n",
       "      <td>782.00</td>\n",
       "      <td>392.00</td>\n",
       "      <td>388.68</td>\n",
       "      <td>1.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>TSLA_20230606_6</td>\n",
       "      <td>TSLA  230721P00205000</td>\n",
       "      <td>2023-06-06</td>\n",
       "      <td>2023-06-08 20:00:00</td>\n",
       "      <td>profit_target</td>\n",
       "      <td>951.00</td>\n",
       "      <td>482.00</td>\n",
       "      <td>467.68</td>\n",
       "      <td>2.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>TSLA_20230607_7</td>\n",
       "      <td>TSLA  230707P00210000</td>\n",
       "      <td>2023-06-07</td>\n",
       "      <td>2023-06-08 20:00:00</td>\n",
       "      <td>profit_target</td>\n",
       "      <td>665.00</td>\n",
       "      <td>320.00</td>\n",
       "      <td>343.68</td>\n",
       "      <td>1.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>TSLA_20230607_8</td>\n",
       "      <td>TSLA  230714P00205000</td>\n",
       "      <td>2023-06-07</td>\n",
       "      <td>2023-06-08 20:00:00</td>\n",
       "      <td>profit_target</td>\n",
       "      <td>614.65</td>\n",
       "      <td>323.83</td>\n",
       "      <td>289.50</td>\n",
       "      <td>1.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>TSLA_20230607_9</td>\n",
       "      <td>TSLA  230714P00210000</td>\n",
       "      <td>2023-06-07</td>\n",
       "      <td>2023-06-08 20:00:00</td>\n",
       "      <td>profit_target</td>\n",
       "      <td>776.00</td>\n",
       "      <td>400.00</td>\n",
       "      <td>374.68</td>\n",
       "      <td>1.78</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           wheel_id                 symbol entry_date           exit_date  \\\n",
       "0   TSLA_20230606_0  TSLA  230707P00205000 2023-06-06 2023-06-08 20:00:00   \n",
       "2   TSLA_20230606_1  TSLA  230707P00210000 2023-06-06 2023-06-08 20:00:00   \n",
       "4   TSLA_20230606_2  TSLA  230714P00200000 2023-06-06 2023-06-08 20:00:00   \n",
       "6   TSLA_20230606_3  TSLA  230714P00205000 2023-06-06 2023-06-08 20:00:00   \n",
       "8   TSLA_20230606_4  TSLA  230714P00210000 2023-06-06 2023-06-08 20:00:00   \n",
       "10  TSLA_20230606_5  TSLA  230721P00200000 2023-06-06 2023-06-08 20:00:00   \n",
       "12  TSLA_20230606_6  TSLA  230721P00205000 2023-06-06 2023-06-08 20:00:00   \n",
       "14  TSLA_20230607_7  TSLA  230707P00210000 2023-06-07 2023-06-08 20:00:00   \n",
       "16  TSLA_20230607_8  TSLA  230714P00205000 2023-06-07 2023-06-08 20:00:00   \n",
       "18  TSLA_20230607_9  TSLA  230714P00210000 2023-06-07 2023-06-08 20:00:00   \n",
       "\n",
       "      exit_reason  premium  exit_price  exit_pnl   roc  \n",
       "0   profit_target   634.00      221.40    411.28  2.01  \n",
       "2   profit_target   806.00      320.00    484.68  2.31  \n",
       "4   profit_target   599.00      250.30    347.38  1.74  \n",
       "6   profit_target   749.00      305.00    442.68  2.16  \n",
       "8   profit_target   918.00      363.10    553.58  2.64  \n",
       "10  profit_target   782.00      392.00    388.68  1.94  \n",
       "12  profit_target   951.00      482.00    467.68  2.28  \n",
       "14  profit_target   665.00      320.00    343.68  1.64  \n",
       "16  profit_target   614.65      323.83    289.50  1.41  \n",
       "18  profit_target   776.00      400.00    374.68  1.78  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# V5 RESULTS EXPLORATION\n",
    "# =============================================================================\n",
    "\n",
    "if len(v5_results_df) > 0:\n",
    "    print(\"=\" * 60)\n",
    "    print(\"V5 RESULTS DATA\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"\\nTotal records: {len(v5_results_df)}\")\n",
    "    print(f\"Unique wheels: {v5_results_df['wheel_id'].nunique()}\")\n",
    "    \n",
    "    # Show phase breakdown\n",
    "    print(f\"\\nPhase breakdown:\")\n",
    "    print(v5_results_df['phase'].value_counts())\n",
    "    \n",
    "    # Display sample of wheel summaries\n",
    "    totals = v5_results_df[v5_results_df['phase'] == 'total']\n",
    "    if len(totals) > 0:\n",
    "        display_cols = ['wheel_id', 'state', 'total_pnl', 'wheel_roc', 'total_days', \n",
    "                       'csp_exit_reason', 'cc_exit_reason']\n",
    "        available_cols = [c for c in display_cols if c in totals.columns]\n",
    "        print(f\"\\nSample wheel summaries (first 10):\")\n",
    "        display(totals[available_cols].head(10).round(2))\n",
    "    \n",
    "    # Display sample CSP exits\n",
    "    csp_exits = v5_results_df[v5_results_df['phase'] == 'csp']\n",
    "    if len(csp_exits) > 0:\n",
    "        csp_cols = ['wheel_id', 'symbol', 'entry_date', 'exit_date', 'exit_reason', \n",
    "                   'premium', 'exit_price', 'exit_pnl', 'roc']\n",
    "        available_csp_cols = [c for c in csp_cols if c in csp_exits.columns]\n",
    "        print(f\"\\nSample CSP exits (first 10):\")\n",
    "        display(csp_exits[available_csp_cols].head(10).round(2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2bf24a91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ANALYSIS BY ENTRY DATE\n",
      "============================================================\n",
      "\n",
      "Daily Summary (first 20 days with trades):\n",
      "                wheels  total_pnl  avg_roc\n",
      "entry_date_str                            \n",
      "2023-06-06           7    3095.96     2.15\n",
      "2023-06-07           5    1756.72     1.69\n",
      "2023-06-08           4    1827.82     2.10\n",
      "2023-06-09           5    2359.20     2.09\n",
      "2023-06-12           5    2238.60     1.93\n",
      "2023-06-13           8    4704.24     2.45\n",
      "2023-06-14           8    4587.14     2.43\n",
      "2023-06-15           6    3762.18     2.66\n",
      "2023-06-16           6    4520.18     3.13\n",
      "2023-06-20           5    2716.95     2.16\n",
      "2023-06-21           9    6703.62     3.09\n",
      "2023-06-22           6    3977.44     2.70\n",
      "2023-06-23           6    4070.60     2.88\n",
      "2023-06-26           5    2399.39     2.14\n",
      "2023-06-27           5    3161.00     2.73\n",
      "2023-06-28           4    2234.32     2.35\n",
      "2023-06-29           4    2118.08     2.23\n",
      "2023-06-30           4    1884.22     1.94\n",
      "2023-07-05           8    3459.24     1.65\n",
      "2023-07-06           5    2446.90     1.91\n",
      "\n",
      "Monthly Summary:\n",
      "             wheels  total_pnl  avg_roc\n",
      "entry_month                            \n",
      "2023-06         102   58117.66     2.44\n",
      "2023-07         107   68235.01     2.45\n",
      "2023-08         121   44417.13     1.61\n",
      "2023-09          47   20162.38     1.77\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# V5 ANALYSIS BY DATE\n",
    "# =============================================================================\n",
    "\n",
    "if len(v5_results_df) > 0 and 'scheduler_entry_date' in v5_results_df.columns:\n",
    "    print(\"=\" * 60)\n",
    "    print(\"ANALYSIS BY ENTRY DATE\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Get wheel summaries\n",
    "    totals = v5_results_df[v5_results_df['phase'] == 'total'].copy()\n",
    "    \n",
    "    if len(totals) > 0:\n",
    "        # Group by entry date\n",
    "        totals['entry_date_str'] = totals['scheduler_entry_date']\n",
    "        daily_summary = totals.groupby('entry_date_str').agg({\n",
    "            'wheel_id': 'count',\n",
    "            'total_pnl': 'sum',\n",
    "            'wheel_roc': 'mean',\n",
    "        }).rename(columns={\n",
    "            'wheel_id': 'wheels',\n",
    "            'total_pnl': 'total_pnl',\n",
    "            'wheel_roc': 'avg_roc'\n",
    "        })\n",
    "        \n",
    "        print(f\"\\nDaily Summary (first 20 days with trades):\")\n",
    "        print(daily_summary.head(20).round(2))\n",
    "        \n",
    "        # Monthly summary if enough data\n",
    "        totals['entry_month'] = pd.to_datetime(totals['scheduler_entry_date']).dt.to_period('M')\n",
    "        monthly_summary = totals.groupby('entry_month').agg({\n",
    "            'wheel_id': 'count',\n",
    "            'total_pnl': 'sum',\n",
    "            'wheel_roc': 'mean',\n",
    "        }).rename(columns={\n",
    "            'wheel_id': 'wheels',\n",
    "            'total_pnl': 'total_pnl',\n",
    "            'wheel_roc': 'avg_roc'\n",
    "        })\n",
    "        \n",
    "        print(f\"\\nMonthly Summary:\")\n",
    "        print(monthly_summary.round(2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0e13d4",
   "metadata": {},
   "source": [
    "## Hedge Fund Performance Metrics & Dashboard\n",
    "\n",
    "Calculate institutional-grade performance metrics and visualize results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "66a97f7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ HF Metrics Functions Loaded\n",
      "  - calculate_hf_metrics(results_df, initial_capital, risk_free_rate)\n",
      "  - print_hf_metrics(metrics)\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# HEDGE FUND PERFORMANCE METRICS\n",
    "# =============================================================================\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from datetime import datetime\n",
    "\n",
    "def calculate_hf_metrics(results_df, initial_capital=100000, risk_free_rate=0.05):\n",
    "    \"\"\"\n",
    "    Calculate comprehensive hedge fund performance metrics.\n",
    "    \n",
    "    Args:\n",
    "        results_df: DataFrame from run_v5_scheduler()\n",
    "        initial_capital: Starting capital for the strategy\n",
    "        risk_free_rate: Annual risk-free rate (default 5%)\n",
    "    \n",
    "    Returns:\n",
    "        dict: Comprehensive performance metrics\n",
    "    \"\"\"\n",
    "    if len(results_df) == 0:\n",
    "        return None\n",
    "    \n",
    "    # Get wheel-level results (phase == 'total')\n",
    "    totals = results_df[results_df['phase'] == 'total'].copy()\n",
    "    \n",
    "    if len(totals) == 0:\n",
    "        print(\"⚠ No 'total' phase rows found\")\n",
    "        return None\n",
    "    \n",
    "    # Determine P&L column\n",
    "    pnl_col = 'total_pnl' if 'total_pnl' in totals.columns else 'exit_pnl'\n",
    "    \n",
    "    # Sort by entry date\n",
    "    totals['entry_date_parsed'] = pd.to_datetime(totals['scheduler_entry_date'])\n",
    "    totals = totals.sort_values('entry_date_parsed')\n",
    "    \n",
    "    # =========================================================================\n",
    "    # BASIC STATISTICS\n",
    "    # =========================================================================\n",
    "    total_pnl = totals[pnl_col].sum()\n",
    "    num_trades = len(totals)\n",
    "    winners = totals[totals[pnl_col] > 0]\n",
    "    losers = totals[totals[pnl_col] < 0]\n",
    "    num_winners = len(winners)\n",
    "    num_losers = len(losers)\n",
    "    \n",
    "    # Win/Loss metrics\n",
    "    win_rate = (num_winners / num_trades * 100) if num_trades > 0 else 0\n",
    "    avg_win = winners[pnl_col].mean() if num_winners > 0 else 0\n",
    "    avg_loss = abs(losers[pnl_col].mean()) if num_losers > 0 else 0\n",
    "    largest_win = winners[pnl_col].max() if num_winners > 0 else 0\n",
    "    largest_loss = losers[pnl_col].min() if num_losers > 0 else 0\n",
    "    \n",
    "    # Profit Factor = Gross Profits / Gross Losses\n",
    "    gross_profit = winners[pnl_col].sum() if num_winners > 0 else 0\n",
    "    gross_loss = abs(losers[pnl_col].sum()) if num_losers > 0 else 1  # Avoid div by 0\n",
    "    profit_factor = gross_profit / gross_loss if gross_loss > 0 else float('inf')\n",
    "    \n",
    "    # Expectancy = (Win Rate * Avg Win) - (Loss Rate * Avg Loss)\n",
    "    loss_rate = num_losers / num_trades if num_trades > 0 else 0\n",
    "    expectancy = (win_rate/100 * avg_win) - (loss_rate * avg_loss)\n",
    "    \n",
    "    # =========================================================================\n",
    "    # CAPITAL-ADJUSTED METRICS (FIX: use actual capital deployed)\n",
    "    # =========================================================================\n",
    "    # Total capital deployed = sum of all initial_capital per trade\n",
    "    total_capital_deployed = totals['initial_capital'].sum() if 'initial_capital' in totals.columns else initial_capital * num_trades\n",
    "    \n",
    "    # =========================================================================\n",
    "    # EQUITY CURVE & DRAWDOWN\n",
    "    # =========================================================================\n",
    "    # Build cumulative equity curve\n",
    "    totals['cumulative_pnl'] = totals[pnl_col].cumsum()\n",
    "    totals['equity'] = initial_capital + totals['cumulative_pnl']\n",
    "    \n",
    "    # Calculate drawdown\n",
    "    totals['peak'] = totals['equity'].cummax()\n",
    "    totals['drawdown'] = totals['equity'] - totals['peak']\n",
    "    totals['drawdown_pct'] = (totals['drawdown'] / totals['peak']) * 100\n",
    "    \n",
    "    max_drawdown = totals['drawdown'].min()\n",
    "    max_drawdown_pct = totals['drawdown_pct'].min()\n",
    "    \n",
    "    # =========================================================================\n",
    "    # RETURN METRICS (FIXED: use capital deployed)\n",
    "    # =========================================================================\n",
    "    # Per-trade ROC is already calculated correctly\n",
    "    avg_roc = totals['wheel_roc'].mean() if 'wheel_roc' in totals.columns else 0\n",
    "    \n",
    "    # Total return based on hypothetical single capital base (for equity curve)\n",
    "    total_return_curve = (total_pnl / initial_capital) * 100\n",
    "    \n",
    "    # Realistic return: P&L / total capital deployed\n",
    "    total_return_realistic = (total_pnl / total_capital_deployed) * 100 if total_capital_deployed > 0 else 0\n",
    "    \n",
    "    final_equity = initial_capital + total_pnl\n",
    "    \n",
    "    # Calculate trading period\n",
    "    start_date = totals['entry_date_parsed'].min()\n",
    "    end_date = totals['entry_date_parsed'].max()\n",
    "    trading_days = (end_date - start_date).days\n",
    "    years = trading_days / 365.25 if trading_days > 0 else 1\n",
    "    \n",
    "    # CAGR based on realistic return\n",
    "    if years > 0 and total_capital_deployed > 0:\n",
    "        # Annualized ROC (average per-trade ROC * trades per year)\n",
    "        trades_per_year = num_trades / years\n",
    "        cagr = avg_roc * trades_per_year  # Approximate annualized return\n",
    "    else:\n",
    "        cagr = 0\n",
    "    \n",
    "    # =========================================================================\n",
    "    # RISK-ADJUSTED METRICS (FIXED: use per-trade ROC)\n",
    "    # =========================================================================\n",
    "    roc_col = 'wheel_roc' if 'wheel_roc' in totals.columns else 'roc'\n",
    "    if roc_col in totals.columns:\n",
    "        returns = totals[roc_col] / 100  # Convert to decimal\n",
    "    else:\n",
    "        returns = totals[pnl_col] / total_capital_deployed * num_trades\n",
    "    \n",
    "    returns_std = returns.std()\n",
    "    returns_mean = returns.mean()\n",
    "    \n",
    "    # Annualize\n",
    "    trades_per_year = num_trades / years if years > 0 else num_trades\n",
    "    annualized_return = returns_mean * trades_per_year\n",
    "    annualized_vol = returns_std * np.sqrt(trades_per_year) if trades_per_year > 0 else 0\n",
    "    \n",
    "    # Sharpe Ratio\n",
    "    sharpe_ratio = (annualized_return - risk_free_rate) / annualized_vol if annualized_vol > 0 else 0\n",
    "    \n",
    "    # Sortino Ratio\n",
    "    negative_returns = returns[returns < 0]\n",
    "    downside_std = negative_returns.std() if len(negative_returns) > 0 else 0\n",
    "    annualized_downside = downside_std * np.sqrt(trades_per_year) if trades_per_year > 0 else 0\n",
    "    sortino_ratio = (annualized_return - risk_free_rate) / annualized_downside if annualized_downside > 0 else float('inf')\n",
    "    \n",
    "    # Calmar Ratio\n",
    "    calmar_ratio = abs(cagr / max_drawdown_pct) if max_drawdown_pct != 0 else float('inf')\n",
    "    \n",
    "    # Recovery Factor\n",
    "    recovery_factor = abs(total_pnl / max_drawdown) if max_drawdown != 0 else float('inf')\n",
    "    \n",
    "    # =========================================================================\n",
    "    # TIME-BASED METRICS\n",
    "    # =========================================================================\n",
    "    avg_days_held = totals['total_days'].mean() if 'total_days' in totals.columns else 0\n",
    "    \n",
    "    # Monthly returns\n",
    "    totals['entry_month'] = totals['entry_date_parsed'].dt.to_period('M')\n",
    "    monthly_pnl = totals.groupby('entry_month')[pnl_col].sum()\n",
    "    monthly_returns = monthly_pnl / initial_capital * 100\n",
    "    \n",
    "    best_month = monthly_returns.max() if len(monthly_returns) > 0 else 0\n",
    "    worst_month = monthly_returns.min() if len(monthly_returns) > 0 else 0\n",
    "    \n",
    "    # =========================================================================\n",
    "    # COMPILE RESULTS\n",
    "    # =========================================================================\n",
    "    metrics = {\n",
    "        # Basic Stats\n",
    "        'total_trades': num_trades,\n",
    "        'winning_trades': num_winners,\n",
    "        'losing_trades': num_losers,\n",
    "        'win_rate': win_rate,\n",
    "        \n",
    "        # P&L\n",
    "        'total_pnl': total_pnl,\n",
    "        'gross_profit': gross_profit,\n",
    "        'gross_loss': -abs(gross_loss) if gross_loss != 1 else 0,\n",
    "        'avg_win': avg_win,\n",
    "        'avg_loss': -avg_loss,\n",
    "        'largest_win': largest_win,\n",
    "        'largest_loss': largest_loss,\n",
    "        'profit_factor': profit_factor,\n",
    "        'expectancy': expectancy,\n",
    "        \n",
    "        # Capital\n",
    "        'total_capital_deployed': total_capital_deployed,\n",
    "        'avg_capital_per_trade': total_capital_deployed / num_trades if num_trades > 0 else 0,\n",
    "        \n",
    "        # Returns\n",
    "        'total_return_pct': total_return_realistic,  # Realistic return\n",
    "        'total_return_curve_pct': total_return_curve,  # For equity curve display\n",
    "        'avg_roc_per_trade': avg_roc,\n",
    "        'cagr': cagr,\n",
    "        'annualized_return': annualized_return * 100,\n",
    "        'annualized_volatility': annualized_vol * 100,\n",
    "        \n",
    "        # Risk Metrics\n",
    "        'max_drawdown': max_drawdown,\n",
    "        'max_drawdown_pct': max_drawdown_pct,\n",
    "        'sharpe_ratio': sharpe_ratio,\n",
    "        'sortino_ratio': sortino_ratio if sortino_ratio != float('inf') else 99.99,\n",
    "        'calmar_ratio': calmar_ratio if calmar_ratio != float('inf') else 99.99,\n",
    "        'recovery_factor': recovery_factor if recovery_factor != float('inf') else 99.99,\n",
    "        \n",
    "        # Time\n",
    "        'start_date': start_date,\n",
    "        'end_date': end_date,\n",
    "        'trading_days': trading_days,\n",
    "        'avg_days_held': avg_days_held,\n",
    "        'best_month_pct': best_month,\n",
    "        'worst_month_pct': worst_month,\n",
    "        \n",
    "        # Data for plotting\n",
    "        '_equity_curve': totals[['entry_date_parsed', 'equity', 'drawdown_pct']].copy(),\n",
    "        '_monthly_returns': monthly_returns,\n",
    "        '_trade_pnl': totals[pnl_col].values,\n",
    "    }\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "\n",
    "def print_hf_metrics(metrics):\n",
    "    \"\"\"Print formatted hedge fund metrics.\"\"\"\n",
    "    if metrics is None:\n",
    "        print(\"⚠ No metrics to display\")\n",
    "        return\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"  HEDGE FUND PERFORMANCE REPORT\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    print(f\"\\n{'─'*35} OVERVIEW {'─'*34}\")\n",
    "    print(f\"  Period:              {metrics['start_date'].strftime('%Y-%m-%d')} to {metrics['end_date'].strftime('%Y-%m-%d')} ({metrics['trading_days']} days)\")\n",
    "    print(f\"  Total Trades:        {metrics['total_trades']}\")\n",
    "    print(f\"  Avg Holding Period:  {metrics['avg_days_held']:.1f} days\")\n",
    "    \n",
    "    print(f\"\\n{'─'*35} CAPITAL {'─'*35}\")\n",
    "    print(f\"  Total Deployed:      ${metrics['total_capital_deployed']:>12,.0f}\")\n",
    "    print(f\"  Avg Per Trade:       ${metrics['avg_capital_per_trade']:>12,.0f}\")\n",
    "    \n",
    "    print(f\"\\n{'─'*35} RETURNS {'─'*35}\")\n",
    "    print(f\"  Total P&L:           ${metrics['total_pnl']:>12,.2f}\")\n",
    "    print(f\"  Return on Capital:   {metrics['total_return_pct']:>12.2f}%  (P&L / Capital Deployed)\")\n",
    "    print(f\"  Avg ROC per Trade:   {metrics['avg_roc_per_trade']:>12.2f}%\")\n",
    "    print(f\"  Annualized Return:   {metrics['annualized_return']:>12.2f}%  (Avg ROC × Trades/Year)\")\n",
    "    print(f\"  Annualized Vol:      {metrics['annualized_volatility']:>12.2f}%\")\n",
    "    \n",
    "    print(f\"\\n{'─'*35} RISK METRICS {'─'*30}\")\n",
    "    print(f\"  Max Drawdown:        ${metrics['max_drawdown']:>12,.2f} ({metrics['max_drawdown_pct']:.2f}%)\")\n",
    "    print(f\"  Sharpe Ratio:        {metrics['sharpe_ratio']:>12.2f}\")\n",
    "    print(f\"  Sortino Ratio:       {metrics['sortino_ratio']:>12.2f}\")\n",
    "    print(f\"  Calmar Ratio:        {metrics['calmar_ratio']:>12.2f}\")\n",
    "    print(f\"  Recovery Factor:     {metrics['recovery_factor']:>12.2f}\")\n",
    "    \n",
    "    print(f\"\\n{'─'*35} WIN/LOSS ANALYSIS {'─'*25}\")\n",
    "    print(f\"  Win Rate:            {metrics['win_rate']:>12.1f}%\")\n",
    "    print(f\"  Winners / Losers:    {metrics['winning_trades']:>5} / {metrics['losing_trades']}\")\n",
    "    print(f\"  Profit Factor:       {metrics['profit_factor']:>12.2f}\")\n",
    "    print(f\"  Expectancy:          ${metrics['expectancy']:>12.2f}\")\n",
    "    print(f\"  Avg Win:             ${metrics['avg_win']:>12.2f}\")\n",
    "    print(f\"  Avg Loss:            ${metrics['avg_loss']:>12.2f}\")\n",
    "    print(f\"  Largest Win:         ${metrics['largest_win']:>12.2f}\")\n",
    "    print(f\"  Largest Loss:        ${metrics['largest_loss']:>12.2f}\")\n",
    "    \n",
    "    print(f\"\\n{'─'*35} MONTHLY {'─'*35}\")\n",
    "    print(f\"  Best Month:          {metrics['best_month_pct']:>12.2f}%\")\n",
    "    print(f\"  Worst Month:         {metrics['worst_month_pct']:>12.2f}%\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "\n",
    "\n",
    "print(\"✓ HF Metrics Functions Loaded\")\n",
    "print(\"  - calculate_hf_metrics(results_df, initial_capital, risk_free_rate)\")\n",
    "print(\"  - print_hf_metrics(metrics)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ad802078",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Dashboard Functions Loaded\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# PERFORMANCE DASHBOARD\n",
    "# =============================================================================\n",
    "\n",
    "def plot_performance_dashboard(metrics, figsize=(16, 12)):\n",
    "    \"\"\"Create a comprehensive performance dashboard.\"\"\"\n",
    "    if metrics is None:\n",
    "        print(\"⚠ No metrics to plot\")\n",
    "        return\n",
    "    \n",
    "    plt.style.use('seaborn-v0_8-whitegrid')\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    gs = fig.add_gridspec(3, 3, hspace=0.35, wspace=0.3)\n",
    "    \n",
    "    green, red, blue, orange = '#2ecc71', '#e74c3c', '#3498db', '#f39c12'\n",
    "    \n",
    "    # 1. EQUITY CURVE\n",
    "    ax1 = fig.add_subplot(gs[0, :2])\n",
    "    equity_data = metrics['_equity_curve']\n",
    "    ax1.plot(equity_data['entry_date_parsed'], equity_data['equity'], color=blue, linewidth=2)\n",
    "    ax1.axhline(y=100000, color='gray', linestyle='--', alpha=0.5)\n",
    "    ax1.fill_between(equity_data['entry_date_parsed'], 100000, equity_data['equity'],\n",
    "                     where=equity_data['equity'] >= 100000, alpha=0.3, color=green)\n",
    "    ax1.fill_between(equity_data['entry_date_parsed'], 100000, equity_data['equity'],\n",
    "                     where=equity_data['equity'] < 100000, alpha=0.3, color=red)\n",
    "    ax1.set_title('Equity Curve', fontsize=14, fontweight='bold')\n",
    "    ax1.set_ylabel('Portfolio Value ($)')\n",
    "    ax1.xaxis.set_major_formatter(mdates.DateFormatter('%b %Y'))\n",
    "    ax1.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'${x:,.0f}'))\n",
    "    \n",
    "    # 2. KEY METRICS CARD\n",
    "    ax2 = fig.add_subplot(gs[0, 2])\n",
    "    ax2.axis('off')\n",
    "    metrics_text = f\"\"\"\n",
    "┌─────────────────────────────────┐\n",
    "│      KEY METRICS                │\n",
    "├─────────────────────────────────┤\n",
    "│  Capital Deployed: ${metrics['total_capital_deployed']/1e6:.1f}M     │\n",
    "│  Return on Cap:    {metrics['total_return_pct']:>6.2f}%      │\n",
    "│  Avg ROC/Trade:    {metrics['avg_roc_per_trade']:>6.2f}%      │\n",
    "│  Sharpe:           {metrics['sharpe_ratio']:>6.2f}       │\n",
    "│  Max DD:           {metrics['max_drawdown_pct']:>6.1f}%      │\n",
    "├─────────────────────────────────┤\n",
    "│  Win Rate:         {metrics['win_rate']:>6.1f}%      │\n",
    "│  Profit Factor:    {metrics['profit_factor']:>6.2f}       │\n",
    "│  Trades:           {metrics['total_trades']:>6d}       │\n",
    "└─────────────────────────────────┘\n",
    "\"\"\"\n",
    "    ax2.text(0.5, 0.5, metrics_text, transform=ax2.transAxes, fontsize=10, fontfamily='monospace',\n",
    "             verticalalignment='center', horizontalalignment='center',\n",
    "             bbox=dict(boxstyle='round', facecolor='#ecf0f1', edgecolor='#bdc3c7'))\n",
    "    \n",
    "    # 3. DRAWDOWN CHART\n",
    "    ax3 = fig.add_subplot(gs[1, :2])\n",
    "    ax3.fill_between(equity_data['entry_date_parsed'], 0, equity_data['drawdown_pct'], color=red, alpha=0.5)\n",
    "    ax3.axhline(y=metrics['max_drawdown_pct'], color='darkred', linestyle='--', alpha=0.7,\n",
    "                label=f\"Max DD: {metrics['max_drawdown_pct']:.1f}%\")\n",
    "    ax3.set_title('Drawdown', fontsize=14, fontweight='bold')\n",
    "    ax3.set_ylabel('Drawdown (%)')\n",
    "    ax3.legend(loc='lower left')\n",
    "    ax3.xaxis.set_major_formatter(mdates.DateFormatter('%b %Y'))\n",
    "    \n",
    "    # 4. TRADE P&L DISTRIBUTION\n",
    "    ax4 = fig.add_subplot(gs[1, 2])\n",
    "    trade_pnl = metrics['_trade_pnl']\n",
    "    ax4.hist(trade_pnl, bins=30, color=blue, alpha=0.7, edgecolor='white')\n",
    "    ax4.axvline(x=0, color='gray', linestyle='--', alpha=0.7)\n",
    "    ax4.axvline(x=np.mean(trade_pnl), color=green, linewidth=2, label=f\"Mean: ${np.mean(trade_pnl):,.0f}\")\n",
    "    ax4.set_title('Trade P&L Distribution', fontsize=14, fontweight='bold')\n",
    "    ax4.set_xlabel('P&L ($)')\n",
    "    ax4.legend(fontsize=9)\n",
    "    \n",
    "    # 5. MONTHLY RETURNS\n",
    "    ax5 = fig.add_subplot(gs[2, :2])\n",
    "    monthly_returns = metrics['_monthly_returns']\n",
    "    months = [str(m) for m in monthly_returns.index]\n",
    "    values = monthly_returns.values\n",
    "    colors_bar = [green if v >= 0 else red for v in values]\n",
    "    bars = ax5.bar(range(len(months)), values, color=colors_bar, alpha=0.8)\n",
    "    ax5.axhline(y=0, color='gray', linestyle='-', alpha=0.5)\n",
    "    ax5.set_title('Monthly Returns (%)', fontsize=14, fontweight='bold')\n",
    "    ax5.set_xticks(range(len(months)))\n",
    "    ax5.set_xticklabels(months, rotation=45, ha='right')\n",
    "    \n",
    "    # 6. WIN/LOSS PIE\n",
    "    ax6 = fig.add_subplot(gs[2, 2])\n",
    "    sizes = [metrics['winning_trades'], metrics['losing_trades']]\n",
    "    if sum(sizes) > 0:\n",
    "        ax6.pie(sizes, labels=[f\"Win\\n{sizes[0]}\", f\"Loss\\n{sizes[1]}\"], colors=[green, red],\n",
    "                autopct='%1.1f%%', startangle=90)\n",
    "    ax6.set_title('Win/Loss', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    fig.suptitle(f\"Wheel Strategy Dashboard: {metrics['start_date'].strftime('%Y-%m-%d')} to {metrics['end_date'].strftime('%Y-%m-%d')}\",\n",
    "                 fontsize=14, fontweight='bold', y=1.01)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    return fig\n",
    "\n",
    "print(\"✓ Dashboard Functions Loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996a4b41",
   "metadata": {},
   "source": [
    "# =============================================================================\n",
    "# RUN HF METRICS & DASHBOARD\n",
    "# =============================================================================\n",
    "\n",
    "if 'v5_results_df' in dir() and len(v5_results_df) > 0:\n",
    "    # Calculate metrics\n",
    "    hf_metrics = calculate_hf_metrics(\n",
    "        v5_results_df,\n",
    "        initial_capital=100000,\n",
    "        risk_free_rate=0.05\n",
    "    )\n",
    "    \n",
    "    # Print report\n",
    "    print_hf_metrics(hf_metrics)\n",
    "    \n",
    "    # Plot dashboard\n",
    "    plot_performance_dashboard(hf_metrics)\n",
    "else:\n",
    "    print(\"⚠ v5_results_df not found. Run the scheduler first (cells 20-22).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e4e824e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "METRICS SUMMARY (for comparison)\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Run</th>\n",
       "      <td>V5 Scheduler</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trades</th>\n",
       "      <td>377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total P&amp;L</th>\n",
       "      <td>$190,932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Capital Deployed</th>\n",
       "      <td>$0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROC</th>\n",
       "      <td>190.93%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Avg ROC/Trade</th>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Win Rate</th>\n",
       "      <td>100.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sharpe</th>\n",
       "      <td>77.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Max DD</th>\n",
       "      <td>0.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Profit Factor</th>\n",
       "      <td>190932.18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             0\n",
       "Run               V5 Scheduler\n",
       "Trades                     377\n",
       "Total P&L             $190,932\n",
       "Capital Deployed            $0\n",
       "ROC                    190.93%\n",
       "Avg ROC/Trade            0.00%\n",
       "Win Rate                100.0%\n",
       "Sharpe                   77.28\n",
       "Max DD                    0.0%\n",
       "Profit Factor        190932.18"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# METRICS SUMMARY TABLE (for comparison across runs)\n",
    "# =============================================================================\n",
    "\n",
    "def metrics_to_dataframe(metrics, run_name='Current'):\n",
    "    \"\"\"Convert metrics dict to a DataFrame row for comparison.\"\"\"\n",
    "    if metrics is None:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # Safely get values with defaults for backwards compatibility\n",
    "    summary = {\n",
    "        'Run': run_name,\n",
    "        'Trades': metrics.get('total_trades', 0),\n",
    "        'Total P&L': f\"${metrics.get('total_pnl', 0):,.0f}\",\n",
    "        'Capital Deployed': f\"${metrics.get('total_capital_deployed', 0):,.0f}\",\n",
    "        'ROC': f\"{metrics.get('total_return_pct', 0):.2f}%\",\n",
    "        'Avg ROC/Trade': f\"{metrics.get('avg_roc_per_trade', 0):.2f}%\",\n",
    "        'Win Rate': f\"{metrics.get('win_rate', 0):.1f}%\",\n",
    "        'Sharpe': f\"{metrics.get('sharpe_ratio', 0):.2f}\",\n",
    "        'Max DD': f\"{metrics.get('max_drawdown_pct', 0):.1f}%\",\n",
    "        'Profit Factor': f\"{metrics.get('profit_factor', 0):.2f}\",\n",
    "    }\n",
    "    return pd.DataFrame([summary])\n",
    "\n",
    "# Display summary table\n",
    "if 'hf_metrics' in dir() and hf_metrics is not None:\n",
    "    print(\"=\" * 70)\n",
    "    print(\"METRICS SUMMARY (for comparison)\")\n",
    "    print(\"=\" * 70)\n",
    "    summary_df = metrics_to_dataframe(hf_metrics, run_name='V5 Scheduler')\n",
    "    display(summary_df.T)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
