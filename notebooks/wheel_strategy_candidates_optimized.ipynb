{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wheel Strategy Candidates - Optimized Multi-Ticker Scanner\n",
    "\n",
    "**Purpose**: Collect wheel strategy option candidates across multiple tickers and days\n",
    "\n",
    "**Features**:\n",
    "- Multi-ticker support (AAPL, TSLA, expandable to 600+)\n",
    "- Smart pre-filtering: Only fetch options for days with BB/SMA entry signals\n",
    "- Batch API calls: Minimize Databento requests\n",
    "- Trading-day DTE calculation (not calendar days)\n",
    "- Actual IV calculation from market prices (not hardcoded)\n",
    "- Delta calculated using actual IV\n",
    "\n",
    "**Workflow**:\n",
    "1. Configuration\n",
    "2. Fetch equity data → Calculate BB & SMA → Identify entry signals\n",
    "3. Batch fetch options only for qualifying days\n",
    "4. Parse symbols, calculate trading-day DTE\n",
    "5. Merge underlying prices\n",
    "6. Calculate IV and delta\n",
    "7. Output results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 1: Imports & Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core imports\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "\n",
    "# Databento\n",
    "import databento as db\n",
    "\n",
    "# Options pricing\n",
    "from py_vollib.black_scholes import implied_volatility\n",
    "from py_vollib.black_scholes.greeks.analytical import delta\n",
    "\n",
    "# Market calendar\n",
    "import pandas_market_calendars as mcal\n",
    "\n",
    "# Environment\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "print(\"✓ All imports successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "env_path = Path(\"/Users/samuelminer/Projects/nissan_options/wheel_strategy/.env\")\n",
    "load_dotenv(env_path, override=True)\n",
    "\n",
    "# Verify API key\n",
    "assert os.getenv(\"DATABENTO_API_KEY\"), \"DATABENTO_API_KEY not found in .env\"\n",
    "\n",
    "# Initialize Databento client\n",
    "client = db.Historical()\n",
    "\n",
    "# Initialize NYSE calendar for trading day calculations\n",
    "nyse = mcal.get_calendar('NYSE')\n",
    "\n",
    "print(\"✓ Environment loaded\")\n",
    "print(\"✓ Databento client initialized\")\n",
    "print(\"✓ NYSE calendar initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "CONFIG = {\n",
    "    # Tickers to scan\n",
    "    'tickers': ['AAPL', 'TSLA'],\n",
    "    \n",
    "    # Number of entry signal days to collect per ticker\n",
    "    'num_days': 10,  # Last 10 trading days with BB/SMA entry signals\n",
    "    \n",
    "    # Historical data for Bollinger Bands calculation\n",
    "    'lookback_days': 504,  # 2 years of trading days\n",
    "    \n",
    "    # Bollinger Bands parameters\n",
    "    'bb_window': 20,  # 20-day SMA\n",
    "    'bb_std': 2.0,    # 2 standard deviations\n",
    "    \n",
    "    # Options collection parameters\n",
    "    'collection_time': '15:45',  # Eastern Time\n",
    "    'min_dte': 30,\n",
    "    'max_dte': 45,\n",
    "    'option_type': 'P',  # Puts only for wheel strategy\n",
    "    \n",
    "    # Greeks calculation\n",
    "    'risk_free_rate': 0.05,  # 5%\n",
    "    \n",
    "    # Data settings\n",
    "    'timezone': 'America/New_York',\n",
    "    'equity_dataset': 'EQUS.MINI',  # Consolidated US equities\n",
    "    'options_dataset': 'OPRA.PILLAR',  # Options data\n",
    "}\n",
    "\n",
    "print(\"Configuration:\")\n",
    "for key, value in CONFIG.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 2: Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_opra_symbol(symbol: str):\n",
    "    \"\"\"\n",
    "    Parse OSI option symbol format: \"AAPL 230721P00180000\"\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (root, expiration_date, call_put, strike)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        parts = symbol.split()\n",
    "        if len(parts) != 2:\n",
    "            return None, None, None, None\n",
    "        \n",
    "        root = parts[0]\n",
    "        rest = parts[1]\n",
    "        \n",
    "        # Parse date: YYMMDD (first 6 chars)\n",
    "        date_str = rest[:6]\n",
    "        year = 2000 + int(date_str[:2])\n",
    "        month = int(date_str[2:4])\n",
    "        day = int(date_str[4:6])\n",
    "        expiration = datetime(year, month, day)\n",
    "        \n",
    "        # Parse call/put (7th char)\n",
    "        call_put = rest[6]\n",
    "        \n",
    "        # Parse strike (remaining 8 chars, divide by 1000)\n",
    "        strike = int(rest[7:]) / 1000.0\n",
    "        \n",
    "        return root, expiration, call_put, strike\n",
    "    except Exception:\n",
    "        return None, None, None, None\n",
    "\n",
    "# Test\n",
    "root, exp, cp, strike = parse_opra_symbol(\"AAPL 230721P00180000\")\n",
    "print(f\"Test: AAPL 230721P00180000 → {root}, {exp}, {cp}, ${strike}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def calculate_dte_trading_days(event_date, exp_date, nyse_calendar):\n    \"\"\"\n    Calculate trading days to expiration (excludes weekends and holidays)\n    \n    Args:\n        event_date: Date of quote\n        exp_date: Expiration date\n        nyse_calendar: pandas_market_calendars NYSE calendar\n    \n    Returns:\n        int: Number of trading days\n    \"\"\"\n    # Normalize to dates (remove time component)\n    event_dt = pd.Timestamp(event_date).normalize()\n    exp_dt = pd.Timestamp(exp_date).normalize()\n    \n    # Get schedule for the date range\n    schedule = nyse_calendar.schedule(start_date=event_dt, end_date=exp_dt)\n    \n    # Count sessions between (exclusive of event_date, inclusive of exp_date)\n    sessions = schedule.index\n    trading_days = len(sessions[(sessions > event_dt) & (sessions <= exp_dt)])\n    \n    return trading_days\n\n# Test\ntest_dte = calculate_dte_trading_days(\n    datetime(2023, 6, 6),\n    datetime(2023, 7, 21),\n    nyse\n)\nprint(f\"Test: Trading days from 2023-06-06 to 2023-07-21 = {test_dte}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_iv(row, r=0.05):\n",
    "    \"\"\"\n",
    "    Calculate implied volatility from option market price\n",
    "    \n",
    "    Args:\n",
    "        row: DataFrame row with mid, underlying_last, strike, dte, call_put\n",
    "        r: Risk-free rate (default 5%)\n",
    "    \n",
    "    Returns:\n",
    "        float: Implied volatility or np.nan if calculation fails\n",
    "    \"\"\"\n",
    "    price = row[\"mid\"]  # (bid + ask) / 2\n",
    "    S = row[\"underlying_last\"]\n",
    "    K = row[\"strike\"]\n",
    "    t = row[\"dte\"] / 365.0\n",
    "    flag = \"p\" if row[\"call_put\"] == \"P\" else \"c\"\n",
    "\n",
    "    # Validation\n",
    "    if not (np.isfinite(price) and np.isfinite(S) and np.isfinite(K) and t > 0):\n",
    "        return np.nan\n",
    "    if price <= 0 or S <= 0 or K <= 0:\n",
    "        return np.nan\n",
    "\n",
    "    try:\n",
    "        return implied_volatility(price, S, K, t, r, flag)\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "\n",
    "print(\"✓ compute_iv() defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_delta(row, r=0.05):\n",
    "    \"\"\"\n",
    "    Calculate delta using Black-Scholes with actual IV\n",
    "    \n",
    "    Args:\n",
    "        row: DataFrame row with underlying_last, strike, dte, iv, call_put\n",
    "        r: Risk-free rate (default 5%)\n",
    "    \n",
    "    Returns:\n",
    "        float: Delta or np.nan if calculation fails\n",
    "    \"\"\"\n",
    "    S = row['underlying_last']\n",
    "    K = row['strike']\n",
    "    t = row['dte'] / 365.0\n",
    "    sigma = row['iv']  # Use calculated IV!\n",
    "    flag = 'p' if row['call_put'] == 'P' else 'c'\n",
    "\n",
    "    # Validation\n",
    "    if not np.isfinite(sigma) or sigma <= 0:\n",
    "        return np.nan\n",
    "    if not (np.isfinite(S) and np.isfinite(K) and t > 0):\n",
    "        return np.nan\n",
    "\n",
    "    try:\n",
    "        return delta(flag, S, K, t, r, sigma)\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "\n",
    "print(\"✓ calculate_delta() defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 3: Fetch Equity Data & Identify Entry Signals\n",
    "\n",
    "**Goal**: Find last 10 trading days per ticker where price triggers BB or SMA entry signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch equity data for all tickers\n",
    "print(\"Fetching equity data...\")\n",
    "\n",
    "equity_data = {}  # ticker -> DataFrame\n",
    "\n",
    "# Calculate date range\n",
    "end_date = pd.Timestamp.utcnow().normalize() - pd.Timedelta(days=1)\n",
    "start_date = end_date - pd.Timedelta(days=CONFIG['lookback_days'])\n",
    "\n",
    "for ticker in CONFIG['tickers']:\n",
    "    print(f\"\\n  Fetching {ticker}...\")\n",
    "    \n",
    "    try:\n",
    "        data = client.timeseries.get_range(\n",
    "            dataset=CONFIG['equity_dataset'],\n",
    "            symbols=ticker,\n",
    "            schema='ohlcv-1d',\n",
    "            stype_in='raw_symbol',\n",
    "            start=start_date,\n",
    "            end=end_date,\n",
    "        )\n",
    "        \n",
    "        df = data.to_df(tz=CONFIG['timezone'])\n",
    "        df.index.name = 'date'\n",
    "        \n",
    "        equity_data[ticker] = df\n",
    "        print(f\"    ✓ {len(df)} days fetched\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"    ✗ Error: {e}\")\n",
    "        continue\n",
    "\n",
    "print(f\"\\n✓ Equity data fetched for {len(equity_data)} tickers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Bollinger Bands and identify entry signals\n",
    "print(\"Calculating Bollinger Bands and entry signals...\")\n",
    "\n",
    "entry_signals = {}  # ticker -> DataFrame with signals\n",
    "\n",
    "for ticker, df in equity_data.items():\n",
    "    print(f\"\\n  Processing {ticker}...\")\n",
    "    \n",
    "    # Sort by date\n",
    "    df_bb = df.copy().sort_values('date')\n",
    "    \n",
    "    # Calculate rolling statistics\n",
    "    window = CONFIG['bb_window']\n",
    "    k = CONFIG['bb_std']\n",
    "    \n",
    "    roll = df_bb['close'].rolling(window=window, min_periods=window)\n",
    "    df_bb['sma20'] = roll.mean()\n",
    "    df_bb['std20'] = roll.std(ddof=0)\n",
    "    \n",
    "    # Bollinger Bands\n",
    "    df_bb['bb_upper'] = df_bb['sma20'] + k * df_bb['std20']\n",
    "    df_bb['bb_lower'] = df_bb['sma20'] - k * df_bb['std20']\n",
    "    \n",
    "    # Entry signals\n",
    "    df_signals = df_bb[['close', 'sma20', 'bb_lower']].dropna()\n",
    "    df_signals['sma_entry'] = df_signals['close'] <= df_signals['sma20']\n",
    "    df_signals['bb_entry'] = df_signals['close'] <= df_signals['bb_lower']\n",
    "    df_signals['entry_signal'] = df_signals['sma_entry'] | df_signals['bb_entry']\n",
    "    \n",
    "    entry_signals[ticker] = df_signals\n",
    "    \n",
    "    # Count signals\n",
    "    total_signals = df_signals['entry_signal'].sum()\n",
    "    sma_only = (df_signals['sma_entry'] & ~df_signals['bb_entry']).sum()\n",
    "    bb_signals = df_signals['bb_entry'].sum()\n",
    "    \n",
    "    print(f\"    Total entry signals: {total_signals}\")\n",
    "    print(f\"      - SMA only: {sma_only}\")\n",
    "    print(f\"      - BB lower: {bb_signals}\")\n",
    "\n",
    "print(\"\\n✓ Bollinger Bands calculated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get last N days with entry signals per ticker\n",
    "print(f\"Selecting last {CONFIG['num_days']} entry signal days per ticker...\")\n",
    "\n",
    "collection_schedule = []  # List of (ticker, date) tuples\n",
    "\n",
    "for ticker, df_signals in entry_signals.items():\n",
    "    # Filter to days with entry signals\n",
    "    signal_days = df_signals[df_signals['entry_signal']]\n",
    "    \n",
    "    # Take last N days\n",
    "    last_n_days = signal_days.index[-CONFIG['num_days']:].tolist()\n",
    "    \n",
    "    # Add to collection schedule\n",
    "    for date in last_n_days:\n",
    "        collection_schedule.append((ticker, date))\n",
    "    \n",
    "    print(f\"  {ticker}: {len(last_n_days)} days\")\n",
    "    print(f\"    Date range: {last_n_days[0].date()} to {last_n_days[-1].date()}\")\n",
    "\n",
    "print(f\"\\n✓ Total collection points: {len(collection_schedule)}\")\n",
    "print(f\"  (Will fetch options for {len(collection_schedule)} ticker-date combinations)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 4: Batch Fetch Options Data\n",
    "\n",
    "**Strategy**: One API call per ticker, fetch all dates in range, filter to 15:45 ET post-fetch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group collection schedule by ticker\n",
    "from collections import defaultdict\n",
    "\n",
    "ticker_dates = defaultdict(list)\n",
    "for ticker, date in collection_schedule:\n",
    "    ticker_dates[ticker].append(date)\n",
    "\n",
    "# Display grouping\n",
    "print(\"Options fetch plan (batched by ticker):\")\n",
    "for ticker, dates in ticker_dates.items():\n",
    "    print(f\"  {ticker}: {len(dates)} days ({dates[0].date()} to {dates[-1].date()})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch fetch options for all tickers\n",
    "print(\"\\nFetching options data (batched)...\")\n",
    "\n",
    "options_raw = {}  # ticker -> DataFrame\n",
    "\n",
    "for ticker, dates in ticker_dates.items():\n",
    "    print(f\"\\n  Fetching {ticker} options...\")\n",
    "    \n",
    "    # Calculate time range for batch fetch\n",
    "    min_date = min(dates)\n",
    "    max_date = max(dates)\n",
    "    \n",
    "    # Construct timestamp for 15:45 ET\n",
    "    start_time = pd.Timestamp(min_date.date()).tz_localize(CONFIG['timezone']).replace(hour=15, minute=45)\n",
    "    end_time = pd.Timestamp(max_date.date()).tz_localize(CONFIG['timezone']).replace(hour=15, minute=46)\n",
    "    \n",
    "    try:\n",
    "        data = client.timeseries.get_range(\n",
    "            dataset=CONFIG['options_dataset'],\n",
    "            schema='ohlcv-1m',\n",
    "            symbols=f'{ticker}.OPT',\n",
    "            stype_in='parent',\n",
    "            start=start_time,\n",
    "            end=end_time,\n",
    "        )\n",
    "        \n",
    "        df_opts = data.to_df(tz=CONFIG['timezone'])\n",
    "        \n",
    "        # Filter to exact dates in our collection schedule\n",
    "        df_opts['quote_date'] = df_opts.index.normalize()\n",
    "        target_dates = [pd.Timestamp(d).normalize() for d in dates]\n",
    "        df_opts = df_opts[df_opts['quote_date'].isin(target_dates)]\n",
    "        \n",
    "        options_raw[ticker] = df_opts\n",
    "        \n",
    "        print(f\"    ✓ {len(df_opts)} option contracts fetched\")\n",
    "        print(f\"      Unique symbols: {df_opts['symbol'].nunique()}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"    ✗ Error: {e}\")\n",
    "        continue\n",
    "\n",
    "print(f\"\\n✓ Options data fetched for {len(options_raw)} tickers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 5: Parse Symbols, Calculate DTE, Filter\n",
    "\n",
    "**Processing**:\n",
    "1. Parse OSI symbols\n",
    "2. Calculate trading-day DTE\n",
    "3. Filter: 30-45 DTE puts only\n",
    "4. Add ticker column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all options data and parse symbols\n",
    "print(\"Parsing option symbols...\")\n",
    "\n",
    "all_options = []\n",
    "\n",
    "for ticker, df_opts in options_raw.items():\n",
    "    print(f\"\\n  Processing {ticker}...\")\n",
    "    \n",
    "    # Add ticker column\n",
    "    df_opts = df_opts.copy()\n",
    "    df_opts['ticker'] = ticker\n",
    "    \n",
    "    # Parse symbols\n",
    "    parsed = df_opts['symbol'].apply(parse_opra_symbol)\n",
    "    df_opts[['root', 'expiration', 'call_put', 'strike']] = pd.DataFrame(\n",
    "        parsed.tolist(),\n",
    "        index=df_opts.index\n",
    "    )\n",
    "    \n",
    "    # Drop failed parses\n",
    "    before = len(df_opts)\n",
    "    df_opts = df_opts.dropna(subset=['root', 'expiration', 'call_put', 'strike'])\n",
    "    after = len(df_opts)\n",
    "    \n",
    "    print(f\"    Parsed {after}/{before} symbols successfully\")\n",
    "    \n",
    "    all_options.append(df_opts)\n",
    "\n",
    "# Combine all tickers\n",
    "options_combined = pd.concat(all_options, ignore_index=False)\n",
    "\n",
    "print(f\"\\n✓ Combined: {len(options_combined)} option contracts across {len(options_raw)} tickers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate trading-day DTE\n",
    "print(\"Calculating trading-day DTE...\")\n",
    "\n",
    "options_combined['dte'] = options_combined.apply(\n",
    "    lambda row: calculate_dte_trading_days(\n",
    "        row.name,  # ts_event from index\n",
    "        row['expiration'],\n",
    "        nyse\n",
    "    ),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "print(f\"  DTE range: {options_combined['dte'].min()} to {options_combined['dte'].max()} trading days\")\n",
    "print(f\"\\n✓ DTE calculated for {len(options_combined)} contracts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter: 30-45 DTE puts only\n",
    "print(f\"\\nFiltering: {CONFIG['min_dte']}-{CONFIG['max_dte']} DTE, type={CONFIG['option_type']}...\")\n",
    "\n",
    "before = len(options_combined)\n",
    "\n",
    "candidates = options_combined[\n",
    "    (options_combined['dte'] >= CONFIG['min_dte']) &\n",
    "    (options_combined['dte'] <= CONFIG['max_dte']) &\n",
    "    (options_combined['call_put'] == CONFIG['option_type'])\n",
    "].copy()\n",
    "\n",
    "after = len(candidates)\n",
    "\n",
    "print(f\"  Filtered: {after} / {before} contracts ({after/before*100:.1f}%)\")\n",
    "print(f\"\\nBy ticker:\")\n",
    "print(candidates['ticker'].value_counts())\n",
    "\n",
    "print(f\"\\n✓ Filtered candidates ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 6: Fetch Underlying Prices & Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch underlying prices at same timestamps\n",
    "print(\"Fetching underlying equity prices at 15:45 ET...\")\n",
    "\n",
    "underlying_prices = {}  # ticker -> DataFrame\n",
    "\n",
    "for ticker, dates in ticker_dates.items():\n",
    "    print(f\"\\n  Fetching {ticker} spot prices...\")\n",
    "    \n",
    "    # Calculate time range\n",
    "    min_date = min(dates)\n",
    "    max_date = max(dates)\n",
    "    \n",
    "    # 15:45 ET timestamps\n",
    "    start_time = pd.Timestamp(min_date.date()).tz_localize(CONFIG['timezone']).replace(hour=15, minute=45)\n",
    "    end_time = pd.Timestamp(max_date.date()).tz_localize(CONFIG['timezone']).replace(hour=15, minute=46)\n",
    "    \n",
    "    try:\n",
    "        data = client.timeseries.get_range(\n",
    "            dataset=CONFIG['equity_dataset'],\n",
    "            symbols=ticker,\n",
    "            schema='ohlcv-1m',\n",
    "            stype_in='raw_symbol',\n",
    "            start=start_time,\n",
    "            end=end_time,\n",
    "        )\n",
    "        \n",
    "        df_equity = data.to_df(tz=CONFIG['timezone'])\n",
    "        df_equity['ticker'] = ticker\n",
    "        \n",
    "        underlying_prices[ticker] = df_equity\n",
    "        \n",
    "        print(f\"    ✓ {len(df_equity)} price points fetched\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"    ✗ Error: {e}\")\n",
    "        continue\n",
    "\n",
    "# Combine all underlying prices\n",
    "underlying_combined = pd.concat(underlying_prices.values())\n",
    "\n",
    "print(f\"\\n✓ Underlying prices fetched for {len(underlying_prices)} tickers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge underlying prices with candidates\n",
    "print(\"Merging underlying prices with options...\")\n",
    "\n",
    "# Extract close price and rename\n",
    "underlying_combined['underlying_last'] = underlying_combined['close']\n",
    "\n",
    "# Merge on timestamp and ticker\n",
    "candidates = candidates.merge(\n",
    "    underlying_combined[['ticker', 'underlying_last']],\n",
    "    left_index=True,\n",
    "    right_index=True,\n",
    "    left_on='ticker',\n",
    "    right_on='ticker',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Check for missing underlying prices\n",
    "missing = candidates['underlying_last'].isna().sum()\n",
    "if missing > 0:\n",
    "    print(f\"  ⚠ Warning: {missing} options missing underlying price\")\n",
    "    candidates = candidates.dropna(subset=['underlying_last'])\n",
    "    print(f\"    Dropped, {len(candidates)} remaining\")\n",
    "\n",
    "print(f\"\\n✓ Underlying prices merged\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 7: Calculate IV and Delta\n",
    "\n",
    "**Order matters**: IV first, then delta using actual IV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mid price (for IV calculation)\n",
    "print(\"Calculating mid prices...\")\n",
    "\n",
    "# Use bid/ask from OHLCV close as proxy (or fetch from bid-ask data)\n",
    "# For OHLCV schema, we'll use close as mid approximation\n",
    "# Note: For production, should fetch actual bid/ask from mbp/trades schema\n",
    "\n",
    "candidates['bid'] = candidates['close'] * 0.98  # Approximate bid\n",
    "candidates['ask'] = candidates['close'] * 1.02  # Approximate ask\n",
    "candidates['mid'] = candidates['close']  # Use close as mid\n",
    "\n",
    "print(f\"  ✓ Mid prices calculated (using close prices from OHLCV)\")\n",
    "print(f\"    Note: For production, fetch actual bid/ask from mbp schema\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Implied Volatility\n",
    "print(\"\\nCalculating implied volatility...\")\n",
    "\n",
    "candidates['iv'] = candidates.apply(\n",
    "    lambda row: compute_iv(row, r=CONFIG['risk_free_rate']),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Check IV calculation success rate\n",
    "valid_iv = candidates['iv'].notna().sum()\n",
    "total = len(candidates)\n",
    "\n",
    "print(f\"  IV calculated: {valid_iv} / {total} ({valid_iv/total*100:.1f}%)\")\n",
    "print(f\"  IV range: {candidates['iv'].min():.2f} to {candidates['iv'].max():.2f}\")\n",
    "print(f\"  IV mean: {candidates['iv'].mean():.2f}\")\n",
    "\n",
    "# Filter out failed IV calculations\n",
    "candidates = candidates.dropna(subset=['iv'])\n",
    "\n",
    "print(f\"\\n✓ {len(candidates)} candidates with valid IV\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Delta (using actual IV)\n",
    "print(\"Calculating delta...\")\n",
    "\n",
    "candidates['delta'] = candidates.apply(\n",
    "    lambda row: calculate_delta(row, r=CONFIG['risk_free_rate']),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Check delta calculation success rate\n",
    "valid_delta = candidates['delta'].notna().sum()\n",
    "total = len(candidates)\n",
    "\n",
    "print(f\"  Delta calculated: {valid_delta} / {total} ({valid_delta/total*100:.1f}%)\")\n",
    "print(f\"  Delta range: {candidates['delta'].min():.3f} to {candidates['delta'].max():.3f}\")\n",
    "print(f\"  Delta mean: {candidates['delta'].mean():.3f}\")\n",
    "\n",
    "# Add absolute delta for reference\n",
    "candidates['abs_delta'] = candidates['delta'].abs()\n",
    "\n",
    "print(f\"\\n✓ Delta calculated using actual IV\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 8: Output & Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add collection date for tracking\n",
    "candidates['collection_date'] = candidates.index.normalize()\n",
    "\n",
    "# Select final columns\n",
    "output_columns = [\n",
    "    'ticker', 'symbol', 'expiration', 'call_put', 'strike', 'dte',\n",
    "    'underlying_last', 'bid', 'ask', 'mid', 'volume',\n",
    "    'iv', 'delta', 'abs_delta', 'collection_date'\n",
    "]\n",
    "\n",
    "results = candidates[output_columns].copy()\n",
    "\n",
    "# Sort by ticker, DTE, strike\n",
    "results = results.sort_values(['ticker', 'dte', 'strike'])\n",
    "\n",
    "print(f\"\\n✓ Final results: {len(results)} candidates\")\n",
    "print(f\"\\nColumns: {list(results.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build backtest-ready trade log that records mid premium as the cost basis for each fill.\n",
    "backtest_columns = [\n",
    "    'ticker', 'symbol', 'expiration', 'strike', 'dte', 'iv', 'delta',\n",
    "    'mid', 'collection_date'\n",
    "]\n",
    "trade_log = results[backtest_columns].sort_values(['dte', 'strike']).reset_index(drop=True)\n",
    "CONTRACT_SIZE = 100\n",
    "trade_log['contract_size'] = CONTRACT_SIZE\n",
    "trade_log['premium_per_contract'] = trade_log['mid']\n",
    "trade_log['premium_total'] = trade_log['mid'] * CONTRACT_SIZE\n",
    "trade_log['cost_basis_per_contract'] = trade_log['mid']\n",
    "trade_log['cost_basis_total'] = trade_log['premium_total']\n",
    "trade_log['trade_date'] = trade_log['collection_date']\n",
    "trade_log = trade_log[\n",
    "    [\n",
    "        'ticker', 'symbol', 'expiration', 'strike', 'dte', 'iv', 'delta',\n",
    "        'collection_date', 'trade_date', 'mid', 'contract_size',\n",
    "        'premium_per_contract', 'premium_total',\n",
    "        'cost_basis_per_contract', 'cost_basis_total'\n",
    "    ]\n",
    "]\n",
    "backtest_log_path = Path(\"/Users/samuelminer/Projects/nissan_options/wheel_strategy/wheel_trade_log.csv\")\n",
    "trade_log.to_csv(backtest_log_path, index=False)\n",
    "print(\"\\nBacktest trade log ready for downstream analysis\")\n",
    "print(f\"  Rows: {len(trade_log)} entries | contract size: {CONTRACT_SIZE}\")\n",
    "print(trade_log[['symbol', 'mid', 'premium_total']].head(3).to_string(index=False))\n",
    "print(f\"  Saved to: {backtest_log_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics by ticker\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SUMMARY BY TICKER\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for ticker in results['ticker'].unique():\n",
    "    ticker_data = results[results['ticker'] == ticker]\n",
    "    \n",
    "    print(f\"\\n{ticker}:\")\n",
    "    print(f\"  Total candidates: {len(ticker_data)}\")\n",
    "    print(f\"  DTE range: {ticker_data['dte'].min()}-{ticker_data['dte'].max()}\")\n",
    "    print(f\"  Strike range: ${ticker_data['strike'].min():.2f} - ${ticker_data['strike'].max():.2f}\")\n",
    "    print(f\"  IV range: {ticker_data['iv'].min():.2f} - {ticker_data['iv'].max():.2f}\")\n",
    "    print(f\"  Delta range: {ticker_data['delta'].min():.3f} - {ticker_data['delta'].max():.3f}\")\n",
    "    print(f\"  Abs Delta range: {ticker_data['abs_delta'].min():.3f} - {ticker_data['abs_delta'].max():.3f}\")\n",
    "    print(f\"  Collection dates: {ticker_data['collection_date'].nunique()} unique days\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sample results\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SAMPLE RESULTS (First 10 per ticker)\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "display_cols = ['ticker', 'symbol', 'expiration', 'strike', 'dte', 'iv', 'delta']\n",
    "\n",
    "for ticker in results['ticker'].unique():\n",
    "    print(f\"\\n{ticker}:\")\n",
    "    print(results[results['ticker'] == ticker][display_cols].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to CSV\n",
    "output_path = Path(\"/Users/samuelminer/Projects/nissan_options/wheel_strategy/wheel_candidates.csv\")\n",
    "\n",
    "results.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"\\n✓ Results saved to: {output_path}\")\n",
    "print(f\"  Total candidates: {len(results)}\")\n",
    "print(f\"  Tickers: {', '.join(results['ticker'].unique())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full results preview\n",
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}