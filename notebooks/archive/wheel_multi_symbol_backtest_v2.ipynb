{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "header",
      "metadata": {},
      "source": [
        "# Multi-Symbol Wheel Strategy Backtest v2\n",
        "\n",
        "Enhanced backtest with realistic market simulation.\n",
        "\n",
        "**New Features in v2:**\n",
        "- **Transaction costs**: IBKR commissions and exchange fees\n",
        "- **Slippage modeling**: Bid-ask spread based execution simulation\n",
        "- **Liquidity filters**: Reject illiquid options (wide spreads, low size)\n",
        "- **Exit fallback cascade**: Daily close â†’ expiry logic when minute data unavailable\n",
        "- **Fixed cost basis**: Proper cash-secured/margin calculation\n",
        "- **Gross vs Net P&L**: Track impact of costs and slippage\n",
        "\n",
        "**Existing Features:**\n",
        "- Multi-symbol support (TSLA, AAPL, etc.)\n",
        "- Caching of API responses\n",
        "- Technical filter (Bollinger Bands/SMA)\n",
        "- Configurable DTE (trading vs calendar days)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "section-1",
      "metadata": {},
      "source": [
        "## 1. Imports & Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "id": "imports",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Setup complete\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "import sys\n",
        "\n",
        "# Load environment variables\n",
        "env_path = Path(\"/Users/samuelminer/Projects/nissan_options/wheel_strategy/.env\")\n",
        "load_dotenv(env_path, override=True)\n",
        "assert os.getenv(\"DATABENTO_API_KEY\"), \"DATABENTO_API_KEY not found\"\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import databento as db\n",
        "import pandas_market_calendars as mcal\n",
        "from py_vollib.black_scholes.implied_volatility import implied_volatility\n",
        "from py_vollib.black_scholes.greeks.analytical import delta\n",
        "\n",
        "# Initialize clients\n",
        "client = db.Historical()\n",
        "nyse = mcal.get_calendar(\"NYSE\")\n",
        "\n",
        "print(\"Setup complete\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cc1baa48",
      "metadata": {},
      "source": [
        "## 3b. Intermediate Step Caching\n",
        "\n",
        "Cache dataframes at each processing step for faster debugging and inspection."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "id": "22fab163",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Intermediate step caching functions defined\n",
            "\n",
            "Available steps to cache:\n",
            "  - 'parsed_options': After parse_option_symbols()\n",
            "  - 'chain_with_dte': After add_trading_dte()\n",
            "  - 'chain_with_greeks': After IV/delta calculation\n",
            "  - 'candidates': After initial filters (DTE, delta, type)\n",
            "  - 'liquidity_filtered': After liquidity filters\n",
            "  - 'backtest_candidates': Final candidates ready for exit strategy\n",
            "  - 'exits': Exit strategy results\n",
            "\n",
            "To clear caches: clear_step_cache_for_date('TSLA', '2023-06-06')\n"
          ]
        }
      ],
      "source": [
        "def get_step_cache_path(step_name, ticker, date):\n",
        "    \"\"\"\n",
        "    Get cache path for intermediate processing step.\n",
        "    \n",
        "    Args:\n",
        "        step_name: Name of processing step (e.g., 'parsed_options', 'candidates', etc.)\n",
        "        ticker: Ticker symbol\n",
        "        date: Date string (YYYY-MM-DD)\n",
        "    \n",
        "    Returns:\n",
        "        Full path to cache file\n",
        "    \"\"\"\n",
        "    cache_name = f\"step_{step_name}_{ticker}_{date}\"\n",
        "    return os.path.join(CONFIG['cache_dir'], f\"{cache_name}.parquet\")\n",
        "\n",
        "\n",
        "def load_step_cache(step_name, ticker, date):\n",
        "    \"\"\"\n",
        "    Load cached dataframe for a processing step.\n",
        "    \n",
        "    Returns:\n",
        "        DataFrame if cached, None if not found\n",
        "    \"\"\"\n",
        "    path = get_step_cache_path(step_name, ticker, date)\n",
        "    if os.path.exists(path):\n",
        "        print(f\"  [CACHE HIT] Loading step: {step_name} for {ticker} on {date}\")\n",
        "        return pd.read_parquet(path)\n",
        "    return None\n",
        "\n",
        "\n",
        "def save_step_cache(df, step_name, ticker, date):\n",
        "    \"\"\"\n",
        "    Save dataframe to cache for a processing step.\n",
        "    \"\"\"\n",
        "    path = get_step_cache_path(step_name, ticker, date)\n",
        "    df.to_parquet(path)\n",
        "    print(f\"  [CACHE SAVE] Saved step: {step_name} for {ticker} on {date}\")\n",
        "\n",
        "\n",
        "def clear_step_cache_for_date(ticker, date):\n",
        "    \"\"\"\n",
        "    Clear all step caches for a specific ticker/date combination.\n",
        "    Useful when you want to reprocess a specific date.\n",
        "    \"\"\"\n",
        "    pattern = f\"step_*_{ticker}_{date}.parquet\"\n",
        "    cache_dir = CONFIG['cache_dir']\n",
        "    \n",
        "    import glob\n",
        "    files = glob.glob(os.path.join(cache_dir, pattern))\n",
        "    \n",
        "    for f in files:\n",
        "        os.remove(f)\n",
        "        print(f\"  [CACHE CLEAR] Removed {os.path.basename(f)}\")\n",
        "    \n",
        "    if len(files) == 0:\n",
        "        print(f\"  [CACHE CLEAR] No step caches found for {ticker} on {date}\")\n",
        "\n",
        "\n",
        "# Example usage in process_entry_date():\n",
        "# \n",
        "# # After parsing symbols\n",
        "# df_parsed = load_step_cache('parsed_options', ticker, entry_date)\n",
        "# if df_parsed is None:\n",
        "#     df_parsed = parse_option_symbols(df_opts)\n",
        "#     save_step_cache(df_parsed, 'parsed_options', ticker, entry_date)\n",
        "#\n",
        "# # After filtering candidates\n",
        "# candidates = load_step_cache('candidates', ticker, entry_date)\n",
        "# if candidates is None:\n",
        "#     candidates = chain_snapshot[...filtering logic...]\n",
        "#     save_step_cache(candidates, 'candidates', ticker, entry_date)\n",
        "\n",
        "print(\"Intermediate step caching functions defined\")\n",
        "print(\"\")\n",
        "print(\"Available steps to cache:\")\n",
        "print(\"  - 'parsed_options': After parse_option_symbols()\")\n",
        "print(\"  - 'chain_with_dte': After add_trading_dte()\")\n",
        "print(\"  - 'chain_with_greeks': After IV/delta calculation\")\n",
        "print(\"  - 'candidates': After initial filters (DTE, delta, type)\")\n",
        "print(\"  - 'liquidity_filtered': After liquidity filters\")\n",
        "print(\"  - 'backtest_candidates': Final candidates ready for exit strategy\")\n",
        "print(\"  - 'exits': Exit strategy results\")\n",
        "print(\"\")\n",
        "print(\"To clear caches: clear_step_cache_for_date('TSLA', '2023-06-06')\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "697068c3",
      "metadata": {},
      "source": [
        "## 3c. Example: Using Step Caching\n",
        "\n",
        "The `process_entry_date` function now caches intermediate steps. Here's how it works:\n",
        "\n",
        "**Cached Steps:**\n",
        "1. `parsed_options` - After parsing OPRA symbols\n",
        "2. `chain_with_dte` - After calculating DTE\n",
        "3. `chain_with_greeks` - After IV/delta calculation\n",
        "4. `candidates` - After DTE/delta filters\n",
        "5. `liquidity_filtered` - After liquidity filters\n",
        "6. `backtest_candidates` - Final candidates ready for backtest\n",
        "7. `exits` - Exit strategy results\n",
        "\n",
        "**Cache Benefits:**\n",
        "- Speed up re-runs when testing different parameters\n",
        "- Inspect intermediate results for debugging  \n",
        "- Skip expensive calculations (IV, delta) on repeat runs\n",
        "\n",
        "**Example: Inspect a Specific Step**\n",
        "```python\n",
        "# Load cached candidates for TSLA on 2023-06-06\n",
        "candidates = load_step_cache('candidates', 'TSLA', '2023-06-06')\n",
        "if candidates is not None:\n",
        "    print(f\"Found {len(candidates)} candidates\")\n",
        "    print(candidates[['symbol', 'strike', 'dte', 'delta']].head())\n",
        "```\n",
        "\n",
        "**Clear Cache for Specific Date:**\n",
        "```python\n",
        "# Clear all step caches for TSLA on 2023-06-06\n",
        "clear_step_cache_for_date('TSLA', '2023-06-06')\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "id": "a3855321",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step caching examples ready (uncomment to use)\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# EXAMPLE: Inspect cached intermediate steps\n",
        "# =============================================================================\n",
        "\n",
        "# Uncomment to inspect a specific step for a ticker/date:\n",
        "\n",
        "# Step 1: Load parsed options\n",
        "# df = load_step_cache('parsed_options', 'TSLA', '2023-06-06')\n",
        "# if df is not None:\n",
        "#     print(f\"Parsed options: {len(df)} rows\")\n",
        "#     print(df[['symbol', 'expiration', 'strike', 'call_put']].head())\n",
        "\n",
        "# Step 2: Load chain with DTE\n",
        "# df = load_step_cache('chain_with_dte', 'TSLA', '2023-06-06')\n",
        "# if df is not None:\n",
        "#     print(f\"Chain with DTE: {len(df)} rows\")\n",
        "#     print(df[['symbol', 'dte', 'expiration']].head())\n",
        "\n",
        "# Step 3: Load chain with greeks\n",
        "# df = load_step_cache('chain_with_greeks', 'TSLA', '2023-06-06')\n",
        "# if df is not None:\n",
        "#     print(f\"Chain with greeks: {len(df)} rows\")\n",
        "#     print(df[['symbol', 'dte', 'iv', 'delta', 'mid']].head())\n",
        "\n",
        "# Step 4: Load filtered candidates\n",
        "# df = load_step_cache('candidates', 'TSLA', '2023-06-06')\n",
        "# if df is not None:\n",
        "#     print(f\"Candidates after filters: {len(df)} rows\")\n",
        "#     print(df[['symbol', 'strike', 'dte', 'delta', 'mid']].head())\n",
        "\n",
        "print(\"Step caching examples ready (uncomment to use)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "section-2",
      "metadata": {},
      "source": [
        "## 2. Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "id": "config",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Entry dates: ['2023-06-06']\n",
            "\n",
            "Tickers: ['TSLA', 'AAPL']\n",
            "Total combinations: 2 x 1 = 2\n",
            "\n",
            "--- Feature Toggles ---\n",
            "Transaction costs: ON\n",
            "Slippage: ON (spread_percentage)\n",
            "Liquidity filters: ON\n",
            "Exit fallback: daily_close=True, expiry_logic=True\n",
            "Margin mode: CASH-SECURED\n"
          ]
        }
      ],
      "source": [
        "CONFIG = {\n",
        "    # ==========================================================================\n",
        "    # TICKERS & DATES\n",
        "    # ==========================================================================\n",
        "    'tickers': ['TSLA', 'AAPL'],\n",
        "    'entry_dates': ['2023-06-06'],  # Or use 'start_date' and 'end_date' below\n",
        "    # 'start_date': '2023-06-01',\n",
        "    # 'end_date': '2023-06-30',\n",
        "\n",
        "    # ==========================================================================\n",
        "    # GENERAL SETTINGS\n",
        "    # ==========================================================================\n",
        "    'timezone': 'America/New_York',\n",
        "    'cache_dir': '../cache/',\n",
        "    'risk_free_rate': 0.04,\n",
        "\n",
        "    # ==========================================================================\n",
        "    # OPTION FILTERS\n",
        "    # ==========================================================================\n",
        "    'min_dte': 5,\n",
        "    'max_dte': 10,\n",
        "    'min_delta': 0.00,\n",
        "    'max_delta': 0.15,\n",
        "    'option_type': 'P',  # 'P' for puts, 'C' for calls\n",
        "\n",
        "    # ==========================================================================\n",
        "    # DTE CALCULATION\n",
        "    # ==========================================================================\n",
        "    'use_trading_days_for_dte_filter': True,   # True = trading days, False = calendar days\n",
        "    'use_trading_days_for_exit': True,         # True = trading days, False = calendar days\n",
        "\n",
        "    # ==========================================================================\n",
        "    # EXIT STRATEGY\n",
        "    # ==========================================================================\n",
        "    'profit_target_pct': 0.50,  # Exit at 50% of premium\n",
        "    'exit_dte': 0,              # Days before expiration to force exit (0 = expiration)\n",
        "\n",
        "    # ==========================================================================\n",
        "    # MARGIN SETTINGS\n",
        "    # ==========================================================================\n",
        "    'margin': {\n",
        "        'use_margin': False,        # False = cash-secured (full collateral)\n",
        "        'margin_requirement': 0.20, # 20% margin if use_margin=True\n",
        "    },\n",
        "\n",
        "    # ==========================================================================\n",
        "    # TRANSACTION COSTS (IBKR)\n",
        "    # ==========================================================================\n",
        "    'costs': {\n",
        "        'enabled': True,\n",
        "        'commission_per_contract': 0.25,    # IBKR tiered pricing\n",
        "        'exchange_fees_per_contract': 0.05, # OCC, exchange fees\n",
        "        'assignment_fee': 0.00,             # IBKR doesn't charge for assignment\n",
        "    },\n",
        "\n",
        "    # ==========================================================================\n",
        "    # SLIPPAGE\n",
        "    # ==========================================================================\n",
        "    'slippage': {\n",
        "        'enabled': True,\n",
        "        'model': 'spread_percentage',  # 'none', 'spread_percentage', 'fixed'\n",
        "        'spread_pct': 0.25,            # Lose 25% of half-spread on each trade\n",
        "        'fixed_amount': 0.02,          # Fixed $ per share if model='fixed'\n",
        "    },\n",
        "\n",
        "    # ==========================================================================\n",
        "    # LIQUIDITY FILTERS\n",
        "    # ==========================================================================\n",
        "    'liquidity': {\n",
        "        'enabled': True,\n",
        "        'max_spread_pct': 0.15,  # Max 15% bid-ask spread relative to mid\n",
        "        'min_bid_size': 10,      # Minimum contracts on bid\n",
        "        'min_ask_size': 10,      # Minimum contracts on ask\n",
        "    },\n",
        "\n",
        "    # ==========================================================================\n",
        "    # EXIT FALLBACK (when minute data unavailable)\n",
        "    # ==========================================================================\n",
        "    'exit_fallback': {\n",
        "        'use_daily_close': True,   # Fallback 1: Use daily OHLCV close\n",
        "        'use_expiry_logic': True,  # Fallback 2: ITM=intrinsic value, OTM=$0\n",
        "    },\n",
        "\n",
        "    # ==========================================================================\n",
        "    # TECHNICAL FILTER (Bollinger Bands)\n",
        "    # ==========================================================================\n",
        "    'technical_filter_enabled': False,\n",
        "    'bb_window': 20,\n",
        "    'bb_std': 2.0,\n",
        "    'require_sma_entry': True,\n",
        "    'require_bb_entry': False,\n",
        "}\n",
        "\n",
        "# =============================================================================\n",
        "# Initialize\n",
        "# =============================================================================\n",
        "os.makedirs(CONFIG['cache_dir'], exist_ok=True)\n",
        "\n",
        "# Convert date range to trading days if specified\n",
        "if 'start_date' in CONFIG and 'end_date' in CONFIG:\n",
        "    start = pd.Timestamp(CONFIG['start_date'])\n",
        "    end = pd.Timestamp(CONFIG['end_date'])\n",
        "    trading_days = nyse.valid_days(start_date=start, end_date=end)\n",
        "    CONFIG['entry_dates'] = [d.strftime('%Y-%m-%d') for d in trading_days]\n",
        "    print(f\"Date range: {CONFIG['start_date']} to {CONFIG['end_date']}\")\n",
        "    print(f\"Generated {len(CONFIG['entry_dates'])} trading days\")\n",
        "else:\n",
        "    print(f\"Entry dates: {CONFIG['entry_dates']}\")\n",
        "\n",
        "# Print configuration summary\n",
        "print(f\"\\nTickers: {CONFIG['tickers']}\")\n",
        "print(f\"Total combinations: {len(CONFIG['tickers'])} x {len(CONFIG['entry_dates'])} = {len(CONFIG['tickers']) * len(CONFIG['entry_dates'])}\")\n",
        "print(f\"\\n--- Feature Toggles ---\")\n",
        "print(f\"Transaction costs: {'ON' if CONFIG['costs']['enabled'] else 'OFF'}\")\n",
        "print(f\"Slippage: {'ON' if CONFIG['slippage']['enabled'] else 'OFF'} ({CONFIG['slippage']['model']})\")\n",
        "print(f\"Liquidity filters: {'ON' if CONFIG['liquidity']['enabled'] else 'OFF'}\")\n",
        "print(f\"Exit fallback: daily_close={CONFIG['exit_fallback']['use_daily_close']}, expiry_logic={CONFIG['exit_fallback']['use_expiry_logic']}\")\n",
        "print(f\"Margin mode: {'MARGIN' if CONFIG['margin']['use_margin'] else 'CASH-SECURED'}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "section-3",
      "metadata": {},
      "source": [
        "## 3. Caching Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "id": "caching",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Caching functions defined\n"
          ]
        }
      ],
      "source": [
        "def get_cache_path(name):\n",
        "    \"\"\"Get full path for a cache file\"\"\"\n",
        "    return os.path.join(CONFIG['cache_dir'], f\"{name}.parquet\")\n",
        "\n",
        "def load_from_cache(name):\n",
        "    \"\"\"Load DataFrame from cache if it exists\"\"\"\n",
        "    path = get_cache_path(name)\n",
        "    if os.path.exists(path):\n",
        "        print(f\"  [CACHE HIT] Loading {name}\")\n",
        "        return pd.read_parquet(path)\n",
        "    return None\n",
        "\n",
        "def save_to_cache(df, name):\n",
        "    \"\"\"Save DataFrame to cache\"\"\"\n",
        "    path = get_cache_path(name)\n",
        "    df.to_parquet(path)\n",
        "    print(f\"  [CACHE SAVE] Saved {name}\")\n",
        "\n",
        "print(\"Caching functions defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "23hngvjnqhv",
      "metadata": {},
      "source": [
        "## 3b. Cost, Slippage & Liquidity Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "id": "3ma6j598i6w",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cost, slippage & liquidity functions defined\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# COST BASIS CALCULATION\n",
        "# =============================================================================\n",
        "def calculate_cost_basis(strike, config):\n",
        "    \"\"\"\n",
        "    Calculate cost basis (collateral required) for a cash-secured put.\n",
        "    \n",
        "    Args:\n",
        "        strike: Strike price of the put\n",
        "        config: CONFIG dict with margin settings\n",
        "    \n",
        "    Returns:\n",
        "        Cost basis per contract (strike * 100 or margin-adjusted)\n",
        "    \"\"\"\n",
        "    if config['margin']['use_margin']:\n",
        "        return strike * 100 * config['margin']['margin_requirement']\n",
        "    return strike * 100  # Full cash-secured\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# TRANSACTION COSTS\n",
        "# =============================================================================\n",
        "def calculate_entry_costs(num_contracts, config):\n",
        "    \"\"\"\n",
        "    Calculate total costs for entering a position.\n",
        "    \n",
        "    Returns:\n",
        "        Total cost in dollars\n",
        "    \"\"\"\n",
        "    if not config['costs']['enabled']:\n",
        "        return 0.0\n",
        "    \n",
        "    commission = num_contracts * config['costs']['commission_per_contract']\n",
        "    exchange_fees = num_contracts * config['costs']['exchange_fees_per_contract']\n",
        "    return commission + exchange_fees\n",
        "\n",
        "\n",
        "def calculate_exit_costs(num_contracts, exit_reason, config):\n",
        "    \"\"\"\n",
        "    Calculate total costs for exiting a position.\n",
        "    \n",
        "    Args:\n",
        "        num_contracts: Number of contracts\n",
        "        exit_reason: 'profit_target', 'time_limit', 'expiry_itm', 'expiry_otm'\n",
        "        config: CONFIG dict\n",
        "    \n",
        "    Returns:\n",
        "        Total cost in dollars\n",
        "    \"\"\"\n",
        "    if not config['costs']['enabled']:\n",
        "        return 0.0\n",
        "    \n",
        "    # If assigned (ITM at expiry), may have assignment fee\n",
        "    if exit_reason == 'expiry_itm':\n",
        "        assignment = num_contracts * config['costs']['assignment_fee']\n",
        "        return assignment  # No commission when assigned\n",
        "    \n",
        "    # If expired worthless (OTM), no costs\n",
        "    if exit_reason == 'expiry_otm':\n",
        "        return 0.0\n",
        "    \n",
        "    # Regular exit (buy to close)\n",
        "    commission = num_contracts * config['costs']['commission_per_contract']\n",
        "    exchange_fees = num_contracts * config['costs']['exchange_fees_per_contract']\n",
        "    return commission + exchange_fees\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# SLIPPAGE\n",
        "# =============================================================================\n",
        "def apply_entry_slippage(mid, bid, ask, config):\n",
        "    \"\"\"\n",
        "    Apply slippage for SELLING (entry). Fill will be closer to bid.\n",
        "    \n",
        "    Args:\n",
        "        mid: Mid price\n",
        "        bid: Bid price\n",
        "        ask: Ask price\n",
        "        config: CONFIG dict with slippage settings\n",
        "    \n",
        "    Returns:\n",
        "        Adjusted fill price (lower than mid when selling)\n",
        "    \"\"\"\n",
        "    if not config['slippage']['enabled']:\n",
        "        return mid\n",
        "    \n",
        "    model = config['slippage']['model']\n",
        "    \n",
        "    if model == 'none':\n",
        "        return mid\n",
        "    elif model == 'spread_percentage':\n",
        "        # Lose a percentage of the half-spread\n",
        "        half_spread = (ask - bid) / 2\n",
        "        slippage = half_spread * config['slippage']['spread_pct']\n",
        "        return mid - slippage  # Sell lower than mid\n",
        "    elif model == 'fixed':\n",
        "        return mid - config['slippage']['fixed_amount']\n",
        "    else:\n",
        "        return mid\n",
        "\n",
        "\n",
        "def apply_exit_slippage(mid, bid, ask, config):\n",
        "    \"\"\"\n",
        "    Apply slippage for BUYING (exit). Fill will be closer to ask.\n",
        "    \n",
        "    Args:\n",
        "        mid: Mid price\n",
        "        bid: Bid price  \n",
        "        ask: Ask price\n",
        "        config: CONFIG dict with slippage settings\n",
        "    \n",
        "    Returns:\n",
        "        Adjusted fill price (higher than mid when buying)\n",
        "    \"\"\"\n",
        "    if not config['slippage']['enabled']:\n",
        "        return mid\n",
        "    \n",
        "    model = config['slippage']['model']\n",
        "    \n",
        "    if model == 'none':\n",
        "        return mid\n",
        "    elif model == 'spread_percentage':\n",
        "        half_spread = (ask - bid) / 2\n",
        "        slippage = half_spread * config['slippage']['spread_pct']\n",
        "        return mid + slippage  # Buy higher than mid\n",
        "    elif model == 'fixed':\n",
        "        return mid + config['slippage']['fixed_amount']\n",
        "    else:\n",
        "        return mid\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# LIQUIDITY FILTERS\n",
        "# =============================================================================\n",
        "def calculate_spread_pct(bid, ask):\n",
        "    \"\"\"Calculate bid-ask spread as percentage of mid price.\"\"\"\n",
        "    if bid <= 0 or ask <= 0:\n",
        "        return float('inf')\n",
        "    mid = (bid + ask) / 2\n",
        "    if mid <= 0:\n",
        "        return float('inf')\n",
        "    return (ask - bid) / mid\n",
        "\n",
        "\n",
        "def passes_liquidity_filter(row, config):\n",
        "    \"\"\"\n",
        "    Check if an option passes liquidity filters.\n",
        "    \n",
        "    Args:\n",
        "        row: DataFrame row with bid_px_00, ask_px_00, bid_sz_00, ask_sz_00\n",
        "        config: CONFIG dict with liquidity settings\n",
        "    \n",
        "    Returns:\n",
        "        (passes: bool, reason: str or None)\n",
        "    \"\"\"\n",
        "    if not config['liquidity']['enabled']:\n",
        "        return True, None\n",
        "    \n",
        "    bid = row.get('bid_px_00', 0)\n",
        "    ask = row.get('ask_px_00', 0)\n",
        "    bid_size = row.get('bid_sz_00', 0)\n",
        "    ask_size = row.get('ask_sz_00', 0)\n",
        "    \n",
        "    # Check spread\n",
        "    spread_pct = calculate_spread_pct(bid, ask)\n",
        "    if spread_pct > config['liquidity']['max_spread_pct']:\n",
        "        return False, f\"spread_too_wide ({spread_pct:.1%} > {config['liquidity']['max_spread_pct']:.1%})\"\n",
        "    \n",
        "    # Check bid size\n",
        "    if bid_size < config['liquidity']['min_bid_size']:\n",
        "        return False, f\"bid_size_low ({bid_size} < {config['liquidity']['min_bid_size']})\"\n",
        "    \n",
        "    # Check ask size\n",
        "    if ask_size < config['liquidity']['min_ask_size']:\n",
        "        return False, f\"ask_size_low ({ask_size} < {config['liquidity']['min_ask_size']})\"\n",
        "    \n",
        "    return True, None\n",
        "\n",
        "\n",
        "print(\"Cost, slippage & liquidity functions defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "section-4",
      "metadata": {},
      "source": [
        "## 4. Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "id": "helpers",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Helper functions defined\n"
          ]
        }
      ],
      "source": [
        "def parse_option_symbols(df):\n",
        "    \"\"\"Parse OPRA symbols into components\"\"\"\n",
        "    sym = df[\"symbol\"]\n",
        "    \n",
        "    # Split ROOT and OPRA code\n",
        "    root_and_code = sym.str.split(expand=True)\n",
        "    df[\"root\"] = root_and_code[0]\n",
        "    code = root_and_code[1]\n",
        "    \n",
        "    # Expiration: YYMMDD\n",
        "    df[\"expiration\"] = pd.to_datetime(code.str[:6], format=\"%y%m%d\")\n",
        "    \n",
        "    # Call/Put flag\n",
        "    df[\"call_put\"] = code.str[6]\n",
        "    \n",
        "    # Strike: in 1/1000 dollars\n",
        "    strike_int = code.str[7:].astype(\"int32\")\n",
        "    df[\"strike\"] = strike_int / 1000.0\n",
        "    \n",
        "    return df\n",
        "\n",
        "\n",
        "def add_trading_dte(df, tz=\"America/New_York\", use_trading_days=True):\n",
        "    \"\"\"\n",
        "    Add days-to-expiration using NYSE calendar or calendar days.\n",
        "    \n",
        "    Args:\n",
        "        df: DataFrame with ts_event and expiration columns\n",
        "        tz: Timezone for event dates\n",
        "        use_trading_days: If True, count trading days. If False, count calendar days.\n",
        "    \"\"\"\n",
        "    out = df.copy()\n",
        "    \n",
        "    # Event dates from ts_event column\n",
        "    event_dt = pd.to_datetime(out[\"ts_event\"]).dt.tz_convert(tz).dt.normalize()\n",
        "    event_days = pd.to_datetime(event_dt.dt.date)  # tz-naive\n",
        "    \n",
        "    # Expiration dates\n",
        "    exp_dt = pd.to_datetime(out[\"expiration\"])\n",
        "    exp_days = pd.to_datetime(exp_dt.dt.date)  # tz-naive\n",
        "    \n",
        "    if use_trading_days:\n",
        "        # Build trading calendar\n",
        "        start_date = event_days.min().date()\n",
        "        end_date = exp_days.max().date()\n",
        "        \n",
        "        schedule = nyse.valid_days(start_date=start_date, end_date=end_date)\n",
        "        schedule = pd.to_datetime(schedule).normalize().tz_localize(None)\n",
        "        \n",
        "        cal_index = pd.Series(np.arange(len(schedule), dtype=np.int32), index=schedule)\n",
        "        \n",
        "        event_idx = cal_index.reindex(event_days).to_numpy()\n",
        "        exp_idx = cal_index.reindex(exp_days).to_numpy()\n",
        "        \n",
        "        out[\"dte\"] = (exp_idx - event_idx - 1).astype(np.int16)\n",
        "    else:\n",
        "        # Calendar days (simple subtraction)\n",
        "        out[\"dte\"] = (exp_days - event_days).dt.days.astype(np.int16)\n",
        "    \n",
        "    return out\n",
        "\n",
        "\n",
        "def calculate_exit_dte_dates(expirations, exit_dte, use_trading_days=True):\n",
        "    \"\"\"\n",
        "    Calculate dates at exit_dte days before expiration.\n",
        "    \n",
        "    Args:\n",
        "        expirations: Series of expiration dates\n",
        "        exit_dte: Number of days before expiration to exit (0 = expiration day)\n",
        "        use_trading_days: If True, count trading days. If False, count calendar days\n",
        "                          (will adjust to prior market day if lands on non-trading day)\n",
        "    \n",
        "    Returns:\n",
        "        Series of exit dates (always valid trading days)\n",
        "    \"\"\"\n",
        "    if exit_dte == 0:\n",
        "        # Exit at expiration - return expiration dates (already trading days for options)\n",
        "        return expirations.apply(lambda x: pd.Timestamp(x).normalize())\n",
        "    \n",
        "    min_exp = expirations.min()\n",
        "    max_exp = expirations.max()\n",
        "    \n",
        "    start_date = min_exp - pd.Timedelta(days=60)\n",
        "    end_date = max_exp\n",
        "    \n",
        "    schedule = nyse.schedule(start_date=start_date, end_date=end_date)\n",
        "    trading_days = schedule.index.tz_localize(None)\n",
        "    trading_days_set = set(trading_days)\n",
        "    \n",
        "    results = []\n",
        "    for exp in expirations:\n",
        "        exp_dt = pd.Timestamp(exp).normalize()\n",
        "        \n",
        "        if use_trading_days:\n",
        "            # Count back trading days\n",
        "            valid_days = trading_days[trading_days <= exp_dt]\n",
        "            \n",
        "            if len(valid_days) >= exit_dte:\n",
        "                target_date = valid_days[-(exit_dte + 1)]  # +1 because expiration day is index -1\n",
        "            else:\n",
        "                target_date = valid_days[0] if len(valid_days) > 0 else exp_dt\n",
        "        else:\n",
        "            # Count back calendar days\n",
        "            target_date = exp_dt - pd.Timedelta(days=exit_dte)\n",
        "            \n",
        "            # If target_date is not a trading day, find the prior trading day\n",
        "            if target_date not in trading_days_set:\n",
        "                prior_days = trading_days[trading_days < target_date]\n",
        "                if len(prior_days) > 0:\n",
        "                    target_date = prior_days[-1]\n",
        "                else:\n",
        "                    # Fallback to expiration if no prior trading days\n",
        "                    target_date = exp_dt\n",
        "        \n",
        "        results.append(target_date)\n",
        "    \n",
        "    return pd.Series(results, index=expirations.index)\n",
        "\n",
        "\n",
        "def compute_iv(row, r):\n",
        "    \"\"\"Compute implied volatility\"\"\"\n",
        "    price = row[\"mid\"]\n",
        "    S = row[\"underlying_last\"]\n",
        "    K = row[\"strike\"]\n",
        "    t = row[\"dte\"] / 365.0\n",
        "    flag = \"p\" if row[\"call_put\"] == \"P\" else \"c\"\n",
        "\n",
        "    if not (np.isfinite(price) and np.isfinite(S) and np.isfinite(K) and t > 0):\n",
        "        return np.nan\n",
        "    if price <= 0 or S <= 0 or K <= 0:\n",
        "        return np.nan\n",
        "\n",
        "    try:\n",
        "        return implied_volatility(price, S, K, t, r, flag)\n",
        "    except Exception:\n",
        "        return np.nan\n",
        "\n",
        "\n",
        "def compute_delta(row, r):\n",
        "    \"\"\"Compute delta using IV\"\"\"\n",
        "    sigma = row[\"iv\"]\n",
        "    if not np.isfinite(sigma):\n",
        "        return np.nan\n",
        "\n",
        "    S = row[\"underlying_last\"]\n",
        "    K = row[\"strike\"]\n",
        "    t = row[\"dte\"] / 365.0\n",
        "    flag = \"p\" if row[\"call_put\"] == \"P\" else \"c\"\n",
        "\n",
        "    return delta(flag, S, K, t, r, sigma)\n",
        "\n",
        "\n",
        "print(\"Helper functions defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "section-5",
      "metadata": {},
      "source": [
        "## 5. Data Fetch Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "id": "fetch-functions",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data fetch functions defined\n"
          ]
        }
      ],
      "source": [
        "def fetch_options_snapshot(ticker, date):\n",
        "    \"\"\"Fetch option chain at 15:45 ET, with caching\"\"\"\n",
        "    cache_name = f\"options_{ticker}_{date}\"\n",
        "    \n",
        "    # Try cache first\n",
        "    cached = load_from_cache(cache_name)\n",
        "    if cached is not None:\n",
        "        return cached\n",
        "    \n",
        "    # Fetch from API\n",
        "    print(f\"  [API] Fetching options for {ticker} on {date}...\")\n",
        "    \n",
        "    tz = CONFIG['timezone']\n",
        "    start_time = pd.Timestamp(f\"{date} 15:45\", tz=tz)\n",
        "    end_time = start_time + pd.Timedelta(minutes=1)\n",
        "    \n",
        "    data = client.timeseries.get_range(\n",
        "        dataset='OPRA.PILLAR',\n",
        "        schema='cmbp-1',\n",
        "        symbols=f'{ticker}.OPT',\n",
        "        stype_in='parent',\n",
        "        start=start_time,\n",
        "        end=end_time,\n",
        "    )\n",
        "    \n",
        "    df = data.to_df(tz=tz).sort_values(\"ts_event\")\n",
        "    print(f\"  [API] Fetched {len(df)} records\")\n",
        "    \n",
        "    # Save to cache\n",
        "    save_to_cache(df, cache_name)\n",
        "    \n",
        "    return df\n",
        "\n",
        "\n",
        "def fetch_equity_price(ticker, date):\n",
        "    \"\"\"Fetch underlying price at 15:45 ET, with caching\"\"\"\n",
        "    cache_name = f\"equity_{ticker}_{date}\"\n",
        "    \n",
        "    # Try cache first\n",
        "    cached = load_from_cache(cache_name)\n",
        "    if cached is not None:\n",
        "        return cached['close'].iloc[0]\n",
        "    \n",
        "    # Fetch from API\n",
        "    print(f\"  [API] Fetching equity price for {ticker} on {date}...\")\n",
        "    \n",
        "    tz = CONFIG['timezone']\n",
        "    start_time = pd.Timestamp(f\"{date} 15:45\", tz=tz)\n",
        "    end_time = start_time + pd.Timedelta(minutes=1)\n",
        "    \n",
        "    data = client.timeseries.get_range(\n",
        "        dataset='XNAS.ITCH',\n",
        "        symbols=[ticker],\n",
        "        schema='ohlcv-1m',\n",
        "        start=start_time,\n",
        "        end=end_time,\n",
        "        stype_in='raw_symbol'\n",
        "    )\n",
        "    \n",
        "    df = data.to_df()\n",
        "    print(f\"  [API] Fetched equity price: ${df['close'].iloc[0]:.2f}\")\n",
        "    \n",
        "    # Save to cache\n",
        "    save_to_cache(df, cache_name)\n",
        "    \n",
        "    return df['close'].iloc[0]\n",
        "\n",
        "\n",
        "def fetch_option_daily_ohlcv(symbol, start_date, end_date):\n",
        "    \"\"\"Fetch daily OHLCV for an option symbol, with caching\"\"\"\n",
        "    # Clean symbol for cache filename\n",
        "    cache_name = f\"daily_{symbol.replace(' ', '_')}_{start_date}_{end_date}\"\n",
        "    \n",
        "    # Try cache first\n",
        "    cached = load_from_cache(cache_name)\n",
        "    if cached is not None:\n",
        "        return cached\n",
        "    \n",
        "    # Fetch from API\n",
        "    print(f\"  [API] Fetching daily OHLCV for {symbol} from {start_date} to {end_date}...\")\n",
        "    \n",
        "    data = client.timeseries.get_range(\n",
        "        dataset='OPRA.PILLAR',\n",
        "        schema='ohlcv-1d',\n",
        "        symbols=symbol,\n",
        "        stype_in='raw_symbol',\n",
        "        start=start_date,\n",
        "        end=end_date,\n",
        "    )\n",
        "    \n",
        "    df = data.to_df(tz=CONFIG['timezone'])\n",
        "    print(f\"  [API] Fetched {len(df)} daily records\")\n",
        "    \n",
        "    # Save to cache\n",
        "    save_to_cache(df, cache_name)\n",
        "    \n",
        "    return df\n",
        "\n",
        "\n",
        "def fetch_option_1545_price(symbol, date):\n",
        "    \"\"\"Fetch option price at 15:45 ET for a specific date, with caching\"\"\"\n",
        "    # Clean symbol for cache filename\n",
        "    cache_name = f\"option_1545_{symbol.replace(' ', '_')}_{date}\"\n",
        "    \n",
        "    # Try cache first\n",
        "    cached = load_from_cache(cache_name)\n",
        "    if cached is not None:\n",
        "        return cached['close'].iloc[0]\n",
        "    \n",
        "    # Fetch from API\n",
        "    print(f\"  [API] Fetching 15:45 price for {symbol} on {date}...\")\n",
        "    \n",
        "    exit_time = pd.Timestamp(date).tz_localize(CONFIG['timezone']).replace(hour=15, minute=45)\n",
        "    \n",
        "    data = client.timeseries.get_range(\n",
        "        dataset='OPRA.PILLAR',\n",
        "        schema='ohlcv-1m',\n",
        "        symbols=symbol,\n",
        "        stype_in='raw_symbol',\n",
        "        start=exit_time,\n",
        "        end=exit_time + pd.Timedelta(minutes=1),\n",
        "    )\n",
        "    \n",
        "    df = data.to_df(tz=CONFIG['timezone'])\n",
        "    \n",
        "    if len(df) > 0:\n",
        "        exit_price = df.iloc[0]['close']\n",
        "        print(f\"  [API] Fetched price: ${exit_price:.2f}\")\n",
        "        \n",
        "        # Save to cache\n",
        "        save_to_cache(df, cache_name)\n",
        "        \n",
        "        return exit_price\n",
        "    else:\n",
        "        print(f\"  [API] No data available\")\n",
        "        return None\n",
        "\n",
        "\n",
        "print(\"Data fetch functions defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "wicmjsau74b",
      "metadata": {},
      "source": [
        "## 5b. Exit Price Fallback Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "id": "b354hf0edjl",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exit fallback functions defined\n"
          ]
        }
      ],
      "source": [
        "def get_exit_price(symbol, exit_date, expiration, strike, underlying_price, config):\n",
        "    \"\"\"\n",
        "    Get exit price with fallback cascade when minute data unavailable.\n",
        "    \n",
        "    Fallback order:\n",
        "    1. Try 15:45 minute-level data\n",
        "    2. Try daily OHLCV close for exit_date\n",
        "    3. Use expiry logic (ITM = intrinsic value, OTM = $0)\n",
        "    \n",
        "    Args:\n",
        "        symbol: Option symbol (e.g., 'TSLA  230721P00200000')\n",
        "        exit_date: Target exit date (pd.Timestamp)\n",
        "        expiration: Option expiration date (pd.Timestamp)\n",
        "        strike: Strike price\n",
        "        underlying_price: Current underlying price (for ITM/OTM check)\n",
        "        config: CONFIG dict with exit_fallback settings\n",
        "    \n",
        "    Returns:\n",
        "        (price: float or None, method: str)\n",
        "        method is one of: 'minute_data', 'daily_close', 'expiry_itm', 'expiry_otm', 'no_data'\n",
        "    \"\"\"\n",
        "    exit_date_normalized = pd.Timestamp(exit_date).tz_localize(None).normalize()\n",
        "    expiration_normalized = pd.Timestamp(expiration).tz_localize(None).normalize()\n",
        "    \n",
        "    # 1. Try 15:45 minute-level data\n",
        "    try:\n",
        "        price = fetch_option_1545_price(symbol, exit_date_normalized.date())\n",
        "        if price is not None:\n",
        "            return price, 'minute_data'\n",
        "    except Exception as e:\n",
        "        print(f\"    [FALLBACK] Minute data fetch failed: {e}\")\n",
        "    \n",
        "    # 2. Try daily OHLCV close\n",
        "    if config['exit_fallback']['use_daily_close']:\n",
        "        try:\n",
        "            # Fetch just that one day\n",
        "            df_daily = fetch_option_daily_ohlcv(\n",
        "                symbol, \n",
        "                exit_date_normalized, \n",
        "                exit_date_normalized + pd.Timedelta(days=1)\n",
        "            )\n",
        "            if len(df_daily) > 0:\n",
        "                close_price = df_daily.iloc[-1]['close']\n",
        "                print(f\"    [FALLBACK] Using daily close: ${close_price:.2f}\")\n",
        "                return close_price, 'daily_close'\n",
        "        except Exception as e:\n",
        "            print(f\"    [FALLBACK] Daily close fetch failed: {e}\")\n",
        "    \n",
        "    # 3. Use expiry logic (only if exit_date >= expiration)\n",
        "    if config['exit_fallback']['use_expiry_logic'] and exit_date_normalized >= expiration_normalized:\n",
        "        # For a PUT: ITM when underlying < strike\n",
        "        if underlying_price < strike:\n",
        "            intrinsic = strike - underlying_price\n",
        "            print(f\"    [FALLBACK] Expiry ITM - intrinsic value: ${intrinsic:.2f}\")\n",
        "            return intrinsic, 'expiry_itm'\n",
        "        else:\n",
        "            print(f\"    [FALLBACK] Expiry OTM - worthless\")\n",
        "            return 0.0, 'expiry_otm'\n",
        "    \n",
        "    # No data available\n",
        "    print(f\"    [FALLBACK] No exit price available\")\n",
        "    return None, 'no_data'\n",
        "\n",
        "\n",
        "def fetch_underlying_price_for_date(ticker, date):\n",
        "    \"\"\"\n",
        "    Fetch underlying price for a specific date (for expiry ITM/OTM calculation).\n",
        "    Uses cached equity data or fetches new.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        return fetch_equity_price(ticker, date)\n",
        "    except Exception:\n",
        "        # If we can't get the exact date, try to get most recent\n",
        "        try:\n",
        "            df = fetch_equity_history(ticker, date, lookback_days=5)\n",
        "            if len(df) > 0:\n",
        "                return df.iloc[-1]['close']\n",
        "        except Exception:\n",
        "            pass\n",
        "    return None\n",
        "\n",
        "\n",
        "print(\"Exit fallback functions defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0xvhk1gbnh7",
      "metadata": {},
      "source": [
        "## 5b. Technical Filter Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "id": "loz4txgrwi",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Technical filter functions defined\n"
          ]
        }
      ],
      "source": [
        "def fetch_equity_history(ticker, end_date, lookback_days=60):\n",
        "    \"\"\"Fetch daily equity OHLCV data for technical analysis, with caching\"\"\"\n",
        "    # Calculate start date with buffer for lookback\n",
        "    end_dt = pd.Timestamp(end_date)\n",
        "    start_dt = end_dt - pd.Timedelta(days=lookback_days)\n",
        "\n",
        "    cache_name = f\"equity_daily_{ticker}_{start_dt.date()}_{end_dt.date()}\"\n",
        "\n",
        "    # Try cache first\n",
        "    cached = load_from_cache(cache_name)\n",
        "    if cached is not None:\n",
        "        return cached\n",
        "\n",
        "    # Fetch from API\n",
        "    print(f\"  [API] Fetching equity history for {ticker} from {start_dt.date()} to {end_dt.date()}...\")\n",
        "\n",
        "    data = client.timeseries.get_range(\n",
        "        dataset='XNAS.ITCH',\n",
        "        symbols=[ticker],\n",
        "        schema='ohlcv-1d',\n",
        "        start=start_dt,\n",
        "        end=end_dt + pd.Timedelta(days=1),\n",
        "        stype_in='raw_symbol'\n",
        "    )\n",
        "\n",
        "    df = data.to_df(tz=CONFIG['timezone'])\n",
        "    print(f\"  [API] Fetched {len(df)} daily records\")\n",
        "\n",
        "    # Save to cache\n",
        "    save_to_cache(df, cache_name)\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "def calculate_bollinger_bands(df, window=20, k=2.0):\n",
        "    \"\"\"Calculate Bollinger Bands and SMA on equity data\"\"\"\n",
        "    df_bb = df.copy().sort_index()\n",
        "\n",
        "    # Rolling stats on close\n",
        "    roll = df_bb[\"close\"].rolling(window=window, min_periods=window)\n",
        "    df_bb[\"sma\"] = roll.mean()\n",
        "    df_bb[\"std\"] = roll.std(ddof=0)\n",
        "\n",
        "    # Bollinger Bands\n",
        "    df_bb[\"bb_upper\"] = df_bb[\"sma\"] + k * df_bb[\"std\"]\n",
        "    df_bb[\"bb_lower\"] = df_bb[\"sma\"] - k * df_bb[\"std\"]\n",
        "\n",
        "    # Bollinger %B (position within bands)\n",
        "    df_bb[\"bb_pctb\"] = (df_bb[\"close\"] - df_bb[\"bb_lower\"]) / (df_bb[\"bb_upper\"] - df_bb[\"bb_lower\"])\n",
        "\n",
        "    return df_bb\n",
        "\n",
        "\n",
        "def check_technical_entry(ticker, entry_date, config):\n",
        "    \"\"\"\n",
        "    Check if the technical entry conditions are met for a given date.\n",
        "\n",
        "    Returns: (passes_filter: bool, details: dict)\n",
        "    \"\"\"\n",
        "    if not config.get('technical_filter_enabled', False):\n",
        "        return True, {'filter_enabled': False}\n",
        "\n",
        "    # Need extra lookback for BB calculation\n",
        "    lookback_days = config.get('bb_window', 20) + 40\n",
        "\n",
        "    # Fetch equity history\n",
        "    df_equity = fetch_equity_history(ticker, entry_date, lookback_days)\n",
        "\n",
        "    # Calculate Bollinger Bands\n",
        "    window = config.get('bb_window', 20)\n",
        "    k = config.get('bb_std', 2.0)\n",
        "    df_bb = calculate_bollinger_bands(df_equity, window=window, k=k)\n",
        "\n",
        "    # Get the entry date row\n",
        "    entry_dt = pd.Timestamp(entry_date).tz_localize(CONFIG['timezone']).normalize()\n",
        "\n",
        "    # Find the closest date (in case entry_date is exact match or close)\n",
        "    df_bb_dates = df_bb.index.normalize()\n",
        "\n",
        "    # Try to find an exact or near match\n",
        "    mask = df_bb_dates <= entry_dt\n",
        "    if not mask.any():\n",
        "        print(f\"  [TECH FILTER] No data found for {entry_date}\")\n",
        "        return False, {'error': 'no_data'}\n",
        "\n",
        "    # Get the most recent row on or before entry_date\n",
        "    closest_idx = df_bb[mask].index[-1]\n",
        "    row = df_bb.loc[closest_idx]\n",
        "\n",
        "    close = row['close']\n",
        "    sma = row['sma']\n",
        "    bb_lower = row['bb_lower']\n",
        "\n",
        "    # Check if we have valid BB data\n",
        "    if pd.isna(sma) or pd.isna(bb_lower):\n",
        "        print(f\"  [TECH FILTER] Insufficient data for BB calculation on {entry_date}\")\n",
        "        return False, {'error': 'insufficient_data'}\n",
        "\n",
        "    # Check entry conditions\n",
        "    sma_entry = close <= sma\n",
        "    bb_entry = close <= bb_lower\n",
        "\n",
        "    details = {\n",
        "        'date': closest_idx,\n",
        "        'close': close,\n",
        "        'sma': sma,\n",
        "        'bb_lower': bb_lower,\n",
        "        'sma_entry': sma_entry,\n",
        "        'bb_entry': bb_entry,\n",
        "    }\n",
        "\n",
        "    # Determine if we pass the filter\n",
        "    require_sma = config.get('require_sma_entry', True)\n",
        "    require_bb = config.get('require_bb_entry', False)\n",
        "\n",
        "    passes = False\n",
        "    if require_bb:\n",
        "        passes = bb_entry\n",
        "    elif require_sma:\n",
        "        passes = sma_entry\n",
        "    else:\n",
        "        passes = sma_entry or bb_entry  # Either condition\n",
        "\n",
        "    return passes, details\n",
        "\n",
        "\n",
        "print(\"Technical filter functions defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "section-6",
      "metadata": {},
      "source": [
        "## 6. Exit Strategy Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "id": "exit-strategy",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exit strategy function defined (v2 with costs, slippage, fallback)\n"
          ]
        }
      ],
      "source": [
        "def backtest_exit_strategy(backtest_candidates, ticker, client, config):\n",
        "    \"\"\"\n",
        "    Backtest exit strategy for wheel options with realistic simulation.\n",
        "    \n",
        "    Features:\n",
        "    - Slippage on exit\n",
        "    - Transaction costs\n",
        "    - Fallback cascade when minute data unavailable\n",
        "    - Tracks gross vs net P&L\n",
        "    \n",
        "    Exit conditions:\n",
        "    1. Profit target: Exit when mid-price <= 50% of premium (early exit)\n",
        "    2. Time limit: Force exit at exit_dte using fallback cascade\n",
        "    \"\"\"\n",
        "    exits = []\n",
        "    exit_dte = config.get('exit_dte', 21)\n",
        "    profit_target_pct = config.get('profit_target_pct', 0.50)\n",
        "    \n",
        "    for idx, row in backtest_candidates.iterrows():\n",
        "        symbol = row['symbol']\n",
        "        \n",
        "        # Normalize dates\n",
        "        entry_date = pd.Timestamp(row['date']).tz_localize(None)\n",
        "        expiration = pd.Timestamp(row['expiration']).tz_localize(None)\n",
        "        date_exit = pd.Timestamp(row['date_exit']).tz_localize(None)\n",
        "        strike = row['strike']\n",
        "        \n",
        "        # Entry details (already adjusted for slippage in process_entry_date)\n",
        "        entry_premium = row['entry_premium']  # Slippage-adjusted entry price\n",
        "        mid_premium = row['mid']              # Original mid price\n",
        "        exit_target = entry_premium * profit_target_pct\n",
        "        cost_basis = row['cost_basis']\n",
        "        entry_costs = row['entry_costs']\n",
        "        \n",
        "        # Entry quote data (for logging)\n",
        "        entry_bid = row.get('bid_px_00', 0)\n",
        "        entry_ask = row.get('ask_px_00', 0)\n",
        "        \n",
        "        print(f\"\\nProcessing {symbol}...\")\n",
        "        print(f\"  Entry: {entry_date.date()}, Mid: ${mid_premium:.2f}, Fill: ${entry_premium:.2f}\")\n",
        "        print(f\"  Exit target: ${exit_target:.2f} ({profit_target_pct:.0%} of premium)\")\n",
        "        print(f\"  Exit date ({exit_dte} DTE): {date_exit.date()}\")\n",
        "        \n",
        "        exit_record = None\n",
        "        \n",
        "        try:\n",
        "            # Fetch daily prices for monitoring profit target\n",
        "            start_daily = entry_date + pd.Timedelta(days=1)\n",
        "            end_daily = date_exit\n",
        "            \n",
        "            if start_daily > end_daily:\n",
        "                print(f\"  Warning: Invalid date range, skipping profit target check\")\n",
        "                df_daily = pd.DataFrame()\n",
        "            else:\n",
        "                df_daily = fetch_option_daily_ohlcv(symbol, start_daily, end_daily)\n",
        "            \n",
        "            # Check daily for profit target\n",
        "            profit_target_hit = False\n",
        "            \n",
        "            for check_date, daily_row in df_daily.iterrows():\n",
        "                daily_low = daily_row['low']\n",
        "                daily_high = daily_row['high']\n",
        "                \n",
        "                # Check if exit target is within daily range\n",
        "                if daily_low <= exit_target <= daily_high:\n",
        "                    # Apply slippage to exit (buying to close)\n",
        "                    # Use mid as approximation since we don't have intraday bid/ask\n",
        "                    exit_mid = exit_target\n",
        "                    # Estimate spread from daily range\n",
        "                    estimated_spread = (daily_high - daily_low) * 0.5\n",
        "                    exit_bid = exit_target - estimated_spread / 2\n",
        "                    exit_ask = exit_target + estimated_spread / 2\n",
        "                    exit_fill = apply_exit_slippage(exit_target, exit_bid, exit_ask, config)\n",
        "                    \n",
        "                    # Calculate costs\n",
        "                    exit_costs = calculate_exit_costs(1, 'profit_target', config)\n",
        "                    \n",
        "                    # P&L calculations (per share)\n",
        "                    gross_pnl = entry_premium - exit_fill\n",
        "                    total_costs = entry_costs + exit_costs\n",
        "                    net_pnl = gross_pnl - total_costs / 100  # Convert costs to per-share\n",
        "                    \n",
        "                    exit_record = {\n",
        "                        'ticker': ticker,\n",
        "                        'symbol': symbol,\n",
        "                        'strike': strike,\n",
        "                        'entry_date': entry_date,\n",
        "                        'exit_date': check_date.tz_localize(None),\n",
        "                        'expiration': expiration,\n",
        "                        'cost_basis': cost_basis,\n",
        "                        'entry_mid': mid_premium,\n",
        "                        'entry_premium': entry_premium,\n",
        "                        'exit_target': exit_target,\n",
        "                        'exit_mid': exit_mid,\n",
        "                        'exit_price': exit_fill,\n",
        "                        'exit_reason': 'profit_target',\n",
        "                        'exit_method': 'daily_range',\n",
        "                        'days_held': (check_date.tz_localize(None) - entry_date).days,\n",
        "                        'gross_pnl': gross_pnl,\n",
        "                        'entry_costs': entry_costs,\n",
        "                        'exit_costs': exit_costs,\n",
        "                        'total_costs': total_costs,\n",
        "                        'net_pnl': net_pnl,\n",
        "                        'slippage_entry': mid_premium - entry_premium,\n",
        "                        'slippage_exit': exit_fill - exit_target,\n",
        "                    }\n",
        "                    \n",
        "                    print(f\"  Profit target hit on {check_date.date()}\")\n",
        "                    print(f\"    Fill: ${exit_fill:.2f}, Gross P&L: ${gross_pnl:.2f}, Net P&L: ${net_pnl:.2f}\")\n",
        "                    profit_target_hit = True\n",
        "                    break\n",
        "            \n",
        "            # If profit target not hit, force exit at exit_dte using fallback\n",
        "            if not profit_target_hit:\n",
        "                # Get underlying price at exit date for ITM/OTM logic\n",
        "                underlying_at_exit = fetch_underlying_price_for_date(ticker, date_exit.date())\n",
        "                if underlying_at_exit is None:\n",
        "                    underlying_at_exit = row.get('underlying_last', strike)  # Fallback to entry price\n",
        "                \n",
        "                # Use fallback cascade\n",
        "                exit_price, exit_method = get_exit_price(\n",
        "                    symbol, date_exit, expiration, strike, underlying_at_exit, config\n",
        "                )\n",
        "                \n",
        "                if exit_price is not None:\n",
        "                    # Apply slippage only for market exits (not expiry logic)\n",
        "                    if exit_method in ['minute_data', 'daily_close']:\n",
        "                        # Estimate spread as 5% of price for slippage calc\n",
        "                        estimated_spread = exit_price * 0.05\n",
        "                        exit_bid = exit_price - estimated_spread / 2\n",
        "                        exit_ask = exit_price + estimated_spread / 2\n",
        "                        exit_fill = apply_exit_slippage(exit_price, exit_bid, exit_ask, config)\n",
        "                    else:\n",
        "                        # No slippage for expiry (assigned or worthless)\n",
        "                        exit_fill = exit_price\n",
        "                    \n",
        "                    # Calculate costs based on exit method\n",
        "                    exit_costs = calculate_exit_costs(1, exit_method, config)\n",
        "                    \n",
        "                    # P&L calculations\n",
        "                    gross_pnl = entry_premium - exit_fill\n",
        "                    total_costs = entry_costs + exit_costs\n",
        "                    net_pnl = gross_pnl - total_costs / 100\n",
        "                    \n",
        "                    exit_reason = f'time_limit_{exit_dte}dte' if exit_method in ['minute_data', 'daily_close'] else exit_method\n",
        "                    \n",
        "                    exit_record = {\n",
        "                        'ticker': ticker,\n",
        "                        'symbol': symbol,\n",
        "                        'strike': strike,\n",
        "                        'entry_date': entry_date,\n",
        "                        'exit_date': date_exit,\n",
        "                        'expiration': expiration,\n",
        "                        'cost_basis': cost_basis,\n",
        "                        'entry_mid': mid_premium,\n",
        "                        'entry_premium': entry_premium,\n",
        "                        'exit_target': exit_target,\n",
        "                        'exit_mid': exit_price,\n",
        "                        'exit_price': exit_fill,\n",
        "                        'exit_reason': exit_reason,\n",
        "                        'exit_method': exit_method,\n",
        "                        'days_held': (date_exit - entry_date).days,\n",
        "                        'gross_pnl': gross_pnl,\n",
        "                        'entry_costs': entry_costs,\n",
        "                        'exit_costs': exit_costs,\n",
        "                        'total_costs': total_costs,\n",
        "                        'net_pnl': net_pnl,\n",
        "                        'slippage_entry': mid_premium - entry_premium,\n",
        "                        'slippage_exit': exit_fill - exit_price if exit_method in ['minute_data', 'daily_close'] else 0,\n",
        "                    }\n",
        "                    \n",
        "                    print(f\"  Exit via {exit_method} on {date_exit.date()}\")\n",
        "                    print(f\"    Fill: ${exit_fill:.2f}, Gross P&L: ${gross_pnl:.2f}, Net P&L: ${net_pnl:.2f}\")\n",
        "                else:\n",
        "                    print(f\"  ERROR: No exit price available - trade dropped\")\n",
        "            \n",
        "            if exit_record:\n",
        "                exits.append(exit_record)\n",
        "                    \n",
        "        except Exception as e:\n",
        "            print(f\"  Error: {e}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "            continue\n",
        "    \n",
        "    # Create results DataFrame\n",
        "    exits_df = pd.DataFrame(exits)\n",
        "    \n",
        "    # Add ROC calculations\n",
        "    if len(exits_df) > 0:\n",
        "        exits_df['gross_pnl_pct'] = (exits_df['gross_pnl'] / exits_df['entry_premium']) * 100\n",
        "        exits_df['net_pnl_pct'] = (exits_df['net_pnl'] / exits_df['entry_premium']) * 100\n",
        "        exits_df['roc'] = (exits_df['net_pnl'] * 100 / exits_df['cost_basis']) * 100  # Multiply by 100 for per-contract\n",
        "    \n",
        "    return exits_df\n",
        "\n",
        "\n",
        "print(\"Exit strategy function defined (v2 with costs, slippage, fallback)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "section-7",
      "metadata": {},
      "source": [
        "## 7. Process Entry Date Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "id": "process-date",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Process entry date function defined (v2 with liquidity, slippage, costs)\n"
          ]
        }
      ],
      "source": [
        "def process_entry_date(entry_date, ticker, positions_df, config):\n",
        "    \"\"\"\n",
        "    Process a single entry date for a single ticker with realistic simulation.\n",
        "    \n",
        "    Features:\n",
        "    - Liquidity filters\n",
        "    - Slippage on entry\n",
        "    - Transaction costs\n",
        "    - Fixed cost basis calculation\n",
        "    - Intermediate step caching for faster debugging\n",
        "    \n",
        "    Returns: (new_positions_df, exits_df, filtered_out_df)\n",
        "    \"\"\"\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Processing {ticker} on {entry_date}\")\n",
        "    print('='*60)\n",
        "    \n",
        "    r = config['risk_free_rate']\n",
        "    use_trading_days_filter = config.get('use_trading_days_for_dte_filter', True)\n",
        "    use_trading_days_exit = config.get('use_trading_days_for_exit', True)\n",
        "    exit_dte = config.get('exit_dte', 21)\n",
        "    \n",
        "    # ===========================================================================\n",
        "    # STEP 1: Fetch options chain (uses API-level cache)\n",
        "    # ===========================================================================\n",
        "    df_opts = fetch_options_snapshot(ticker, entry_date)\n",
        "    \n",
        "    # ===========================================================================\n",
        "    # STEP 2: Parse symbols\n",
        "    # ===========================================================================\n",
        "    df_parsed = load_step_cache('parsed_options', ticker, entry_date)\n",
        "    if df_parsed is None:\n",
        "        df_parsed = parse_option_symbols(df_opts)\n",
        "        save_step_cache(df_parsed, 'parsed_options', ticker, entry_date)\n",
        "    \n",
        "    # ===========================================================================\n",
        "    # STEP 3: Add DTE\n",
        "    # ===========================================================================\n",
        "    df_with_dte = load_step_cache('chain_with_dte', ticker, entry_date)\n",
        "    if df_with_dte is None:\n",
        "        df_with_dte = add_trading_dte(df_parsed, use_trading_days=use_trading_days_filter)\n",
        "        save_step_cache(df_with_dte, 'chain_with_dte', ticker, entry_date)\n",
        "    \n",
        "    # ===========================================================================\n",
        "    # STEP 4: Fetch underlying price (uses API-level cache)\n",
        "    # ===========================================================================\n",
        "    underlying_price = fetch_equity_price(ticker, entry_date)\n",
        "    \n",
        "    # ===========================================================================\n",
        "    # STEP 5-7: Process chain snapshot with greeks\n",
        "    # ===========================================================================\n",
        "    chain_with_greeks = load_step_cache('chain_with_greeks', ticker, entry_date)\n",
        "    if chain_with_greeks is None:\n",
        "        # Keep only rows with quotes\n",
        "        quotes = df_with_dte[df_with_dte[\"bid_px_00\"].notna() & df_with_dte[\"ask_px_00\"].notna()].copy()\n",
        "        quotes[\"mid\"] = (quotes[\"bid_px_00\"] + quotes[\"ask_px_00\"]) / 2\n",
        "        \n",
        "        # Collapse to one row per contract (latest quote)\n",
        "        chain_snapshot = (\n",
        "            quotes\n",
        "            .sort_values(\"ts_event\")\n",
        "            .groupby([\"symbol\", \"expiration\", \"strike\", \"call_put\"])\n",
        "            .tail(1)\n",
        "            .copy()\n",
        "        )\n",
        "        chain_snapshot[\"underlying_last\"] = underlying_price\n",
        "        \n",
        "        # Calculate IV and delta\n",
        "        chain_snapshot[\"iv\"] = chain_snapshot.apply(lambda row: compute_iv(row, r), axis=1)\n",
        "        chain_snapshot[\"delta\"] = chain_snapshot.apply(lambda row: compute_delta(row, r), axis=1)\n",
        "        \n",
        "        # Calculate exit dates\n",
        "        chain_snapshot['date_exit'] = calculate_exit_dte_dates(\n",
        "            chain_snapshot['expiration'], \n",
        "            exit_dte,\n",
        "            use_trading_days=use_trading_days_exit\n",
        "        )\n",
        "        \n",
        "        # Add entry date\n",
        "        chain_snapshot['date'] = chain_snapshot['ts_event'].dt.date\n",
        "        \n",
        "        chain_with_greeks = chain_snapshot\n",
        "        save_step_cache(chain_with_greeks, 'chain_with_greeks', ticker, entry_date)\n",
        "    \n",
        "    # ===========================================================================\n",
        "    # STEP 8: Basic option filters (DTE, delta, type)\n",
        "    # ===========================================================================\n",
        "    candidates = load_step_cache('candidates', ticker, entry_date)\n",
        "    if candidates is None:\n",
        "        candidates = chain_with_greeks[\n",
        "            (chain_with_greeks[\"call_put\"] == config['option_type'])\n",
        "            & chain_with_greeks[\"dte\"].between(config['min_dte'], config['max_dte'])\n",
        "            & chain_with_greeks[\"delta\"].abs().between(config['min_delta'], config['max_delta'])\n",
        "        ].copy()\n",
        "        save_step_cache(candidates, 'candidates', ticker, entry_date)\n",
        "    \n",
        "    print(f\"\\nFound {len(candidates)} candidates passing basic filters (DTE, delta)\")\n",
        "    \n",
        "    if len(candidates) == 0:\n",
        "        return pd.DataFrame(), pd.DataFrame(), pd.DataFrame()\n",
        "    \n",
        "    # 11. Apply liquidity filters\n",
        "    filtered_out = []\n",
        "    liquidity_passed = []\n",
        "    \n",
        "    for idx, row in candidates.iterrows():\n",
        "        passes, reason = passes_liquidity_filter(row, config)\n",
        "        if passes:\n",
        "            liquidity_passed.append(idx)\n",
        "        else:\n",
        "            filtered_out.append({\n",
        "                'symbol': row['symbol'],\n",
        "                'strike': row['strike'],\n",
        "                'dte': row['dte'],\n",
        "                'reason': reason,\n",
        "                'bid': row.get('bid_px_00', 0),\n",
        "                'ask': row.get('ask_px_00', 0),\n",
        "                'bid_size': row.get('bid_sz_00', 0),\n",
        "                'ask_size': row.get('ask_sz_00', 0),\n",
        "            })\n",
        "    \n",
        "    candidates = candidates.loc[liquidity_passed]\n",
        "    filtered_out_df = pd.DataFrame(filtered_out)\n",
        "    \n",
        "    if config['liquidity']['enabled']:\n",
        "        print(f\"After liquidity filter: {len(candidates)} candidates\")\n",
        "        if len(filtered_out_df) > 0:\n",
        "            print(f\"  Filtered out: {len(filtered_out_df)} (reasons: {filtered_out_df['reason'].value_counts().to_dict()})\")\n",
        "    \n",
        "    if len(candidates) == 0:\n",
        "        return pd.DataFrame(), pd.DataFrame(), filtered_out_df\n",
        "    \n",
        "    # 12. Filter out same-day duplicates\n",
        "    if len(positions_df) > 0:\n",
        "        same_date_positions = positions_df[\n",
        "            (positions_df['entry_date'] == entry_date) & \n",
        "            (positions_df['ticker'] == ticker)\n",
        "        ]\n",
        "        if len(same_date_positions) > 0:\n",
        "            held_symbols = same_date_positions['symbol'].tolist()\n",
        "            candidates = candidates[~candidates['symbol'].isin(held_symbols)]\n",
        "            print(f\"After removing same-day duplicates: {len(candidates)} candidates\")\n",
        "    \n",
        "    if len(candidates) == 0:\n",
        "        return pd.DataFrame(), pd.DataFrame(), filtered_out_df\n",
        "    \n",
        "    # 13. Create backtest candidates with slippage and costs\n",
        "    backtest_candidates = candidates.copy()\n",
        "    \n",
        "    # Apply entry slippage (selling puts)\n",
        "    backtest_candidates['entry_premium'] = backtest_candidates.apply(\n",
        "        lambda row: apply_entry_slippage(\n",
        "            row['mid'], \n",
        "            row['bid_px_00'], \n",
        "            row['ask_px_00'], \n",
        "            config\n",
        "        ), \n",
        "        axis=1\n",
        "    )\n",
        "    \n",
        "    # Calculate cost basis (FIXED)\n",
        "    backtest_candidates['cost_basis'] = backtest_candidates['strike'].apply(\n",
        "        lambda s: calculate_cost_basis(s, config)\n",
        "    )\n",
        "    \n",
        "    # Calculate entry costs\n",
        "    backtest_candidates['entry_costs'] = calculate_entry_costs(1, config)\n",
        "    \n",
        "    # Calculate profit target based on slippage-adjusted premium\n",
        "    backtest_candidates['exit_50_perc'] = config['profit_target_pct'] * backtest_candidates['entry_premium']\n",
        "    \n",
        "    # Track slippage\n",
        "    backtest_candidates['entry_slippage'] = backtest_candidates['mid'] - backtest_candidates['entry_premium']\n",
        "    \n",
        "    # Select columns for output\n",
        "    backtest_cols = [\n",
        "        'symbol', 'date_exit', 'cost_basis', 'mid', 'entry_premium', 'entry_costs',\n",
        "        'exit_50_perc', 'entry_slippage', 'date', 'dte', 'expiration', 'strike',\n",
        "        'bid_px_00', 'ask_px_00', 'bid_sz_00', 'ask_sz_00', 'underlying_last'\n",
        "    ]\n",
        "    backtest_candidates = backtest_candidates[backtest_cols]\n",
        "    \n",
        "    print(f\"\\nBacktest candidates:\")\n",
        "    display_cols = ['symbol', 'strike', 'dte', 'mid', 'entry_premium', 'entry_slippage']\n",
        "    print(backtest_candidates[display_cols].to_string())\n",
        "    \n",
        "    # 14. Run exit strategy\n",
        "    exits_df = backtest_exit_strategy(backtest_candidates, ticker, client, config)\n",
        "    \n",
        "    # 15. Create new positions for tracking\n",
        "    new_positions = backtest_candidates.copy()\n",
        "    new_positions['entry_date'] = entry_date\n",
        "    new_positions['ticker'] = ticker\n",
        "    \n",
        "    return new_positions, exits_df, filtered_out_df\n",
        "\n",
        "\n",
        "print(\"Process entry date function defined (v2 with liquidity, slippage, costs)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "section-8",
      "metadata": {},
      "source": [
        "## 8. Main Backtest Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "main-loop",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize tracking DataFrames\n",
        "positions_df = pd.DataFrame()      # All positions entered\n",
        "all_exits_df = pd.DataFrame()      # All completed trades\n",
        "all_filtered_df = pd.DataFrame()   # Options filtered out by liquidity\n",
        "skipped_entries = []               # Ticker/date combos that failed technical filter\n",
        "\n",
        "# Process each ticker and entry date combination\n",
        "for ticker in CONFIG['tickers']:\n",
        "    print(f\"\\n{'#'*70}\")\n",
        "    print(f\"# Processing ticker: {ticker}\")\n",
        "    print('#'*70)\n",
        "\n",
        "    for entry_date in CONFIG['entry_dates']:\n",
        "\n",
        "        # Check technical filter first (per ticker)\n",
        "        if CONFIG.get('technical_filter_enabled', False):\n",
        "            passes_filter, tech_details = check_technical_entry(\n",
        "                ticker, entry_date, CONFIG\n",
        "            )\n",
        "\n",
        "            if not passes_filter:\n",
        "                print(f\"\\n[SKIPPED] {ticker} on {entry_date} - Failed technical filter\")\n",
        "                if 'close' in tech_details:\n",
        "                    print(f\"  Close: ${tech_details['close']:.2f}, SMA: ${tech_details['sma']:.2f}\")\n",
        "                skipped_entries.append({'ticker': ticker, 'date': entry_date, 'reason': 'technical_filter', **tech_details})\n",
        "                continue\n",
        "            else:\n",
        "                print(f\"\\n[PASSED] {ticker} on {entry_date} - Technical filter passed\")\n",
        "                if 'close' in tech_details:\n",
        "                    print(f\"  Close: ${tech_details['close']:.2f}, SMA: ${tech_details['sma']:.2f}\")\n",
        "\n",
        "        # Process this ticker/date combination\n",
        "        new_positions, exits, filtered = process_entry_date(\n",
        "            entry_date=entry_date,\n",
        "            ticker=ticker,\n",
        "            positions_df=positions_df,\n",
        "            config=CONFIG\n",
        "        )\n",
        "\n",
        "        # Add new positions\n",
        "        if len(new_positions) > 0:\n",
        "            positions_df = pd.concat([positions_df, new_positions], ignore_index=True)\n",
        "\n",
        "        # Accumulate exits\n",
        "        if len(exits) > 0:\n",
        "            all_exits_df = pd.concat([all_exits_df, exits], ignore_index=True)\n",
        "\n",
        "        # Track filtered out options\n",
        "        if len(filtered) > 0:\n",
        "            filtered['ticker'] = ticker\n",
        "            filtered['entry_date'] = entry_date\n",
        "            all_filtered_df = pd.concat([all_filtered_df, filtered], ignore_index=True)\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"BACKTEST COMPLETE\")\n",
        "print('='*70)\n",
        "print(f\"Tickers processed: {CONFIG['tickers']}\")\n",
        "total_combinations = len(CONFIG['tickers']) * len(CONFIG['entry_dates'])\n",
        "print(f\"Total ticker/date combinations: {total_combinations}\")\n",
        "\n",
        "if CONFIG.get('technical_filter_enabled', False) and len(skipped_entries) > 0:\n",
        "    print(f\"Skipped by technical filter: {len(skipped_entries)}\")\n",
        "\n",
        "print(f\"\\nTotal positions entered: {len(positions_df)}\")\n",
        "print(f\"Total exits: {len(all_exits_df)}\")\n",
        "\n",
        "if len(all_filtered_df) > 0:\n",
        "    print(f\"Options filtered by liquidity: {len(all_filtered_df)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "section-9",
      "metadata": {},
      "source": [
        "## 9. Results - Aggregate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "results-aggregate",
      "metadata": {},
      "outputs": [],
      "source": [
        "if len(all_exits_df) > 0:\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"AGGREGATE RESULTS (All Tickers)\")\n",
        "    print(\"=\"*70)\n",
        "    \n",
        "    # Exit method breakdown\n",
        "    print(\"\\nExit Methods:\")\n",
        "    print(all_exits_df['exit_method'].value_counts().to_string())\n",
        "    \n",
        "    print(\"\\nExit Reasons:\")\n",
        "    print(all_exits_df['exit_reason'].value_counts().to_string())\n",
        "    \n",
        "    # P&L Summary\n",
        "    print(\"\\n\" + \"-\"*40)\n",
        "    print(\"P&L SUMMARY (per share values)\")\n",
        "    print(\"-\"*40)\n",
        "    \n",
        "    total_gross = all_exits_df['gross_pnl'].sum()\n",
        "    total_net = all_exits_df['net_pnl'].sum()\n",
        "    total_costs = all_exits_df['total_costs'].sum()\n",
        "    total_entry_slippage = all_exits_df['slippage_entry'].sum()\n",
        "    total_exit_slippage = all_exits_df['slippage_exit'].sum()\n",
        "    \n",
        "    print(f\"\\nGross P&L:     ${total_gross:>10.2f}\")\n",
        "    print(f\"Total Costs:   ${total_costs:>10.2f}\")\n",
        "    print(f\"Net P&L:       ${total_net:>10.2f}\")\n",
        "    print(f\"\\nEntry Slippage: ${total_entry_slippage:>9.2f}\")\n",
        "    print(f\"Exit Slippage:  ${total_exit_slippage:>9.2f}\")\n",
        "    \n",
        "    # Per-contract values (x100)\n",
        "    print(\"\\n\" + \"-\"*40)\n",
        "    print(\"P&L SUMMARY (per contract = x100)\")\n",
        "    print(\"-\"*40)\n",
        "    print(f\"\\nGross P&L:     ${total_gross * 100:>10.2f}\")\n",
        "    print(f\"Total Costs:   ${total_costs:>10.2f}\")\n",
        "    print(f\"Net P&L:       ${total_net * 100:>10.2f}\")\n",
        "    \n",
        "    # Performance metrics\n",
        "    print(\"\\n\" + \"-\"*40)\n",
        "    print(\"PERFORMANCE METRICS\")\n",
        "    print(\"-\"*40)\n",
        "    print(f\"\\nTrades: {len(all_exits_df)}\")\n",
        "    print(f\"Win Rate: {(all_exits_df['net_pnl'] > 0).mean() * 100:.1f}%\")\n",
        "    print(f\"Avg Gross P&L: ${all_exits_df['gross_pnl'].mean():.2f}\")\n",
        "    print(f\"Avg Net P&L:   ${all_exits_df['net_pnl'].mean():.2f}\")\n",
        "    print(f\"Avg ROC:       {all_exits_df['roc'].mean():.2f}%\")\n",
        "    print(f\"Avg Days Held: {all_exits_df['days_held'].mean():.1f}\")\n",
        "    \n",
        "    # Trade log\n",
        "    print(\"\\n\" + \"-\"*40)\n",
        "    print(\"TRADE LOG\")\n",
        "    print(\"-\"*40)\n",
        "    display_cols = ['ticker', 'symbol', 'entry_date', 'exit_date', \n",
        "                   'entry_premium', 'exit_price', 'gross_pnl', 'net_pnl', \n",
        "                   'total_costs', 'roc', 'exit_method']\n",
        "    print(all_exits_df[display_cols].to_string())\n",
        "else:\n",
        "    print(\"No exits recorded\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "section-10",
      "metadata": {},
      "source": [
        "## 10. Results - By Ticker"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "results-by-ticker",
      "metadata": {},
      "outputs": [],
      "source": [
        "if len(all_exits_df) > 0:\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"RESULTS BY TICKER\")\n",
        "    print(\"=\"*70)\n",
        "    \n",
        "    for ticker in CONFIG['tickers']:\n",
        "        ticker_exits = all_exits_df[all_exits_df['ticker'] == ticker]\n",
        "        \n",
        "        if len(ticker_exits) == 0:\n",
        "            print(f\"\\n{ticker}: No exits\")\n",
        "            continue\n",
        "            \n",
        "        print(f\"\\n{'-'*50}\")\n",
        "        print(f\"{ticker}\")\n",
        "        print(f\"{'-'*50}\")\n",
        "        \n",
        "        print(f\"  Trades: {len(ticker_exits)}\")\n",
        "        print(f\"  Win Rate: {(ticker_exits['net_pnl'] > 0).mean() * 100:.1f}%\")\n",
        "        print(f\"\\n  Gross P&L: ${ticker_exits['gross_pnl'].sum():.2f} (per share)\")\n",
        "        print(f\"  Net P&L:   ${ticker_exits['net_pnl'].sum():.2f} (per share)\")\n",
        "        print(f\"  Costs:     ${ticker_exits['total_costs'].sum():.2f}\")\n",
        "        print(f\"\\n  Avg Gross: ${ticker_exits['gross_pnl'].mean():.2f}\")\n",
        "        print(f\"  Avg Net:   ${ticker_exits['net_pnl'].mean():.2f}\")\n",
        "        print(f\"  Avg ROC:   {ticker_exits['roc'].mean():.2f}%\")\n",
        "        print(f\"  Avg Days:  {ticker_exits['days_held'].mean():.1f}\")\n",
        "        \n",
        "        print(f\"\\n  Exit methods:\")\n",
        "        for method, count in ticker_exits['exit_method'].value_counts().items():\n",
        "            print(f\"    {method}: {count}\")\n",
        "else:\n",
        "    print(\"No exits recorded\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "section-11",
      "metadata": {},
      "source": [
        "## 11. Ticker Comparison Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ticker-comparison",
      "metadata": {},
      "outputs": [],
      "source": [
        "if len(all_exits_df) > 0:\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"TICKER COMPARISON\")\n",
        "    print(\"=\"*70)\n",
        "    \n",
        "    comparison = all_exits_df.groupby('ticker').agg({\n",
        "        'gross_pnl': ['count', 'sum', 'mean'],\n",
        "        'net_pnl': ['sum', 'mean'],\n",
        "        'total_costs': 'sum',\n",
        "        'roc': 'mean',\n",
        "        'days_held': 'mean',\n",
        "    }).round(2)\n",
        "    \n",
        "    comparison.columns = ['Trades', 'Gross P&L', 'Avg Gross', \n",
        "                          'Net P&L', 'Avg Net', 'Total Costs',\n",
        "                          'Avg ROC %', 'Avg Days']\n",
        "    \n",
        "    # Add win rate\n",
        "    win_rates = all_exits_df.groupby('ticker').apply(\n",
        "        lambda x: (x['net_pnl'] > 0).mean() * 100,\n",
        "        include_groups=False\n",
        "    ).round(1)\n",
        "    comparison['Win %'] = win_rates\n",
        "    \n",
        "    print(comparison.to_string())\n",
        "    \n",
        "    # Cost impact summary\n",
        "    print(\"\\n\" + \"-\"*40)\n",
        "    print(\"COST & SLIPPAGE IMPACT\")\n",
        "    print(\"-\"*40)\n",
        "    \n",
        "    for ticker in CONFIG['tickers']:\n",
        "        t = all_exits_df[all_exits_df['ticker'] == ticker]\n",
        "        if len(t) == 0:\n",
        "            continue\n",
        "        \n",
        "        gross = t['gross_pnl'].sum()\n",
        "        net = t['net_pnl'].sum()\n",
        "        costs = t['total_costs'].sum()\n",
        "        slip_entry = t['slippage_entry'].sum()\n",
        "        slip_exit = t['slippage_exit'].sum()\n",
        "        \n",
        "        print(f\"\\n{ticker}:\")\n",
        "        print(f\"  Gross â†’ Net: ${gross:.2f} â†’ ${net:.2f}\")\n",
        "        print(f\"  Costs: ${costs:.2f} ({costs/gross*100 if gross else 0:.1f}% of gross)\")\n",
        "        print(f\"  Entry slippage: ${slip_entry:.2f}\")\n",
        "        print(f\"  Exit slippage: ${slip_exit:.2f}\")\n",
        "else:\n",
        "    print(\"No exits recorded\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "section-12",
      "metadata": {},
      "source": [
        "## 12. Validation & Filtered Options\n",
        "\n",
        "Check trades and see which options were filtered by liquidity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "validation",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Show options filtered out by liquidity\n",
        "if len(all_filtered_df) > 0:\n",
        "    print(\"=\"*60)\n",
        "    print(\"OPTIONS FILTERED BY LIQUIDITY\")\n",
        "    print(\"=\"*60)\n",
        "    print(f\"\\nTotal filtered: {len(all_filtered_df)}\")\n",
        "    print(\"\\nBy reason:\")\n",
        "    for reason, count in all_filtered_df['reason'].value_counts().items():\n",
        "        print(f\"  {reason}: {count}\")\n",
        "    \n",
        "    print(\"\\nSample filtered options:\")\n",
        "    print(all_filtered_df.head(10).to_string())\n",
        "else:\n",
        "    print(\"No options filtered by liquidity\")\n",
        "\n",
        "# Validation: Check specific symbols\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"VALIDATION\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "expected_tsla = ['TSLA  230721P00200000', 'TSLA  230721P00205000']\n",
        "\n",
        "if len(all_exits_df) > 0:\n",
        "    print(\"\\nTSLA validation (expected symbols):\")\n",
        "    for sym in expected_tsla:\n",
        "        match = all_exits_df[all_exits_df['symbol'] == sym]\n",
        "        if len(match) > 0:\n",
        "            row = match.iloc[0]\n",
        "            print(f\"\\n  {sym}:\")\n",
        "            print(f\"    Entry: ${row['entry_premium']:.2f} (mid: ${row['entry_mid']:.2f})\")\n",
        "            print(f\"    Exit:  ${row['exit_price']:.2f} via {row['exit_method']}\")\n",
        "            print(f\"    Gross P&L: ${row['gross_pnl']:.2f}\")\n",
        "            print(f\"    Net P&L:   ${row['net_pnl']:.2f}\")\n",
        "            print(f\"    ROC: {row['roc']:.2f}%\")\n",
        "        else:\n",
        "            print(f\"\\n  {sym}: NOT FOUND\")\n",
        "else:\n",
        "    print(\"\\nNo trades to validate\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.14.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
